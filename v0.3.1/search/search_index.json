{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#_1","title":"Home","text":"<p>       A modern open-source platform that transforms bioinformatics workflow outputs into interactive dashboards.     </p> Workflow Ecosystem <p>       Connect with standardized bioinformatics workflows from various platforms.     </p> Snakemake Workflow Catalog Live interactive demo - Try it! <p>The demo is running an \"unauthenticated mode\" to allow anyone to try it out without needing an account. However, you can create a temporary account to create your own projects and upload datasets.</p> <p>Note: Accounts and related data will be reset after 1 hour to keep the demo environment clean.</p> Get started with Depictio                Try Demo Directly                             Launch in Gitpod                             Install Locally              Live Demo <p>Your browser does not support iframes. Click here to view the Depictio dashboard</p> Powered by Modern Technologies Dash FastAPI MongoDB MinIO Polars Project Overview The Challenge <p>Bioinformatics researchers face significant challenges managing and analyzing large-scale datasets from production workflows. Despite numerous available tools, there's a notable absence of platforms designed for seamless integration with production workflows.</p> Our Solution <p>Depictio addresses this gap with a generic, centralized platform that integrates workflow output data to build interactive dashboards. It provides scalable, flexible, and open-source solutions for researchers handling large datasets from any execution engine (Nextflow, Snakemake, Galaxy, R, etc.).</p> Key Features Data Ingestion <ul> <li>Client-side processing: Depictio-CLI allows local data scanning and processing, pushing results to S3 bucket</li> <li>Multiple formats: Support for Parquet, CSV, JSON, TSV using Polars and Delta Lake</li> </ul> Frontend &amp; Visualization <ul> <li>Customizable dashboards: Design and customize dashboards with ease</li> <li>Real-time interactivity: Dynamic data exploration with instant updates</li> <li>Project organization: Organize dashboards by projects for better management</li> </ul> System &amp; Infrastructure <ul> <li>Cloud-ready: Built for Kubernetes and Docker-Compose environments</li> <li>Open-source: Community-driven development with transparent deployment</li> </ul> Getting Started <p>Ready to get started with Depictio?</p> Docker Compose <p>Quickest way to get started</p> Recommended Kubernetes <p>For production environments</p> Production CLI Tools <p>For data ingestion and management</p> Tools Funding <p>Depictio is developed with the support of academic and public funding, enabling us to provide a free and open-source platform for the bioinformatics community.</p> Marie Sk\u0142odowska-Curie Grant <p>This project has received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sk\u0142odowska-Curie grant agreement No 945405</p> Learn More ARISE Programme <p>ARISE is a postdoctoral research programme for technology developers, hosted at EMBL.</p> Learn More EMBL <p>The European Molecular Biology Laboratory is Europe's flagship laboratory for the life sciences.</p> Learn More Academic Partners SciLifeLab Data Centre <p>SciLifeLab Data Centre provides data-driven life science research infrastructure and expertise to accelerate open science in Sweden and beyond.</p> Learn More"},{"location":"animated-logo/","title":"Animated Triangular Logo","text":"<p>The triangular SVG from the original Depictio progressive loading script, now with dynamic animations!</p>"},{"location":"animated-logo/#interactive-triangular-svg","title":"Interactive Triangular SVG","text":"Click the logo to trigger enhanced animation! Trigger Animation Debug Shapes <p>         \ud83d\udca1 Hover over the logo to see the sequential triangular animation!     </p>"},{"location":"animated-logo/#triangular-animation-features","title":"Triangular Animation Features","text":"<p>The animated triangular logo includes the exact effects from the original Python implementation:</p>"},{"location":"animated-logo/#1-sequential-triangle-pulsing","title":"1. Sequential Triangle Pulsing","text":"<ul> <li>7 Triangular Shapes: Each triangle (<code>shape-1</code> through <code>shape-7</code>) animates individually</li> <li>Sequential Timing: 0.1s delays between each triangle (0s, 0.1s, 0.2s, 0.3s, 0.4s, 0.5s, 0.6s)</li> <li>Pulse Effect: Each triangle scales from 100% to 120% and back with brightness changes</li> <li>Transform Origin: Each shape uses <code>center</code> origin and <code>fill-box</code> for proper scaling</li> </ul>"},{"location":"animated-logo/#2-color-coded-triangles","title":"2. Color-Coded Triangles","text":"<ul> <li>Shape 1: <code>#f1c547</code> (Golden yellow)</li> <li>Shape 2: <code>#c064d3</code> (Purple/magenta)  </li> <li>Shape 3: <code>#58b3cb</code> (Light blue)</li> <li>Shape 4: <code>#6279f0</code> (Blue)</li> <li>Shape 5: <code>#ee9644</code> (Orange)</li> <li>Shape 6: <code>#7d5dec</code> (Purple)</li> <li>Shape 7: <code>#a1d44d</code> (Green)</li> </ul>"},{"location":"animated-logo/#3-interactive-features","title":"3. Interactive Features","text":"<ul> <li>Click Activation: Click to trigger the sequential animation</li> <li>Automatic Cycling: Animation triggers every 10 seconds</li> <li>Debug Console: Console logs show triangle detection and animation status</li> </ul>"},{"location":"animated-logo/#shape-animation-timing","title":"Shape Animation Timing","text":"Triangle 1 <p>Delay: 0.0s</p> <p>Color: Golden Yellow</p> Triangle 2 <p>Delay: 0.1s</p> <p>Color: Purple/Magenta</p> Triangle 3 <p>Delay: 0.2s</p> <p>Color: Light Blue</p> Triangle 4 <p>Delay: 0.3s</p> <p>Color: Blue</p> Triangle 5 <p>Delay: 0.4s</p> <p>Color: Orange</p> Triangle 6 <p>Delay: 0.5s</p> <p>Color: Purple</p> Triangle 7 <p>Delay: 0.6s</p> <p>Color: Green</p>"},{"location":"animated-logo/#technical-implementation","title":"Technical Implementation","text":"<p>The animation system consists of:</p> <ol> <li>CSS Keyframes: Define the core animation patterns</li> <li>JavaScript Enhancement: Adds interactivity and advanced effects  </li> <li>Sequential Timing: Staggered animations with delays</li> <li>Responsive Design: Animations adapt to different screen sizes</li> </ol>"},{"location":"animated-logo/#animation-keyframes-used","title":"Animation Keyframes Used","text":"<ul> <li><code>sequential-pulse</code>: Main pulsing animation with scaling and color effects</li> <li><code>logo-breathe</code>: Subtle breathing effect with rotation and glow</li> <li><code>color-shift</code>: Smooth color transitions across the spectrum</li> <li><code>particle-float</code>: Floating particle effects around the logo</li> </ul>"},{"location":"animated-logo/#code-reference","title":"Code Reference","text":"<p>The implementation can be found in: - CSS: <code>docs/stylesheets/extra.css:92-166</code> (Animation definitions) - JavaScript: <code>docs/javascripts/animated-logo.js:1-150</code> (Interactive enhancements) - Configuration: <code>mkdocs.yml:77-78</code> (Asset loading)</p>"},{"location":"animated-logo/#svg-details","title":"SVG Details","text":"<p>This SVG contains 7 triangular shapes with the following colors:</p> <ul> <li>Shape 1: Golden yellow (#f1c547)</li> <li>Shape 2: Purple/magenta (#c064d3)</li> <li>Shape 3: Light blue (#58b3cb)</li> <li>Shape 4: Blue (#6279f0)</li> <li>Shape 5: Orange (#ee9644)</li> <li>Shape 6: Purple (#7d5dec)</li> <li>Shape 7: Green (#a1d44d)</li> </ul> <p>The original Python script animates each triangle sequentially with a 0.1s delay between each one.</p>"},{"location":"documentation_outline/","title":"Depictio Documentation Outline","text":"<p>This document provides an overview of the Depictio documentation structure and content. It serves as a guide for maintaining and expanding the documentation.</p>"},{"location":"documentation_outline/#documentation-structure","title":"Documentation Structure","text":"<p>The Depictio documentation is organized into the following main sections:</p>"},{"location":"documentation_outline/#home","title":"Home","text":"<ul> <li>Purpose: Provide an overview of Depictio and its key features</li> <li>Content: Project overview, key features, getting started links, documentation structure</li> <li>Files: <code>index.md</code></li> </ul>"},{"location":"documentation_outline/#installation","title":"Installation","text":"<ul> <li>Purpose: Guide users through the installation process</li> <li>Content: Installation instructions for different environments</li> <li>Files:</li> <li><code>installation/install.md</code> - Overview of installation options</li> <li><code>installation/docker.md</code> - Docker Compose installation</li> <li><code>installation/kubernetes.md</code> - Kubernetes installation</li> <li><code>installation/cli.md</code> - CLI installation</li> </ul>"},{"location":"documentation_outline/#usage","title":"Usage","text":"<ul> <li>Purpose: Help users effectively use Depictio</li> <li>Content: Getting started guides, CLI usage, web UI guides, dashboard creation and usage</li> <li>Files:</li> <li><code>usage/get_started.md</code> - Quick start guide</li> <li><code>depictio-cli/usage.md</code> - CLI usage instructions</li> <li><code>depictio-cli/full_reference_config.md</code> - YAML configuration reference</li> <li><code>usage/guides/web_ui.md</code> - Web UI guide</li> <li><code>usage/guides/dashboard_creation.md</code> - Dashboard creation guide</li> <li><code>usage/guides/dashboard_usage.md</code> - Dashboard usage guide</li> <li><code>usage/administration.md</code> - Administration guide</li> </ul>"},{"location":"documentation_outline/#features","title":"Features","text":"<ul> <li>Purpose: Describe Depictio's features and architecture</li> <li>Content: Architecture overview, modularity, and other features</li> <li>Files:</li> <li><code>features/architecture.md</code> - System architecture</li> <li><code>features/modularity.md</code> - Modularity and code structure</li> </ul>"},{"location":"documentation_outline/#api","title":"API","text":"<ul> <li>Purpose: Document the Depictio API</li> <li>Content: API overview, endpoints, authentication, and usage</li> <li>Files:</li> <li><code>api/overview.md</code> - API overview and authentication</li> <li><code>api/endpoints.md</code> - API endpoints summary</li> </ul>"},{"location":"documentation_outline/#developer","title":"Developer","text":"<ul> <li>Purpose: Provide information for developers who want to contribute</li> <li>Content: Contributing guidelines, development setup, workflow</li> <li>Files:</li> <li><code>developer/contributing.md</code> - Contributing guide</li> </ul>"},{"location":"documentation_outline/#faq","title":"FAQ","text":"<ul> <li>Purpose: Answer common questions about Depictio</li> <li>Content: General FAQs, installation FAQs, usage FAQs</li> <li>Files:</li> <li><code>FAQ/general.md</code> - General frequently asked questions</li> </ul>"},{"location":"documentation_outline/#changelog","title":"Changelog","text":"<ul> <li>Purpose: Track changes and updates to Depictio</li> <li>Content: Version history, new features, bug fixes</li> <li>Files:</li> <li><code>changelog/changelog.md</code> - Changelog</li> </ul>"},{"location":"documentation_outline/#content-guidelines","title":"Content Guidelines","text":"<p>When adding or updating documentation, please follow these guidelines:</p> <ol> <li>Clear Structure: Maintain the hierarchical structure of the documentation</li> <li>Consistent Style: Use consistent formatting and writing style</li> <li>User-Focused: Write with the user's perspective in mind</li> <li>Examples: Include examples and code snippets where appropriate</li> <li>Visuals: Use diagrams, screenshots, and other visuals to enhance understanding</li> <li>Up-to-Date: Keep documentation in sync with the latest version of Depictio</li> </ol>"},{"location":"documentation_outline/#future-expansion","title":"Future Expansion","text":"<p>The documentation can be expanded in the following areas:</p> <ol> <li>Tutorials: Step-by-step guides for common tasks</li> <li>Advanced Usage: Advanced features and configurations</li> <li>Troubleshooting: Common issues and their solutions</li> <li>API Reference: Detailed API documentation</li> <li>Component Reference: Detailed documentation for each dashboard component</li> <li>Use Cases: Real-world examples of how Depictio is being used</li> </ol>"},{"location":"FAQ/","title":"Frequently Asked Questions","text":"<p>This section addresses common questions about Depictio. If you don't find an answer to your question here, please check open an issue on GitHub.</p>"},{"location":"FAQ/#faq-categories","title":"FAQ Categories","text":"<p>The FAQ is organized into several categories to help you find answers quickly:</p>"},{"location":"FAQ/#general-questions","title":"General Questions","text":"<p>Common questions about what Depictio is, who it's for, and its key features.</p> <p>View General FAQ</p>"},{"location":"FAQ/#installation-and-setup","title":"Installation and Setup","text":"<p>Questions about system requirements, installation methods, and configuration.</p> <p>View Installation Guide</p>"},{"location":"FAQ/#usage","title":"Usage","text":"<p>Questions about creating dashboards, supported data formats, and sharing.</p> <p>View Usage Guide</p>"},{"location":"FAQ/#getting-more-help","title":"Getting More Help","text":"<p>If you can't find an answer to your question in the FAQ:</p> <ol> <li>Search the documentation: Use the search function to find relevant information</li> <li>Open an issue on GitHub: For bugs, feature requests, or other technical issues</li> </ol>"},{"location":"FAQ/faq/","title":"FAQ","text":"<p>Ongoing list of frequently asked questions.</p>"},{"location":"FAQ/faq/#code-mode","title":"Code Mode","text":""},{"location":"FAQ/faq/#what-is-code-mode-in-figure-creation","title":"What is Code Mode in figure creation?","text":"<p>Code Mode allows you to create figures by writing Python/Plotly code directly instead of using the UI interface. You get full control over visualization parameters and can create complex, customized plots using familiar Python syntax.</p>"},{"location":"FAQ/faq/#how-secure-is-code-execution-in-code-mode","title":"How secure is code execution in Code Mode?","text":"<p>Code execution uses RestrictedPython (Zope Foundation's battle-tested security framework) with multiple protection layers: - Compile-time restrictions: Unsafe operations blocked before code runs - Isolated execution environment: Code runs with only approved globals and built-ins - No system access: File system, network, and OS operations completely blocked - Memory protection: Works on DataFrame copies to prevent data corruption - Comprehensive logging: All execution attempts are monitored and attributed</p>"},{"location":"FAQ/faq/#can-i-import-custom-libraries-in-code-mode","title":"Can I import custom libraries in Code Mode?","text":"<p>No, only pre-approved libraries are available for security reasons: - <code>plotly.express</code> (as <code>px</code>) - <code>plotly.graph_objects</code> (as <code>go</code>) - <code>pandas</code> (as <code>pd</code>) - <code>numpy</code> (as <code>np</code>) - Basic Python built-ins (str, int, len, range, etc.)</p>"},{"location":"FAQ/faq/#whats-the-difference-between-ui-mode-and-code-mode","title":"What's the difference between UI Mode and Code Mode?","text":"Feature UI Mode Code Mode Ease of Use Point-and-click interface Requires Python knowledge Customization Limited to UI options Full Plotly customization Speed Quick for standard plots Better for complex visualizations Learning Curve Beginner-friendly Requires coding skills"},{"location":"FAQ/faq/#how-do-i-access-my-data-in-code-mode","title":"How do I access my data in Code Mode?","text":"<p>Your selected data collection is automatically available as the <code>df</code> variable (pandas DataFrame). Simply use <code>df</code> in your code:</p> <pre><code># Example: Create a scatter plot\nfig = px.scatter(df, x='column1', y='column2', color='category')\n</code></pre>"},{"location":"FAQ/faq/#why-do-i-get-import-not-allowed-or-compilation-errors","title":"Why do I get \"Import not allowed\" or compilation errors?","text":"<p>RestrictedPython automatically blocks unsafe operations at compile-time. Common issues:</p> <p>\u2705 Allowed: <pre><code># Pre-imported libraries (no import needed)\nfig = px.scatter(df, x='col1', y='col2')\ndf_filtered = df[df['value'] &gt; 10]\n</code></pre></p> <p>\u274c Blocked by RestrictedPython: <pre><code>import requests          # Network access blocked\nimport os               # System access blocked\nopen('file.txt')        # File operations blocked\nexec('some_code')       # Dynamic execution blocked\n</code></pre></p> <p>The security framework prevents these operations before your code runs, ensuring complete safety.</p>"},{"location":"FAQ/faq/#can-i-save-and-reuse-code-snippets","title":"Can I save and reuse code snippets?","text":"<p>Currently, code is saved with each figure component. For reusable code patterns, you can copy-paste between components or keep your own external code library for reference.</p>"},{"location":"FAQ/faq/#known-issues","title":"Known Issues","text":""},{"location":"FAQ/general/","title":"Frequently Asked Questions","text":"<p>This page addresses common questions about Depictio. If you don't find an answer to your question here, please open an issue on GitHub.</p>"},{"location":"FAQ/general/#general-questions","title":"General Questions","text":""},{"location":"FAQ/general/#what-is-depictio","title":"What is Depictio?","text":"<p>Depictio is a microservices web-based platform designed to streamline the analysis of bioinformatics workflows by enabling the creation of customized visualization dashboards. It provides a dynamic and interactive dashboard experience for quality control (QC) metrics monitoring and result exploration in omics.</p>"},{"location":"FAQ/general/#who-is-depictio-for","title":"Who is Depictio for?","text":"<p>Depictio is designed for bioinformaticians, researchers, and core facilities who work with large-scale omics datasets and need a flexible, interactive way to visualize and analyze their data. The tool is primarily designed to aggregate data from production workflows (e.g., typically nf-core). While the backend is mostly designed to be used by bioinformaticians, the frontend is user-friendly and can be used by anyone who needs to visualize and explore omics data.</p>"},{"location":"FAQ/general/#is-depictio-open-source","title":"Is Depictio open-source?","text":"<p>Yes, Depictio is an open-source project under MIT Licence. You can find the source code on GitHub.</p>"},{"location":"FAQ/general/#is-depictio-free-to-use","title":"Is Depictio free to use?","text":"<p>Yes, Depictio is free to use under the MIT License. You can deploy it on your own infrastructure without any licensing fees.</p>"},{"location":"FAQ/general/#who-is-behind-depictio","title":"Who is behind Depictio?","text":"<p>Depictio is currently actively and mainly developed by Thomas Weber, an ARISE fellow working in the European Molecular Biology Laboratory (EMBL) Data Science Centre. The project is open to contributions from the community, and we welcome pull requests and feedback.</p>"},{"location":"FAQ/general/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"FAQ/general/#what-are-the-system-requirements-for-depictio","title":"What are the system requirements for Depictio?","text":"<p>Depictio is designed to run in containerized environments. The basic requirements are:</p> <ul> <li>Docker and Docker Compose (for local deployment)</li> <li>Kubernetes (for production deployment)</li> </ul> <p>We recommend at least 8 GB of RAM and a multi-core CPU for optimal performance, especially when working with large datasets.</p>"},{"location":"FAQ/general/#how-do-i-install-depictio","title":"How do I install Depictio?","text":"<p>Please refer to our Installation Guide for detailed instructions on how to install Depictio in different environments.</p>"},{"location":"FAQ/general/#can-i-run-depictio-on-my-local-machine","title":"Can I run Depictio on my local machine?","text":"<p>Yes, you can run Depictio locally using Docker Compose. See the Docker Compose Installation Guide for details.</p>"},{"location":"FAQ/general/#usage","title":"Usage","text":""},{"location":"FAQ/general/#how-do-i-create-a-dashboard-in-depictio","title":"How do I create a dashboard in Depictio?","text":"<p>Creating dashboards in Depictio is straightforward. Please refer to our Dashboard Creation Guide for step-by-step instructions.</p>"},{"location":"FAQ/general/#what-data-formats-does-depictio-support","title":"What data formats does Depictio support?","text":"<p>Depictio currently supports all tabular formats (CSV, TSV, XLSX, Parquet, etc.) compatible with Polars. Futur versions will include support for MultiQC reports, as well as JBrowse compatible omics data formats (BED, BAM, VCF, etc.).</p>"},{"location":"FAQ/general/#can-i-share-my-dashboards-with-others","title":"Can I share my dashboards with others?","text":"<p>Depictio currently supports instance-level sharing of dashboards. You can make your dashboards public or private, and share them with other users on the same instance. Future versions will include more advanced sharing options with role-based access control (RBAC) and user groups. We're also envisioning to support sharing dashboards with external users via public links and via SciLifeLab Serve.</p>"},{"location":"FAQ/general/#technical-questions","title":"Technical Questions","text":""},{"location":"FAQ/general/#how-does-depictio-handle-large-datasets","title":"How does Depictio handle large datasets?","text":"<p>Depictio relies on Polars and Delta lake for efficient data processing and storage. This allows it to handle large datasets efficiently, leveraging lazy evaluation and optimized query execution.</p>"},{"location":"FAQ/general/#can-i-integrate-depictio-with-my-existing-workflows","title":"Can I integrate Depictio with my existing workflows?","text":"<p>Yes, Depictio is designed to integrate with existing bioinformatics workflows. The depictio-CLI tool can be used to push data from your workflows to Depictio for visualization.</p>"},{"location":"FAQ/general/#is-there-an-api-for-depictio","title":"Is there an API for Depictio?","text":"<p>Yes, Depictio provides a comprehensive REST API that allows you to interact with all aspects of the platform programmatically. See the API Reference for details.</p>"},{"location":"FAQ/general/#troubleshooting","title":"Troubleshooting","text":""},{"location":"FAQ/general/#im-having-trouble-connecting-to-the-depictio-server-what-should-i-check","title":"I'm having trouble connecting to the Depictio server. What should I check?","text":"<ol> <li>Ensure that all required services (API, Dash, MongoDB, MinIO) are running using Docker Compose or Kubernetes</li> <li>Check the logs of the services for any error messages</li> <li>Check network connectivity and firewall settings</li> <li>Verify that the server URLs are correctly configured (in the <code>.env</code> file for Docker Compose or in the Kubernetes configuration)</li> </ol>"},{"location":"FAQ/general/#how-do-i-report-a-bug-or-request-a-feature","title":"How do I report a bug or request a feature?","text":"<p>You can report bugs or request features by opening an issue on our GitHub repository. Please provide as much detail as possible to help us understand and address your issue.</p>"},{"location":"api/","title":"API Documentation","text":"<p>Depictio provides a comprehensive REST API that allows you to interact with all aspects of the platform programmatically. This section provides an overview of the API and links to detailed documentation.</p>"},{"location":"api/#overview","title":"Overview","text":"<p>The Depictio API enables you to:</p> <ul> <li>Manage projects and workflows</li> <li>Create and configure dashboards</li> <li>Upload and retrieve data</li> <li>Manage users and permissions</li> </ul> <p>All API endpoints follow RESTful principles and use JWT authentication for security.</p>"},{"location":"api/#api-structure-endpoints","title":"API Structure &amp; Endpoints","text":"<p>The Depictio API is organized around the following main resources:</p> <ul> <li>Projects - Manage top-level entities that encapsulate production-oriented pipelines/workflows</li> <li>Workflows - Interact with standardized production-oriented workflows</li> <li>Run Configurations - Define parameters and settings for workflow runs</li> <li>Runs - Manage instances of workflow executions</li> <li>Files - Access artifacts produced by workflow runs</li> <li>Data Collections - Work with aggregated data from files following the same structure</li> <li>Dashboards - Create and manage interactive visualization dashboards</li> <li>Users - Handle user authentication and authorization</li> </ul>"},{"location":"api/#authentication","title":"Authentication","text":"<p>All API requests require authentication using JWT (JSON Web Tokens). To authenticate:</p> <ol> <li>Obtain a token by sending a POST request to the <code>/auth/login</code> endpoint with your credentials</li> <li>Include the token in the <code>Authorization</code> header of subsequent requests using the format: <code>Bearer &lt;token&gt;</code></li> </ol>"},{"location":"api/#api-versioning","title":"API Versioning","text":"<p>The Depictio API uses versioning to ensure backward compatibility. The current version is <code>v1</code>, which is reflected in the URL path:</p> <pre><code>https://your-depictio-instance.com/depictio/api/v1/...\n</code></pre>"},{"location":"api/#in-this-section","title":"In This Section","text":"<ul> <li>API Reference - Interactive API documentation generated from the OpenAPI specification</li> </ul> <ul> <li>FastAPI Docs - Access to the auto-generated FastAPI documentation</li> </ul>"},{"location":"api/api_docs_integration/","title":"API Documentation Integration","text":"<p>This page explains how to integrate the Depictio API documentation with MkDocs using the OpenAPI specification.</p>"},{"location":"api/api_docs_integration/#automated-openapi-specification-export","title":"Automated OpenAPI Specification Export","text":"<p>Depictio includes a script to automatically export the OpenAPI specification from a running API instance. This ensures that your documentation always reflects the latest API changes.</p>"},{"location":"api/api_docs_integration/#using-the-script","title":"Using the Script","text":"<p>The script is located at <code>update_openapi.py</code> in the documentation root directory. To use it:</p> <ol> <li>Make sure your Depictio API is running (typically at http://localhost:8058)</li> <li>Run the script:</li> </ol> <pre><code># From the depictio-docs directory\npython update_openapi.py\n</code></pre> <p>This will fetch the OpenAPI specification and save it to <code>docs/api/openapi.json</code>.</p>"},{"location":"api/api_docs_integration/#script-options","title":"Script Options","text":"<p>The script supports several command-line options:</p> <pre><code>python update_openapi.py --help\n</code></pre> <ul> <li><code>--api-url</code>: Base URL of the API (default: http://localhost:8058)</li> <li><code>--output</code>: Path where the OpenAPI JSON file should be saved (default: docs/api/openapi.json)</li> <li><code>--indent</code>: JSON indentation level (default: 2)</li> </ul>"},{"location":"api/api_docs_integration/#integration-with-documentation-build","title":"Integration with Documentation Build","text":"<p>You can integrate this script into your documentation build process by adding it to your build scripts or CI/CD pipeline. For example:</p> <pre><code># Start the API server\ndocker-compose up -d depictio-backend\n\n# Wait for the API to be ready\nsleep 10\n\n# Fetch the OpenAPI specification\npython update_openapi.py\n\n# Build the documentation\nmkdocs build\n</code></pre>"},{"location":"api/api_docs_integration/#displaying-api-documentation-in-mkdocs","title":"Displaying API Documentation in MkDocs","text":"<p>Once you have the OpenAPI specification, you can display it in your MkDocs site using the <code>swagger-ui-tag</code> plugin.</p>"},{"location":"api/api_docs_integration/#basic-usage","title":"Basic Usage","text":"<p>To display the API documentation on a page, add the following to your Markdown:</p> <pre><code>&lt;swagger-ui url=\"../../api/openapi.json\"/&gt;\n</code></pre> <p>The path should be relative to the current Markdown file.</p>"},{"location":"api/api_docs_integration/#customization-options","title":"Customization Options","text":"<p>You can customize the Swagger UI display with additional options:</p> <pre><code>&lt;swagger-ui\n  url=\"../../api/openapi.json\"\n  expand=\"all\"\n  theme=\"dark\"\n/&gt;\n</code></pre> <p>Available options include:</p> <ul> <li><code>expand</code>: Controls the default expansion setting for operations and tags. Values are \"list\" (default), \"full\", \"none\", or \"all\".</li> <li><code>theme</code>: The theme to use. Values are \"light\" (default) or \"dark\".</li> <li><code>try-it-out-enabled</code>: Whether to show the \"Try it out\" section. Values are \"true\" or \"false\".</li> </ul>"},{"location":"api/api_docs_integration/#example-full-api-documentation-page","title":"Example: Full API Documentation Page","text":"<p>Here's an example of a complete API documentation page:</p> <pre><code># API Reference\n\nThis page provides interactive documentation for the Depictio API.\n\n## Authentication\n\nTo use the API, you need to authenticate using JWT tokens. See the [Authentication](#/components/securitySchemes/bearerAuth) section for details.\n\n## Endpoints\n\n&lt;swagger-ui url=\"../../api/openapi.json\"/&gt;\n</code></pre>"},{"location":"api/api_docs_integration/#fallback-for-static-documentation","title":"Fallback for Static Documentation","text":"<p>If you want to provide API documentation even when the OpenAPI specification hasn't been generated (e.g., for GitHub Pages), you can include a simplified static version:</p> <pre><code>&lt;swagger-ui url=\"../../api/openapi.json\" fallback=\"true\"/&gt;\n</code></pre> <p>With the <code>fallback</code> option, if the OpenAPI specification file is not found, a message will be displayed instead of an error.</p>"},{"location":"api/api_docs_integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api/api_docs_integration/#openapi-specification-not-found","title":"OpenAPI Specification Not Found","text":"<p>If you see an error about the OpenAPI specification not being found:</p> <ol> <li>Make sure you've run the <code>update_openapi.py</code> script</li> <li>Check that the path in the <code>url</code> attribute is correct relative to the current Markdown file</li> <li>Verify that the file exists in the expected location</li> </ol>"},{"location":"api/api_docs_integration/#swagger-ui-not-displaying","title":"Swagger UI Not Displaying","text":"<p>If the Swagger UI component is not displaying:</p> <ol> <li>Make sure the <code>swagger-ui-tag</code> plugin is installed and enabled in your <code>mkdocs.yml</code></li> <li>Check for JavaScript errors in your browser's developer console</li> <li>Try using a different browser</li> </ol>"},{"location":"api/endpoints/","title":"API Endpoints","text":"<p>This page provides an overview of the available API endpoints in Depictio. For detailed documentation on each endpoint, please refer to the API reference.</p>"},{"location":"api/endpoints/#available-endpoints","title":"Available Endpoints","text":"<ul> <li>Projects - Endpoints for managing projects</li> <li>Workflows - Endpoints for managing workflows</li> <li>Run Configurations - Endpoints for managing run configurations</li> <li>Runs - Endpoints for managing workflow runs</li> <li>Files - Endpoints for accessing files</li> <li>Data Collections - Endpoints for working with data collections</li> <li>Dashboards - Endpoints for managing dashboards</li> <li>Users - Endpoints for user management</li> </ul>"},{"location":"api/fastapi_docs/","title":"FastAPI Documentation","text":"<p>Depictio uses FastAPI for its backend, which provides automatic, interactive API documentation. This page explains how to access and use this documentation.</p>"},{"location":"api/fastapi_docs/#accessing-the-api-documentation","title":"Accessing the API Documentation","text":"<p>FastAPI automatically generates two types of interactive documentation:</p> <ol> <li>Swagger UI - Available at <code>/docs</code></li> <li>ReDoc - Available at <code>/redoc</code></li> </ol> <p>To access these, simply append these paths to your Depictio API base URL:</p> <ul> <li>Swagger UI: <code>http://&lt;your-depictio-host&gt;:8058/docs</code></li> <li>ReDoc: <code>http://&lt;your-depictio-host&gt;:8058/redoc</code></li> </ul>"},{"location":"api/reference/","title":"API Reference","text":"<p>This page provides interactive documentation for the Depictio API.</p>"},{"location":"api/reference/#interactive-api-documentation","title":"Interactive API Documentation","text":"<p>The documentation below is generated automatically from the OpenAPI specification.</p> <p></p>"},{"location":"api/reference/#using-the-api-documentation","title":"Using the API Documentation","text":"<ol> <li>Browse Endpoints: Expand the sections to see available endpoints</li> <li>Read Documentation: Each endpoint includes descriptions, parameters, and response schemas</li> </ol>"},{"location":"blog/","title":"Depictio Blog","text":"<p>Welcome to Depictio blog!</p> <p>Find the latest news, features, and insights from the Depictio project.</p>"},{"location":"blog/post_130525/","title":"13/05/2025 - Depictio goes live!","text":"<p>We are excited to announce that Depictio is now live! After months of hard work and dedication, we are thrilled to share our platform with the world. Depictio is designed to help you visualize and analyze your data in a more intuitive and interactive way. With Depictio, you can create stunning visualizations, build interactive dashboards, and gain insights from your data like never before. Our platform is user-friendly and flexible, making it easy for anyone to get started with data visualization. We invite you to explore Depictio and see how it can transform the way you work with data. Whether you're a data analyst, a business intelligence professional, or just someone who loves data, Depictio has something for you.</p>"},{"location":"blog/drafts/create-your-first-dashboard/","title":"\ud83c\udfa8 Create Your First Dashboard: From Data to Interactive Insights","text":"<p>Step-by-step guide to building your first interactive dashboard in Depictio - no coding required!</p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#what-youll-build","title":"\ud83c\udfaf What You'll Build","text":"<p>By the end of this tutorial, you'll have created a fully interactive dashboard with:</p> <ul> <li>\ud83c\udf9b\ufe0f Interactive Controls - Sliders and dropdowns that filter your data</li> <li>\ud83d\udcca Dynamic Charts - Scatter plots and bar charts that update in real-time</li> <li>\ud83d\udccb Data Tables - Sortable, filterable tables with infinite scrolling</li> <li>\ud83c\udfaf Metrics Cards - Key statistics that change with your filters</li> </ul> <p>Time to complete: 15-20 minutes Difficulty: Beginner Requirements: Sample CSV file (we'll provide one)</p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#step-1-prepare-your-data","title":"\ud83d\ude80 Step 1: Prepare Your Data","text":"","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#option-a-use-our-sample-data","title":"Option A: Use Our Sample Data","text":"<p>Download our sample Palmer Penguins dataset:</p> <pre><code># Download sample data\ncurl -o penguins.csv https://raw.githubusercontent.com/depictio/sample-data/main/penguins.csv\n</code></pre>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#option-b-use-your-own-data","title":"Option B: Use Your Own Data","text":"<p>Your CSV file should have: - Column headers in the first row - Mixed data types (text, numbers, categories) - At least 50 rows for interesting interactions</p> <p>Example structure: <pre><code>species,island,bill_length_mm,bill_depth_mm,flipper_length_mm,body_mass_g,sex,year\nAdelie,Torgersen,39.1,18.7,181,3750,male,2007\nAdelie,Torgersen,39.5,17.4,186,3800,female,2007\nChinstrap,Dream,46.5,17.9,192,3500,female,2007\n...\n</code></pre></p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#step-2-create-your-project","title":"\ud83d\udcc1 Step 2: Create Your Project","text":"","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#using-the-web-interface","title":"Using the Web Interface","text":"<ol> <li>Visit Depictio \u2192 Go to demo.depictio.embl.org</li> <li>Create Account \u2192 Click \"Sign Up\" (or use demo mode)</li> <li>New Project \u2192 Click \"+ Create Project\"</li> <li>Project Settings:</li> <li>Name: \"My First Dashboard\"  </li> <li>Type: Basic</li> <li>Description: \"Learning interactive dashboards\"</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#using-the-cli","title":"Using the CLI","text":"<pre><code># Install depictio-cli\npip install depictio-cli\n\n# Login and create project\ndepictio auth login\ndepictio project create \\\n    --name \"My First Dashboard\" \\\n    --type basic \\\n    --description \"Learning interactive dashboards\"\n</code></pre>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#step-3-upload-your-data","title":"\ud83d\udce4 Step 3: Upload Your Data","text":"","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#web-upload","title":"Web Upload","text":"<ol> <li>Navigate to Project \u2192 Click on \"My First Dashboard\"</li> <li>Add Data Collection:</li> <li>Click \"Add Data Collection\"</li> <li>Name: \"Penguins Dataset\"</li> <li>Upload File: Select your <code>penguins.csv</code></li> <li>Click \"Upload\"</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#cli-upload","title":"CLI Upload","text":"<pre><code># Upload data collection\ndepictio data upload \\\n    --file penguins.csv \\\n    --collection-name \"Penguins Dataset\" \\\n    --project-name \"My First Dashboard\"\n</code></pre> <p>\u2705 Success indicator: You should see \"Data collection created successfully\" and your data preview.</p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#step-4-create-your-dashboard","title":"\ud83c\udfa8 Step 4: Create Your Dashboard","text":"","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#access-dashboard-builder","title":"Access Dashboard Builder","text":"<ol> <li>Go to Dashboards \u2192 Click \"Dashboards\" tab</li> <li>Create Dashboard \u2192 Click \"+ New Dashboard\"</li> <li>Dashboard Settings:</li> <li>Name: \"Penguins Explorer\"</li> <li>Description: \"Interactive penguin species analysis\"</li> </ol> <p>You'll see the dashboard canvas - an empty grid where you'll add components.</p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#step-5-add-interactive-controls","title":"\ud83c\udf9b\ufe0f Step 5: Add Interactive Controls","text":"<p>Interactive components are global filters that affect all other dashboard components.</p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#add-species-filter","title":"Add Species Filter","text":"<ol> <li>Add Component \u2192 Click \"+\" button \u2192 \"Interactive Component\"</li> <li>Component Configuration:</li> <li>Data Collection: \"Penguins Dataset\"</li> <li>Column: \"species\"</li> <li>Component Type: \"Dropdown\"</li> <li>Label: \"Filter by Species\"</li> <li>Save \u2192 Click \"Save Component\"</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#add-body-mass-slider","title":"Add Body Mass Slider","text":"<ol> <li>Add Component \u2192 Click \"+\" \u2192 \"Interactive Component\" </li> <li>Configuration:</li> <li>Data Collection: \"Penguins Dataset\"</li> <li>Column: \"body_mass_g\"</li> <li>Component Type: \"Range Slider\"</li> <li>Label: \"Body Mass Range (g)\"</li> <li>Save \u2192 Click \"Save Component\"</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#add-island-selection","title":"Add Island Selection","text":"<ol> <li>Add Component \u2192 Click \"+\" \u2192 \"Interactive Component\"</li> <li>Configuration:</li> <li>Data Collection: \"Penguins Dataset\"  </li> <li>Column: \"island\"</li> <li>Component Type: \"Segmented Control\"</li> <li>Label: \"Select Island\"</li> <li>Save \u2192 Click \"Save Component\"</li> </ol> <p>\ud83c\udfaf Result: You now have three interactive controls that will filter your entire dashboard!</p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#step-6-add-visual-components","title":"\ud83d\udcca Step 6: Add Visual Components","text":"","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#create-a-scatter-plot","title":"Create a Scatter Plot","text":"<ol> <li>Add Component \u2192 Click \"+\" \u2192 \"Figure Component\"</li> <li>Figure Configuration:</li> <li>Chart Type: \"Scatter Plot\"</li> <li>Data Collection: \"Penguins Dataset\"</li> <li>X-axis: \"bill_length_mm\"</li> <li>Y-axis: \"bill_depth_mm\" </li> <li>Color: \"species\"</li> <li>Size: \"body_mass_g\"</li> <li>Title: \"Bill Dimensions by Species\"</li> <li>Save \u2192 Click \"Save Component\"</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#add-a-bar-chart","title":"Add a Bar Chart","text":"<ol> <li>Add Component \u2192 Click \"+\" \u2192 \"Figure Component\"</li> <li>Configuration:</li> <li>Chart Type: \"Bar Chart\"</li> <li>Data Collection: \"Penguins Dataset\"</li> <li>X-axis: \"island\"</li> <li>Y-axis: \"count\" (aggregated)</li> <li>Color: \"species\"</li> <li>Title: \"Penguin Count by Island\"</li> <li>Save \u2192 Click \"Save Component\"</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#create-a-metrics-card","title":"Create a Metrics Card","text":"<ol> <li>Add Component \u2192 Click \"+\" \u2192 \"Card Component\"</li> <li>Configuration:</li> <li>Data Collection: \"Penguins Dataset\"</li> <li>Metric: \"body_mass_g\"</li> <li>Aggregation: \"Average\"</li> <li>Title: \"Average Body Mass\"</li> <li>Format: \"Number with units (g)\"</li> <li>Save \u2192 Click \"Save Component\"</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#add-a-data-table","title":"Add a Data Table","text":"<ol> <li>Add Component \u2192 Click \"+\" \u2192 \"Table Component\"</li> <li>Configuration:</li> <li>Data Collection: \"Penguins Dataset\"</li> <li>Columns: Select all columns</li> <li>Title: \"Penguin Data Explorer\"</li> <li>Enable Sorting: \u2705</li> <li>Enable Filtering: \u2705</li> <li>Save \u2192 Click \"Save Component\"</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#step-7-test-the-interactivity","title":"\u2728 Step 7: Test the Interactivity","text":"<p>Now comes the magic! All components respond to interactive filters simultaneously.</p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#test-species-filter","title":"Test Species Filter","text":"<ol> <li>Use the species dropdown \u2192 Select \"Adelie\"</li> <li>Watch everything update:</li> <li>Scatter plot shows only Adelie penguins</li> <li>Bar chart adjusts counts</li> <li>Average body mass recalculates  </li> <li>Table filters to Adelie rows only</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#test-body-mass-slider","title":"Test Body Mass Slider","text":"<ol> <li>Adjust the mass range \u2192 Drag to 3000-4000g</li> <li>See real-time updates:</li> <li>All charts filter to penguins in that mass range</li> <li>Metrics update instantly</li> <li>Table shows matching rows</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#test-multi-filter-combinations","title":"Test Multi-Filter Combinations","text":"<ol> <li>Apply multiple filters:</li> <li>Species: \"Chinstrap\"</li> <li>Body Mass: 3500-4500g</li> <li>Island: \"Dream\"</li> <li>Everything synchronizes to show only Chinstrap penguins from Dream island in the specified mass range!</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#step-8-customize-your-layout","title":"\ud83c\udfa8 Step 8: Customize Your Layout","text":"","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#arrange-components","title":"Arrange Components","text":"<ol> <li>Enable Edit Mode \u2192 Toggle \"Edit Mode\" in the header</li> <li>Drag Components \u2192 Click and drag to rearrange</li> <li>Resize Components \u2192 Drag corners to resize</li> <li>Fine-tune Layout \u2192 Position components for optimal viewing</li> </ol> <p>Recommended Layout: <pre><code>[Species Filter] [Body Mass Slider] [Island Selection]\n[   Scatter Plot   ] [  Bar Chart  ] [ Metrics Card ]\n[          Data Table (full width)          ]\n</code></pre></p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#advanced-customization","title":"Advanced Customization","text":"<p>Chart Styling: - Colors: Customize color schemes - Axes: Adjust labels and ranges - Legends: Position and format legends - Annotations: Add trend lines or highlights</p> <p>Component Options: - Responsive Sizing: Components adapt to screen size - Conditional Formatting: Highlight important values - Export Options: Download charts as images</p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#step-9-advanced-interactions","title":"\ud83d\udd04 Step 9: Advanced Interactions","text":"","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#scatter-plot-selections","title":"Scatter Plot Selections","text":"<ol> <li>Box Selection \u2192 Click and drag on scatter plot to select points</li> <li>Watch Updates \u2192 All other components filter to selected points</li> <li>Reset Selection \u2192 Click \"Reset\" button to clear</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#table-row-selection-coming-soon","title":"Table Row Selection (Coming Soon!)","text":"<pre><code># Future feature: Table row selection\nselected_rows = table_component.get_selected_rows()\ndashboard.apply_selection_filter(selected_rows)\n</code></pre>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#cross-filtering","title":"Cross-Filtering","text":"<p>Your dashboard now supports cross-filtering: selections in one component automatically filter all others, creating a cohesive analytical experience.</p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#step-10-save-and-share","title":"\ud83d\udcbe Step 10: Save and Share","text":"","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#save-your-dashboard","title":"Save Your Dashboard","text":"<ol> <li>Save Progress \u2192 Click \"Save Dashboard\"</li> <li>Set Permissions:</li> <li>Private: Only you can access</li> <li>Public: Anyone with link can view</li> <li>Team: Share with specific users</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#share-options","title":"Share Options","text":"<p>Public Link: <pre><code># Your shareable dashboard URL\nhttps://demo.depictio.embl.org/dashboards/your-dashboard-id\n</code></pre></p> <p>Embed Code: <pre><code>&lt;!-- Embed in website or documentation --&gt;\n&lt;iframe src=\"https://demo.depictio.embl.org/embed/your-dashboard-id\" \n        width=\"100%\" height=\"600px\" frameborder=\"0\"&gt;\n&lt;/iframe&gt;\n</code></pre></p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#what-youve-accomplished","title":"\ud83c\udfaf What You've Accomplished","text":"<p>Congratulations! \ud83c\udf89 You've created a fully interactive dashboard with:</p> <p>\u2705 Real-time filtering across all components \u2705 Professional visualizations (scatter plots, bar charts) \u2705 Interactive controls (dropdowns, sliders, segmented controls) \u2705 Data exploration tools (sortable tables, metrics) \u2705 Responsive design that works on any device \u2705 Shareable results with public links</p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#next-level-advanced-features","title":"\ud83d\ude80 Next Level: Advanced Features","text":"","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#add-more-data-collections","title":"Add More Data Collections","text":"<pre><code># Upload additional datasets to the same project\ndepictio data upload \\\n    --file environmental_data.csv \\\n    --collection-name \"Environmental Conditions\"\n\ndepictio data upload \\\n    --file genetic_markers.parquet \\\n    --collection-name \"Genetic Analysis\"\n</code></pre>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#cross-collection-joins","title":"Cross-Collection Joins","text":"<ol> <li>Join Data \u2192 Use common columns to combine datasets</li> <li>Complex Analysis \u2192 Correlate penguin traits with environmental factors</li> <li>Advanced Visualizations \u2192 Multi-dimensional analysis</li> </ol>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#custom-component-types","title":"Custom Component Types","text":"<ul> <li>\ud83d\udcc8 Time Series \u2192 Trend analysis over time</li> <li>\ud83d\uddfa\ufe0f Geographic Maps \u2192 Spatial data visualization  </li> <li>\ud83c\udfaf KPI Dashboards \u2192 Executive summary views</li> <li>\ud83d\udcca Statistical Plots \u2192 Box plots, violin plots, regression lines</li> </ul>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#troubleshooting","title":"\ud83d\udee0\ufe0f Troubleshooting","text":"","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#common-issues","title":"Common Issues","text":"<p>\u274c Components not updating together - \u2705 Ensure all components use the same data collection - \u2705 Check that interactive components target the right columns</p> <p>\u274c Slow performance - \u2705 Limit initial data display (use sampling for large datasets) - \u2705 Use aggregated views for very large tables</p> <p>\u274c Charts not displaying properly - \u2705 Verify column data types (numeric vs categorical) - \u2705 Check for missing values in key columns</p> <p>\u274c Upload errors - \u2705 Ensure CSV has headers in the first row - \u2705 Check file size limits (contact admin for large files)</p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#getting-help","title":"Getting Help","text":"<p>\ud83d\udcda Documentation: docs.depictio.embl.org \ud83d\udcac Community: GitHub Discussions \ud83d\udc1b Bug Reports: GitHub Issues \ud83d\udce7 Direct Support: Open an issue for personalized help  </p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#whats-next","title":"\ud83d\uddfa\ufe0f What's Next?","text":"","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#explore-more-tutorials","title":"Explore More Tutorials","text":"<ul> <li>\ud83d\udd2c Advanced Project Types - Bioinformatics workflow integration</li> <li>\u26a1 Performance Optimization - Handle massive datasets  </li> <li>\ud83c\udfa8 UI Customization - Design beautiful dashboards</li> <li>\ud83d\udcca Table Mastery - Advanced table features</li> </ul>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/create-your-first-dashboard/#join-the-community","title":"Join the Community","text":"<ul> <li>\u2b50 Star the project on GitHub</li> <li>\ud83e\udd1d Contribute features or documentation  </li> <li>\ud83d\udcac Share your dashboards in the community</li> <li>\ud83d\udce2 Provide feedback to shape future development</li> </ul> <p>You've just created your first interactive dashboard! This is the beginning of your journey into powerful, code-free data analysis with Depictio. Every component, every interaction, every insight is now at your fingertips.</p> <p>Thomas Weber January 2025</p>","tags":["tutorial","dashboard","interactive-components","getting-started","beginner"]},{"location":"blog/drafts/infinite-scrolling-tables/","title":"\ud83d\udcca Infinite Scrolling Tables: Handle Millions of Rows Seamlessly","text":"<p>How Depictio's AG Grid infinite scrolling delivers smooth table navigation for massive datasets while maintaining real-time interactivity.</p>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#the-challenge-displaying-millions-of-rows","title":"\ud83c\udfaf The Challenge: Displaying Millions of Rows","text":"<p>Traditional tables break when dealing with genomics datasets containing millions of rows. Loading all data at once causes:</p> <ul> <li>\ud83d\udc0c Browser freezing (DOM becomes unresponsive)</li> <li>\ud83d\udcbe Memory exhaustion (GB of RAM consumed)</li> <li>\ud83d\udeab Poor user experience (infinite loading screens)</li> <li>\u26a1 Lost interactivity (dashboard components stop responding)</li> </ul>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#the-solution-intelligent-infinite-scrolling","title":"\ud83d\udca1 The Solution: Intelligent Infinite Scrolling","text":"<p>Depictio implements AG Grid's infinite row model with intelligent server-side processing that handles unlimited dataset sizes while maintaining real-time dashboard interactivity.</p>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#key-innovation-interactive-aware-pagination","title":"\u26a1 Key Innovation: Interactive-Aware Pagination","text":"<p>Unlike traditional pagination systems, Depictio's infinite scrolling seamlessly integrates with dashboard interactions:</p> <pre><code># User filters dashboard \u2192 Table automatically updates\ndef infinite_scroll_component(request, interactive_values, stored_metadata, local_store, pathname):\n    \"\"\"\n    INFINITE SCROLL CALLBACK WITH INTERACTIVE COMPONENT SUPPORT\n\n    Handles:\n    - Interactive component filtering via iterative_join\n    - AG Grid server-side filtering and sorting  \n    - Efficient pagination for all dataset sizes\n    - Cache invalidation when interactive values change\n    \"\"\"\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#architecture-smart-block-based-loading","title":"\ud83c\udfd7\ufe0f Architecture: Smart Block-Based Loading","text":"","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#block-based-data-fetching","title":"Block-Based Data Fetching","text":"<p>Instead of loading entire tables, Depictio fetches small data blocks on demand:</p> <pre><code># AG Grid infinite row model configuration\nrowModelType=\"infinite\",\ndashGridOptions={\n    \"rowBuffer\": 0,              # No extra buffer rows\n    \"maxBlocksInCache\": 10,      # Keep max 10 blocks in memory\n    \"cacheBlockSize\": 100,       # Each block = 100 rows\n    \"cacheOverflowSize\": 2,      # Allow 2 extra blocks\n    \"infiniteInitialRowCount\": 1000,  # Initial estimate\n    \"pagination\": True,          # Enable pagination controls\n}\n</code></pre> <p>Result: Only 1,000 rows maximum in browser memory, regardless of dataset size.</p>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#server-side-processing-pipeline","title":"Server-Side Processing Pipeline","text":"<p>Each scroll request triggers an optimized server-side pipeline:</p> <pre><code># 1. CACHE INVALIDATION: Detect interactive component changes\ntriggered_by_interactive = ctx.triggered and any(\n    \"interactive-values-store\" in str(trigger[\"prop_id\"]) for trigger in ctx.triggered\n)\n\n# 2. FILTER APPLICATION: Apply dashboard filters first\nif interactive_values:\n    filtered_df = apply_interactive_filters(base_df, interactive_values)\n\n# 3. AG GRID FILTERS: Apply table-specific filters  \nif ag_grid_filter_model:\n    filtered_df = apply_ag_grid_filters(filtered_df, ag_grid_filter_model)\n\n# 4. SORTING: Apply user-requested sorting\nif sort_model:\n    filtered_df = apply_sorting(filtered_df, sort_model)\n\n# 5. PAGINATION: Return only requested block\nstart_row = request[\"startRow\"] \nend_row = request[\"endRow\"]\npage_df = filtered_df.slice(start_row, end_row - start_row)\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#real-time-interactivity-integration","title":"\ud83d\udd04 Real-Time Interactivity Integration","text":"","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#seamless-dashboard-synchronization","title":"Seamless Dashboard Synchronization","text":"<p>When users interact with dashboard controls, the table instantly reflects changes without losing scroll position:</p> <pre><code># Interactive component change detected\nlogger.info(\"\ud83c\udfaf Interactive component changed - invalidating table cache\")\n\n# Cache invalidation ensures fresh data\nif triggered_by_interactive:\n    # Clear cached blocks to force refresh with new filters\n    invalidate_table_cache(table_id)\n\n    # Apply new interactive filters \n    updated_metadata = extract_interactive_metadata(interactive_values)\n    filtered_data = apply_metadata_filters(base_data, updated_metadata)\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#smart-filter-combination","title":"Smart Filter Combination","text":"<p>The system intelligently combines two types of filters:</p> <ol> <li>Dashboard Filters (from interactive components)</li> <li>Table Filters (from AG Grid column filters)</li> </ol> <pre><code>def apply_combined_filters(df, interactive_metadata, ag_grid_filters):\n    \"\"\"\n    Apply both dashboard and table-specific filters efficiently.\n    \"\"\"\n    # First apply dashboard-wide interactive filters\n    if interactive_metadata:\n        df = apply_metadata_filters(df, interactive_metadata)\n\n    # Then apply table-specific AG Grid filters\n    if ag_grid_filters:\n        for column, filter_config in ag_grid_filters.items():\n            df = apply_ag_grid_filter(df, filter_config, column)\n\n    return df\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#performance-optimizations","title":"\ud83d\ude80 Performance Optimizations","text":"","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#1-intelligent-caching-strategy","title":"1. Intelligent Caching Strategy","text":"<pre><code># Multi-level caching for optimal performance\nclass TableCache:\n    def __init__(self):\n        self.base_data_cache = {}      # Full filtered datasets\n        self.block_cache = {}          # Individual data blocks\n        self.metadata_cache = {}       # Filter metadata snapshots\n\n    def get_block(self, table_id, start_row, end_row, filters):\n        cache_key = f\"{table_id}_{start_row}_{end_row}_{hash(filters)}\"\n\n        if cache_key in self.block_cache:\n            return self.block_cache[cache_key]\n\n        # Generate block and cache it\n        block_data = self.generate_block(table_id, start_row, end_row, filters)\n        self.block_cache[cache_key] = block_data\n        return block_data\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#2-optimized-polars-operations","title":"2. Optimized Polars Operations","text":"<pre><code># Efficient column filtering with type safety\ndef apply_ag_grid_filter(df: pl.DataFrame, filter_model: dict, col: str) -&gt; pl.DataFrame:\n    \"\"\"Apply AG Grid filter to Polars DataFrame efficiently.\"\"\"\n\n    filter_type = filter_model[\"type\"]\n\n    if filter_type == \"contains\":\n        return df.filter(pl.col(col).str.contains(filter_model[\"filter\"], literal=False))\n    elif filter_type == \"inRange\":\n        crit1, crit2 = filter_model[\"filter\"], filter_model[\"filterTo\"]\n        return df.filter(pl.col(col).is_between(crit1, crit2))\n    elif filter_type == \"equals\":\n        return df.filter(pl.col(col) == filter_model[\"filter\"])\n    # ... additional filter types\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#3-concurrent-data-processing","title":"3. Concurrent Data Processing","text":"<pre><code># Process multiple data operations concurrently\nasync def process_table_request(request, filters):\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        # Submit concurrent tasks\n        filter_future = executor.submit(apply_filters, base_data, filters)\n        sort_future = executor.submit(apply_sorting, filtered_data, sort_model)\n\n        # Wait for results\n        filtered_data = filter_future.result()\n        sorted_data = sort_future.result()\n\n        return paginate_data(sorted_data, request[\"startRow\"], request[\"endRow\"])\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#real-world-performance-metrics","title":"\ud83d\udcca Real-World Performance Metrics","text":"","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#genomics-dataset-5m-rows-50-columns","title":"Genomics Dataset: 5M Rows \u00d7 50 Columns","text":"<ul> <li>Initial load time: 150ms (first 100 rows)</li> <li>Scroll response time: 45ms average</li> <li>Memory usage: 15MB (browser)</li> <li>Filter update time: 85ms</li> <li>Interactive sync: &lt; 100ms</li> </ul>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#multi-omics-analysis-25m-rows-200-columns","title":"Multi-Omics Analysis: 25M Rows \u00d7 200 Columns","text":"<ul> <li>Initial load time: 200ms (first 100 rows)</li> <li>Scroll response time: 120ms average</li> <li>Memory usage: 18MB (browser)</li> <li>Server memory: 500MB cached</li> <li>Concurrent users: 50+ supported</li> </ul>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#filter-performance-comparison","title":"Filter Performance Comparison","text":"Dataset Size Traditional Table Infinite Scroll Performance Gain 10K rows 200ms 45ms 4.4x faster 100K rows 2.5s 50ms 50x faster 1M rows Browser crash 85ms \u221e improvement 10M rows Not possible 120ms Enables impossible","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#technical-implementation-details","title":"\ud83d\udd27 Technical Implementation Details","text":"","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#ag-grid-configuration","title":"AG Grid Configuration","text":"<pre><code># Optimized infinite scroll configuration\ntable_aggrid = dag.AgGrid(\n    id={\"type\": \"table-component\", \"index\": str(index)},\n    rowModelType=\"infinite\",      # Enable infinite scrolling\n    columnDefs=column_definitions,\n    dashGridOptions={\n        # INFINITE MODEL TUNING\n        \"rowBuffer\": 0,           # Minimal memory footprint\n        \"maxBlocksInCache\": 10,   # Reasonable cache size\n        \"cacheBlockSize\": 100,    # Optimal block size\n        \"cacheOverflowSize\": 2,   # Allow cache overflow\n        \"infiniteInitialRowCount\": 1000,  # Initial row estimate\n\n        # USER EXPERIENCE\n        \"rowSelection\": \"multiple\",\n        \"enableCellTextSelection\": True,\n        \"pagination\": True,\n        \"paginationPageSize\": 100,\n\n        # PERFORMANCE\n        \"suppressScrollOnNewData\": True,\n        \"suppressAnimationFrame\": False,\n    }\n)\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#server-side-response-format","title":"Server-Side Response Format","text":"<pre><code># AG Grid infinite model response structure\ndef create_infinite_response(data_block, total_rows, last_row):\n    return {\n        \"rowData\": data_block.to_dicts(),  # Current page data\n        \"rowCount\": total_rows,            # Total filtered rows\n        \"lastRow\": last_row               # Indicates end of data\n    }\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#cache-management","title":"Cache Management","text":"<pre><code>class InfiniteScrollCache:\n    def __init__(self, max_blocks=50, ttl_seconds=300):\n        self.cache = {}\n        self.timestamps = {}\n        self.max_blocks = max_blocks\n        self.ttl = ttl_seconds\n\n    def get(self, key):\n        if key in self.cache and not self._is_expired(key):\n            self.timestamps[key] = time.time()  # Update access time\n            return self.cache[key]\n        return None\n\n    def set(self, key, value):\n        # Cleanup old entries if cache is full\n        if len(self.cache) &gt;= self.max_blocks:\n            self._evict_oldest()\n\n        self.cache[key] = value\n        self.timestamps[key] = time.time()\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#advanced-features","title":"\ud83c\udfaf Advanced Features","text":"","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#1-smart-row-estimation","title":"1. Smart Row Estimation","text":"<pre><code># Dynamic row count estimation for better UX\ndef estimate_total_rows(df, current_filters):\n    if not current_filters:\n        return len(df)  # No filters = full dataset\n\n    # Sample-based estimation for large datasets\n    sample_size = min(10000, len(df))\n    sample_df = df.sample(sample_size)\n    filtered_sample = apply_filters(sample_df, current_filters)\n\n    # Extrapolate to full dataset\n    filter_ratio = len(filtered_sample) / sample_size\n    return int(len(df) * filter_ratio)\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#2-intelligent-preloading","title":"2. Intelligent Preloading","text":"<pre><code># Preload adjacent blocks for smooth scrolling\ndef preload_adjacent_blocks(current_block, direction=\"down\"):\n    if direction == \"down\":\n        next_start = current_block[\"endRow\"]\n        next_end = next_start + BLOCK_SIZE\n        preload_block(next_start, next_end)\n    else:\n        prev_end = current_block[\"startRow\"] \n        prev_start = max(0, prev_end - BLOCK_SIZE)\n        preload_block(prev_start, prev_end)\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#3-filter-debouncing","title":"3. Filter Debouncing","text":"<pre><code># Prevent excessive filtering requests during typing\n@debounce(delay=300)  # Wait 300ms after user stops typing\ndef apply_text_filter(filter_value, column):\n    return df.filter(pl.col(column).str.contains(filter_value))\n</code></pre>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#user-experience-benefits","title":"\ud83c\udfad User Experience Benefits","text":"","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#seamless-navigation","title":"Seamless Navigation","text":"<ul> <li>\ud83d\ude80 Instant scrolling through millions of rows</li> <li>\ud83d\udd0d Real-time filtering without page reloads</li> <li>\u2195\ufe0f Natural scroll behavior (no pagination clicks)</li> <li>\ud83d\udcca Persistent dashboard sync during table interactions</li> </ul>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#memory-efficiency","title":"Memory Efficiency","text":"<ul> <li>\ud83d\udcbe Minimal browser memory (&lt; 20MB for any table size)</li> <li>\u26a1 Fast device support (works on tablets, older laptops)</li> <li>\ud83d\udd0b Battery friendly (no excessive DOM manipulation)</li> </ul>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#developer-experience","title":"Developer Experience","text":"<ul> <li>\ud83d\udd27 Zero configuration (automatic infinite scrolling)</li> <li>\ud83d\udcc8 Automatic performance optimization</li> <li>\ud83d\udee0\ufe0f Built-in filter integration</li> <li>\ud83d\udcca Real-time debugging info</li> </ul>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/infinite-scrolling-tables/#whats-next","title":"\ud83d\uddfa\ufe0f What's Next?","text":"<p>The infinite scrolling foundation enables future enhancements: - \ud83d\udcca Virtual column rendering (handle 1000+ columns) - \ud83e\udd1d Multi-table synchronization (linked scrolling) - \ud83d\udcf1 Mobile-optimized touch scrolling - \ud83d\udd04 Real-time collaborative table editing</p> <p>Infinite scrolling tables transform how users explore large datasets. By combining intelligent caching, server-side processing, and seamless dashboard integration, Depictio makes million-row tables feel as responsive as small datasets.</p> <p>Thomas Weber January 2025</p>","tags":["infinite-scrolling","ag-grid","performance","tables","large-datasets"]},{"location":"blog/drafts/interactive-metadata-system/","title":"\u26a1 Interactive Metadata System: Real-Time Data Filtering at Scale","text":"<p>How Depictio achieves millisecond-fast dashboard updates with lazy Polars queries, intelligent caching, and S3-direct filtering.</p>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#the-challenge-real-time-filtering-at-scale","title":"\ud83c\udfaf The Challenge: Real-Time Filtering at Scale","text":"<p>Imagine you have a dashboard with 10 components, each displaying different views of a multi-gigabyte genomics dataset. When a user moves a slider or selects a dropdown option, all 10 components must update instantly with filtered data.</p> <p>The challenge: How do you filter terabytes of data and update multiple visualizations in under 200ms?</p>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#the-solution-metadata-driven-lazy-queries","title":"\ud83e\udde0 The Solution: Metadata-Driven Lazy Queries","text":"<p>Depictio solves this with an intelligent metadata system that converts user interactions into optimized Polars queries executed directly on S3-stored Delta Lakes.</p>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#the-magic-single-lazy-query-architecture","title":"\u26a1 The Magic: Single Lazy Query Architecture","text":"<p>Instead of 10 separate database calls, Depictio executes one optimized lazy query that filters the entire dataset:</p> <pre><code># User interactions become metadata\nmetadata = [\n    {\n        \"interactive_component_type\": \"Select\",\n        \"column_name\": \"sample_type\", \n        \"value\": [\"tumor\", \"normal\"]\n    },\n    {\n        \"interactive_component_type\": \"RangeSlider\",\n        \"column_name\": \"expression_level\",\n        \"value\": [2.5, 8.0]\n    }\n]\n\n# Single lazy query filters everything\ndelta_scan = pl.scan_delta(s3_location, storage_options=s3_config)\nfiltered_df = delta_scan.filter(\n    (pl.col(\"sample_type\").cast(pl.String).is_in([\"tumor\", \"normal\"])) &amp;\n    (pl.col(\"expression_level\") &gt;= 2.5) &amp; \n    (pl.col(\"expression_level\") &lt;= 8.0)\n).collect()\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#architecture-from-ui-to-data","title":"\ud83d\udd27 Architecture: From UI to Data","text":"","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#1-interactive-component-metadata-capture","title":"1. Interactive Component Metadata Capture","text":"<p>Every user interaction generates structured metadata:</p> <pre><code># Dropdown selection\n{\n    \"interactive_component_type\": \"Select\",\n    \"column_name\": \"treatment_group\",\n    \"value\": [\"control\", \"treatment_a\"]\n}\n\n# Slider movement  \n{\n    \"interactive_component_type\": \"RangeSlider\", \n    \"column_name\": \"age_years\",\n    \"value\": [25, 65]\n}\n\n# Text search\n{\n    \"interactive_component_type\": \"TextInput\",\n    \"column_name\": \"gene_name\", \n    \"value\": \"BRCA\"\n}\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#2-polars-filter-translation-engine","title":"2. Polars Filter Translation Engine","text":"<p>The metadata gets translated into efficient Polars expressions:</p> <pre><code>def add_filter(filter_list, interactive_component_type, column_name, value, min_value=None, max_value=None):\n    if interactive_component_type in [\"Select\", \"MultiSelect\", \"SegmentedControl\"]:\n        if value:\n            # Ensure value is a list for is_in() function\n            if not isinstance(value, list):\n                value = [value]\n\n            # Cast both column and values to string for compatibility\n            string_values = [str(v) for v in value]\n            filter_list.append(pl.col(column_name).cast(pl.String).is_in(string_values))\n\n    elif interactive_component_type == \"TextInput\":\n        if value:\n            filter_list.append(pl.col(column_name).str.contains(value))\n\n    elif interactive_component_type == \"RangeSlider\":\n        if value:\n            filter_list.append(\n                (pl.col(column_name) &gt;= value[0]) &amp; (pl.col(column_name) &lt;= value[1])\n            )\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#3-intelligent-caching-strategy","title":"3. Intelligent Caching Strategy","text":"<p>Depictio uses adaptive loading with intelligent caching:</p> <pre><code># ADAPTIVE LOADING STRATEGY\nif size_bytes == -1:\n    # UNKNOWN SIZE: Use dynamic estimation approach\n    base_cache_key = f\"{workflow_id}_{data_collection_id}_base\"\n\n    if base_cache_key in _dataframe_memory_cache:\n        # Use cached DataFrame and apply runtime filters\n        cached_df = _dataframe_memory_cache[base_cache_key]\n\n        # Apply metadata filters in memory (very fast)\n        if metadata and not load_for_options:\n            df = apply_runtime_filters(cached_df, metadata)\n        else:\n            df = cached_df\n    else:\n        # Load full DataFrame and cache for future use\n        df = delta_scan.collect()\n        _dataframe_memory_cache[base_cache_key] = df\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#performance-optimization-multi-level-strategy","title":"\ud83d\ude80 Performance Optimization: Multi-Level Strategy","text":"","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#level-1-s3-direct-lazy-scanning","title":"Level 1: S3-Direct Lazy Scanning","text":"<p><pre><code># Scan Delta Lake directly on S3 without downloading\ndelta_scan = pl.scan_delta(file_id, storage_options=polars_s3_config)\n</code></pre> - \u26a1 Zero download time for metadata operations - \ud83c\udf10 Cloud-native filtering - \ud83d\udcca Parquet-optimized predicate pushdown</p>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#level-2-intelligent-memory-caching","title":"Level 2: Intelligent Memory Caching","text":"<pre><code># Cache frequently accessed DataFrames in memory\nif hasattr(df, \"estimated_size\"):\n    actual_size = df.estimated_size(\"b\")\nelse:\n    actual_size = df.height * df.width * 8  # Rough estimation\n\nif actual_size &lt;= MEMORY_CACHE_THRESHOLD:\n    logger.debug(f\"Caching DataFrame in memory (size: {actual_size} bytes)\")\n    _dataframe_memory_cache[base_cache_key] = df\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#level-3-runtime-filter-application","title":"Level 3: Runtime Filter Application","text":"<pre><code>def apply_runtime_filters(df, metadata):\n    \"\"\"Apply filters to an already loaded DataFrame for maximum speed.\"\"\"\n    filter_list = process_metadata_and_filter(metadata)\n\n    if filter_list:\n        # Combine all filters with AND logic\n        combined_filter = filter_list[0]\n        for f in filter_list[1:]:\n            combined_filter = combined_filter &amp; f\n        return df.filter(combined_filter)\n\n    return df\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#real-time-update-flow","title":"\ud83d\udd04 Real-Time Update Flow","text":"<p>Here's what happens when a user interacts with any component:</p>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#step-1-metadata-generation-1ms","title":"Step 1: Metadata Generation (&lt; 1ms)","text":"<pre><code>// User moves slider \u2192 Metadata update\n{\n  component_id: \"slider_age\", \n  column: \"age_years\",\n  type: \"RangeSlider\", \n  value: [30, 60]\n}\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#step-2-filter-translation-5ms","title":"Step 2: Filter Translation (&lt; 5ms)","text":"<pre><code># Metadata \u2192 Polars filter\nfilter_expr = (pl.col(\"age_years\") &gt;= 30) &amp; (pl.col(\"age_years\") &lt;= 60)\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#step-3-data-processing-10-100ms","title":"Step 3: Data Processing (10-100ms)","text":"<pre><code># Single query updates all dashboard components\nif data_in_cache:\n    # Memory filtering (10ms)\n    filtered_df = cached_df.filter(combined_filters)\nelse:\n    # S3 lazy query (50-100ms)  \n    filtered_df = delta_scan.filter(combined_filters).collect()\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#step-4-component-updates-50ms","title":"Step 4: Component Updates (&lt; 50ms)","text":"<p>All dashboard components receive the filtered data simultaneously.</p>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#real-world-performance","title":"\ud83d\udcca Real-World Performance","text":"","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#genomics-pipeline-dashboard","title":"Genomics Pipeline Dashboard","text":"<ul> <li>Dataset: 2.5M rows, 50 columns (~500MB)</li> <li>Components: 8 interactive filters, 12 visualizations</li> <li>Update time: 85ms average</li> <li>Memory usage: 120MB cached</li> </ul>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#multi-omics-analysis","title":"Multi-Omics Analysis","text":"<ul> <li>Dataset: 15M rows, 200 columns (~3.2GB) </li> <li>Components: 15 interactive filters, 20 visualizations</li> <li>Update time: 180ms average </li> <li>Storage: Direct S3 Delta Lake access</li> </ul>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#technical-implementation-details","title":"\ud83d\udee0\ufe0f Technical Implementation Details","text":"","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#s3-compatible-storage-configuration","title":"S3-Compatible Storage Configuration","text":"<pre><code>polars_s3_config = {\n    \"aws_endpoint_url\": os.getenv(\"AWS_ENDPOINT_URL\"),\n    \"aws_access_key_id\": os.getenv(\"AWS_ACCESS_KEY_ID\"),\n    \"aws_secret_access_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n    \"aws_region\": os.getenv(\"AWS_REGION\", \"us-east-1\"),\n    \"aws_allow_http\": os.getenv(\"AWS_ALLOW_HTTP\", \"false\").lower() == \"true\"\n}\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#delta-lake-integration","title":"Delta Lake Integration","text":"<pre><code># Delta Lake provides ACID transactions and time travel\ndelta_scan = pl.scan_delta(\n    file_location,  # S3 path: s3://bucket/dataset.delta\n    storage_options=polars_s3_config,\n    # version=timestamp  # Time travel capabilities\n)\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#concurrent-processing","title":"Concurrent Processing","text":"<pre><code># Process multiple data collections concurrently\nwith concurrent.futures.ThreadPoolExecutor() as executor:\n    futures = []\n    for collection in data_collections:\n        future = executor.submit(load_deltatable_lite, collection, metadata, token)\n        futures.append(future)\n\n    results = [future.result() for future in futures]\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#advanced-features","title":"\ud83d\udd2c Advanced Features","text":"","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#automatic-type-casting","title":"Automatic Type Casting","text":"<pre><code># Handle mixed data types gracefully\ntry:\n    string_values = [str(v) for v in value]\n    filter_list.append(pl.col(column_name).cast(pl.String).is_in(string_values))\nexcept Exception as e:\n    # Fallback to original filter without casting\n    filter_list.append(pl.col(column_name).is_in(value))\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#join-aware-filtering","title":"Join-Aware Filtering","text":"<pre><code># Ensure proper run isolation in joins\nif \"depictio_run_id\" in df1.columns and \"depictio_run_id\" in df2.columns:\n    if \"depictio_run_id\" not in join_columns:\n        join_columns.append(\"depictio_run_id\")\n        logger.debug(\"Added depictio_run_id to join columns for proper run isolation\")\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#memory-management","title":"Memory Management","text":"<pre><code># Adaptive caching with memory limits\nMEMORY_CACHE_THRESHOLD = 100 * 1024 * 1024  # 100MB threshold\nMAX_CACHE_ENTRIES = 50\n\ndef cleanup_old_cache_entries():\n    \"\"\"Remove least recently used cache entries when limit exceeded.\"\"\"\n    if len(_dataframe_memory_cache) &gt; MAX_CACHE_ENTRIES:\n        # Remove oldest entries based on timestamps\n        sorted_entries = sorted(_cache_timestamps.items(), key=lambda x: x[1])\n        for key, _ in sorted_entries[:10]:  # Remove 10 oldest\n            _dataframe_memory_cache.pop(key, None)\n            _cache_timestamps.pop(key, None)\n</code></pre>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#key-benefits","title":"\ud83c\udfaf Key Benefits","text":"","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#for-users","title":"For Users","text":"<ul> <li>\u26a1 Instant feedback (&lt; 200ms updates)</li> <li>\ud83d\udd04 Synchronized dashboards (all components update together)</li> <li>\ud83d\udcca Handle massive datasets (GB to TB scale)</li> <li>\ud83c\udf10 Cloud-native (works with any S3-compatible storage)</li> </ul>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#for-developers","title":"For Developers","text":"<ul> <li>\ud83e\udde0 Simple metadata API (JSON-based interaction tracking)</li> <li>\ud83d\udd27 Polars-powered (efficient column-oriented processing)</li> <li>\ud83d\udcc8 Scalable architecture (memory + cloud storage)</li> <li>\ud83d\udee0\ufe0f Type-safe operations (automatic casting and validation)</li> </ul>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/interactive-metadata-system/#whats-next","title":"\ud83d\uddfa\ufe0f What's Next?","text":"<p>This metadata system enables exciting future capabilities: - \ud83e\udd16 AI-powered query optimization - \ud83d\udcca Predictive data caching - \ud83d\udd04 Real-time collaborative filtering - \ud83d\udcc8 Advanced aggregation patterns</p> <p>The interactive metadata system is the engine that makes Depictio's real-time dashboards possible. By combining lazy evaluation, intelligent caching, and cloud-native storage, we've created a system that scales from kilobytes to terabytes while maintaining sub-second responsiveness.</p> <p>Thomas Weber January 2025</p>","tags":["metadata","polars","interactive-components","performance","lazy-queries","s3"]},{"location":"blog/drafts/ui-major-upgrade/","title":"\ud83d\ude80 UI Major Upgrade: Modernizing Depictio's Interface","text":"<p>How we transformed Depictio's UI with DMC 2.1 upgrade and dynamic grid layout migration - the technical story behind a major UX overhaul.</p>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#why-this-upgrade-was-critical","title":"\ud83c\udfaf Why This Upgrade Was Critical","text":"<p>Building modern dashboards requires modern UI foundations. Our interface was struggling with two major limitations:</p> <ol> <li>\ud83d\udd27 Outdated Component Library: DMC 0.12 was limiting our design possibilities</li> <li>\ud83d\udcd0 Grid Layout Issues: dash-draggable couldn't handle proper vertical component growth</li> </ol> <p>These constraints were holding back the intuitive, responsive experience users expect from a modern data platform.</p>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#challenge-1-dmc-upgrade-012-21","title":"\ud83e\udde9 Challenge #1: DMC Upgrade (0.12 \u2192 2.1)","text":"","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#the-problem","title":"The Problem","text":"<p>Dash Mantine Components (DMC) 0.12 was severely limiting our UI capabilities: - Missing modern components (advanced inputs, layouts) - Inconsistent theming system - Limited styling flexibility - Poor responsive design patterns</p>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#the-solution-major-version-jump","title":"The Solution: Major Version Jump","text":"<p>Upgrading from DMC 0.12 to 2.1 was complex but necessary:</p> <pre><code># Before (DMC 0.12) - Limited component options\ndmc.Button(\n    children=\"Submit\",\n    variant=\"filled\",  # Limited variants\n    color=\"blue\"       # Basic color system\n)\n\n# After (DMC 2.1) - Rich component ecosystem  \ndmc.Button(\n    children=\"Submit\",\n    variant=\"gradient\",         # New gradient variants\n    gradient={\"from\": \"blue\", \"to\": \"purple\"},  \n    leftIcon=DashIconify(icon=\"mdi:upload\"),\n    loading=loading_state,      # Built-in loading states\n    fullWidth=True             # Better responsive options\n)\n</code></pre>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#impact-modern-design-system","title":"Impact: Modern Design System","text":"<p>The upgrade enabled: - \ud83c\udfa8 Advanced theming with CSS custom properties - \ud83d\udcf1 Better responsive components  - \u26a1 Improved performance and bundle size - \ud83d\udd27 New component types (advanced inputs, better layouts)</p>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#challenge-2-grid-layout-migration","title":"\ud83d\udcd0 Challenge #2: Grid Layout Migration","text":"","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#the-problem-dash-draggable-limitations","title":"The Problem: dash-draggable Limitations","text":"<p>Our dashboard grid system had critical vertical growth issues:</p> <pre><code># dash-draggable - Fixed height components\nResponsiveGridLayout(\n    children=components,\n    layouts={\"lg\": [{\"i\": \"0\", \"x\": 0, \"y\": 0, \"w\": 6, \"h\": 4}]},\n    # Components couldn't grow vertically properly\n)\n</code></pre> <p>Components were trapped in fixed heights, creating poor user experiences when: - Plots needed more vertical space - Tables had many rows - Text components required different sizes</p>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#the-solution-dash-dynamic-grid-layout","title":"The Solution: dash-dynamic-grid-layout","text":"<p>We migrated to <code>dash-dynamic-grid-layout</code> with smart vertical growth:</p> <pre><code># dash-dynamic-grid-layout - Dynamic vertical growth\ndgl.DashGridLayout(\n    items=wrapped_components,     # New component wrapping system\n    itemLayout=single_layout,     # Simplified layout structure\n    rowHeight=10,                # Flexible 10px units\n    enableVerticalGrowth=True,   # Key feature!\n    showRemoveButton=edit_mode,  # Connected to edit mode\n    showResizeHandles=edit_mode  # Contextual UI controls\n)\n</code></pre>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#technical-implementation-vertical-growth-system","title":"Technical Implementation: Vertical Growth System","text":"<p>The migration required sophisticated CSS injection for proper flexbox behavior:</p> <pre><code>// Dynamic CSS injection for component flexibility\nconst style = document.createElement('style');\nstyle.textContent = `\n    .react-grid-item {\n        display: flex !important;\n        flex-direction: column !important;\n    }\n    .react-grid-item &gt; div {\n        height: 100% !important;\n        width: 100% !important;\n        display: flex !important;\n        flex-direction: column !important;\n    }\n    .js-plotly-plot {\n        flex-grow: 1 !important;\n        height: 100% !important;\n    }\n`;\n</code></pre>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#component-wrapping-system","title":"Component Wrapping System","text":"<p>Every component now gets intelligently wrapped for proper grid behavior:</p> <pre><code>def wrap_component_in_draggable_wrapper(component, component_id, component_type=\"component\"):\n    \"\"\"\n    Wrap a component in DraggableWrapper for dynamic grid layout.\n    \"\"\"\n    wrapped_content = html.Div(\n        component,\n        style={\n            \"height\": \"100%\",\n            \"width\": \"100%\", \n            \"display\": \"flex\",\n            \"flex-direction\": \"column\",\n            \"box-sizing\": \"border-box\",\n        },\n    )\n\n    return dgl.DraggableWrapper(\n        wrapped_content,\n        id=component_id,\n        handleText=f\"Drag {component_type.title()}\",\n    )\n</code></pre>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#ux-revolution-transparent-edit-mode","title":"\ud83c\udfa8 UX Revolution: \"Transparent\" Edit Mode","text":"","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#before-confusing-edit-interface","title":"Before: Confusing Edit Interface","text":"<ul> <li>Edit buttons always visible (cluttered interface)</li> <li>No clear distinction between view/edit modes</li> <li>Users confused about when they could modify components</li> </ul>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#after-contextual-transparent-design","title":"After: Contextual, Transparent Design","text":"<p>\ud83d\udd04 Edit Mode Toggle: Clean switch in the header offcanvas</p> <pre><code># Connected edit mode to grid system\n@app.callback(\n    [\n        Output(\"draggable-wrapper\", \"showRemoveButton\"),\n        Output(\"draggable-wrapper\", \"showResizeHandles\")\n    ],\n    Input(\"edit-mode-switch\", \"checked\")\n)\ndef toggle_edit_mode(edit_enabled):\n    return edit_enabled, edit_enabled\n</code></pre> <p>\ud83c\udfaf Contextual Component Buttons:  - Reset button (appears on hover for filtered components) - Justify text (for text components only) - Edit button (when component supports configuration) - Remove button (only in edit mode)</p>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#performance-technical-benefits","title":"\u26a1 Performance &amp; Technical Benefits","text":"","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#grid-layout-performance","title":"Grid Layout Performance","text":"<ul> <li>\ud83c\udfc3 Faster rendering: More efficient React Grid Layout algorithm</li> <li>\ud83d\udccf Better positioning: Improved component placement logic</li> <li>\ud83d\udd04 Smoother interactions: Optimized drag &amp; resize operations</li> </ul>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#component-system-improvements","title":"Component System Improvements","text":"<ul> <li>\ud83c\udfaf Sequential IDs: Clean (0, 1, 2, 3...) component identification</li> <li>\ud83d\udd17 Backward compatibility: Existing layouts still work</li> <li>\ud83d\udee0\ufe0f Type safety: All code passes <code>ruff</code> and <code>tycheck</code></li> </ul>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#dynamic-graph-resizing","title":"Dynamic Graph Resizing","text":"<p>Real-time graph adaptation to container changes:</p> <pre><code>// Clientside callback for dynamic graph resizing  \nfunction(layout) {\n    if (layout &amp;&amp; layout.length &gt; 0) {\n        setTimeout(function() {\n            layout.forEach(function(layoutItem) {\n                const gridItem = document.querySelector('[data-grid=\"' + layoutItem.i + '\"]');\n                if (gridItem) {\n                    const newHeight = Math.max(layoutItem.h * 10 - 20, 150);\n                    const graphElements = gridItem.querySelectorAll('.js-plotly-plot');\n                    graphElements.forEach(function(graphElement) {\n                        if (window.Plotly) {\n                            window.Plotly.relayout(graphElement, {\n                                height: newHeight - 40,\n                                autosize: true\n                            });\n                        }\n                    });\n                }\n            });\n        }, 100);\n    }\n}\n</code></pre>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#results-transformed-user-experience","title":"\ud83c\udfaf Results: Transformed User Experience","text":"","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#before-vs-after","title":"Before vs After","text":"Aspect Before (DMC 0.12 + dash-draggable) After (DMC 2.1 + dash-dynamic-grid-layout) Vertical Growth \u274c Fixed component heights \u2705 Dynamic vertical expansion Edit Mode \u274c Always-visible clutter \u2705 Clean, contextual controls Components \u274c Limited design options \u2705 Modern component library Responsiveness \u274c Poor mobile experience \u2705 Fully responsive design Performance \u274c Slower interactions \u2705 Smooth, optimized UX","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#user-feedback-impact","title":"User Feedback Impact","text":"<ul> <li>\ud83d\udcc8 Improved usability: Users can resize components naturally</li> <li>\ud83c\udfa8 Modern aesthetics: Professional, clean interface</li> <li>\u26a1 Better performance: Faster dashboard interactions  </li> <li>\ud83d\udcf1 Mobile ready: Responsive design across devices</li> </ul>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#technical-migration-process","title":"\ud83d\udd27 Technical Migration Process","text":"","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#1-component-library-upgrade","title":"1. Component Library Upgrade","text":"<pre><code># Package updates\npip install dash-mantine-components==2.1.0\npip uninstall dash-draggable  \npip install dash-dynamic-grid-layout\n</code></pre>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#2-code-refactoring","title":"2. Code Refactoring","text":"<ul> <li>Updated imports across 15+ files</li> <li>Converted layout structures from responsive to single layout</li> <li>Added CSS injection for vertical growth</li> <li>Implemented component wrapping system</li> </ul>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#3-testing-validation","title":"3. Testing &amp; Validation","text":"<ul> <li>\u2705 All existing functionality preserved</li> <li>\u2705 Backward compatibility maintained</li> <li>\u2705 Performance improvements verified</li> <li>\u2705 Cross-browser testing completed</li> </ul>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#whats-next","title":"\ud83d\uddfa\ufe0f What's Next?","text":"<p>This foundation enables exciting future features: - \ud83e\udde9 Advanced component templates - \ud83d\udcf1 Mobile-first dashboard editing - \ud83c\udfa8 Custom theme builder - \u26a1 Real-time collaborative editing</p>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/drafts/ui-major-upgrade/#technical-resources","title":"\ud83d\udd17 Technical Resources","text":"<ul> <li>Grid Migration Details: Check our technical documentation</li> <li>DMC 2.1 Guide: Component upgrade patterns</li> <li>Source Code: Grid layout implementation</li> </ul> <p>This upgrade represents months of careful engineering to modernize Depictio's foundation while maintaining all existing functionality. Every line of code was refactored with backward compatibility in mind.</p> <p>Thomas Weber January 2025</p>","tags":["upgrade","dmc","grid-layout","user-interface","modernization"]},{"location":"blog/depictio-goes-live-/","title":"Depictio goes live !","text":"<p>Depictio is now live with a public demo!</p> <p>A longer demo is also available in Dashboard Creation Guide.</p>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#what-is-depictio","title":"\ud83c\udfaf What is Depictio?","text":"<p>Depictio is an open-source, modern, web-based platform that aims to help life-science researchers and bioinformaticians to analyse complex data generated out of high-throughput experiments into interactive, shareable dashboards without requiring programming skills.</p>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#why-depictio-and-how-does-it-differ-from-other-tools-eg-shiny-dash-streamlit-gradio-etc","title":"\u2753 Why Depictio and how does it differ from other tools (e.g., Shiny, Dash, Streamlit, Gradio, etc.)?","text":"<p>In bioinformatics, core facilities and research groups generating large datasets are relying on highly standardised workflows (e.g., nf-core pipelines) that produce structured outputs. These datasets require interactive exploration and visualization tools, helpful for quality control issues identification, as well as deriving actionable insights.</p> <p>While there are multiple popular dashboarding solutions amongts bioinformaticians like Shiny, Dash, Streamlit, Gradio, they require programming skills and time to design tailored systems. This includes multiple steps, from the data ingestion to the data visualisation, as well as hosting and maintaining platforms in a production environment.</p> <p>Depictio aims to fill this gap by providing a comprehensive platform composed of a cloud-compatible microservices architecture and a companion CLI tool (depictio-cli) living close to the data. The system provides a no-code dashboard creation experience that allows researchers to focus on data analysis.</p>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#wait-but-where-is-the-life-science-focus-in-this","title":"\ud83e\udd28 Wait, but where is the life science focus in this ?","text":"<p>While the current version of Depictio is a general-purpose dashboarding tool (open-source alternative to Plotly Studio), the next phase (Q3-Q4 2025) is to have a strong focus towards life sciences domain-specific features.</p> <p>On the frontend, this means bringing in specialized components (like JBrowse2 for genome visualization) and bioinformatics heavily used visualizations (like volcano plots, heatmaps, etc.) that are tailored for life science data.</p> <p>On the backend and data ingestion side, our plan is to focus on developing seamless integration of MultiQC reports (gold standard in bioinformatics QC reporting) and to develop workflows templates for popular bioinformatics pipelines (like nf-core) to make it easy to aggregate, visualize and analyze aggregated results.</p> <p>In the end, the idea would be to provide a comprehensive platform that allows life science researchers to easily create interactive dashboards using community-driven templates for established workflows.</p> <p>In the spirit of MultiQC's automated data discovery for gold-standard bioinformatics QC tools (cutadapt, fastqc, ...) using <code>multiqc .</code> in a terminal, you would be able to run <code>depictio --template nf-core/rnaseq .</code> to automatically ingest workflow relevant data and fill a dashboard with pre-configured components for visualizing the results of a RNA-seq analysis conducted with nf-core/rnaseq pipeline.</p>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#who-is-it-for","title":"\ud83d\udc65 Who is it for?","text":"<p>Current users:</p> <ul> <li>Researchers and data scientists seeking code-free dashboard creation</li> <li>Anyone working with datasets who wants interactive exploration tools</li> </ul> <p>Future target audience:</p> <ul> <li>Life science researchers analyzing high-throughput experimental data</li> <li>Bioinformaticians working with standardised pipeline outputs and multi-omics datasets</li> </ul>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#main-current-features","title":"\ud83c\udfa8 Main current features","text":"<ul> <li>No-code dashboard creation: Build interactive dashboards without writing code</li> <li>Real-time interactivity: Play with your data using sliders, dropdowns, as well as box selection on scatter plots</li> <li>Multi-data sources support: Combine multiple data sources (so-called Data Collections in Depictio) in a single dashboard using SQL-like joining system</li> <li>Authenticated or Unauthenticated Access: Use the system with JWT-based authentication and Google Oauth or in unauthenticated mode (like the demo)</li> <li>Docker-compose &amp; Kubernetes ready: Easy deployment options for production use</li> <li>Companion CLI (depictio-cli): Command-line interface for managing projects, scan data, and upload datasets</li> </ul>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#modern-architecture","title":"\ud83d\udee0\ufe0f Modern Architecture","text":"<p>Depictio is built on a state-of-the-art microservices architecture combining modern technologies for optimal performance, scalability, and developer experience. The system provides a comprehensive platform for interactive data visualization and analysis.</p> <ul> <li> <p> Frontend Technologies</p> <p>Plotly Dash (React-based) interactive interface with Mantine UI components</p> </li> <li> <p> Asynchronous Backend</p> <p>High-performance async FastAPI backend with Python for real-time updates</p> </li> <li> <p> Metadata Storage</p> <p>MongoDB for project metadata, configurations, and user management</p> </li> <li> <p> Data Storage</p> <p>Delta Lake for optimized data storage and time-travel capabilities</p> </li> <li> <p> Object Storage</p> <p>MinIO S3-compatible storage for scalable file management</p> </li> <li> <p> Data Processing</p> <p>Polars engine for high-performance data manipulation and Delta Lake storage</p> </li> <li> <p> Authentication</p> <p>JWT-based authentication with Google OAuth integration</p> </li> <li> <p> DevOps &amp; Deployment</p> <p>Docker and Kubernetes support for cloud-native infrastructure</p> </li> </ul>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#architecture-overview","title":"Architecture Overview","text":"<p>The system is designed with a clear separation of concerns:</p> <ul> <li>\ud83c\udfa8 Frontend Layer: React-based dashboard interface with Plotly visualizations and Mantine UI components</li> <li>\u2699\ufe0f API Layer: FastAPI backend handling authentication, data operations, and real-time updates  </li> <li>\ud83d\udcbe Data Layer: MongoDB for metadata, Delta Lake for analytics data, MinIO for object storage</li> <li>\ud83d\ude80 Processing Engine: Polars for high-performance data manipulation and analysis</li> <li>\ud83d\udd27 CLI Tool: <code>depictio-cli</code> for project management, data scanning, and automated workflows</li> </ul>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#who-is-behind-depictio","title":"\ud83d\udc65 Who is behind Depictio?","text":"<p>Depictio is an open-source and academic project initiated by Thomas Weber, Research Fellow at the European Molecular Biology Laboratory (EMBL) during his ARISE fellowship (Marie Sk\u0142odowska-Curie Actions ; grant agreement No 945405). The project is primarily supported by the EMBL Data Science Centre with additional contributions from the SciLifeLab Data Centre.</p>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#who-is-currently-using-depictio","title":"\ud83d\udd2c Who is currently using Depictio?","text":"<p>Depictio is currently being used by EMBL researchers and data scientists across different life science fields. Some specific use cases include:</p> <ul> <li>Strand-seq biobank (Korbel group, EMBL Heidelberg): Single-cell DNA sequencing to study Structural Variants (SVs) in human genomes. Pipeline used: mosaicatcher-pipeline</li> <li>Marine microbiome interactome study (Vincent group, TREC, EMBL Heidelberg): Marine microbiome analysis using single-cell amplicon sequencing. Pipeline used: nf-core/ampliseq</li> </ul>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#how-to-try-it-out","title":"\ud83d\ude80 How to Try It Out","text":"<p>Access the live demo at demo.depictio.embl.org or start using it below directly and explore the features. You can also create your own project and upload datasets to start dashboarding. Don't forget to check out the guides for step-by-step instructions on how to use the system.</p> <p>Note</p> <p>The demo is running a \"unauthenticated mode\" to allow anyone to try it out without needing an account. However, you can create a temporary account to create your own projects and upload datasets. Accounts and related data will be reset after 1 hour to keep the demo environment clean.</p> Live interactive demo - Try it! Live Demo <p>Your browser does not support iframes. Click here to view the Depictio dashboard</p>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#what-you-can-do-in-the-demo","title":"\ud83c\udfae What You Can Do in the Demo","text":"","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#1-explore-pre-loaded-demo-datasets","title":"1. Explore Pre-loaded Demo Datasets ..","text":"<ul> <li>Iris and Palmer Penguins datasets for quick visualization (Palmer penguins was turned into a sequencing runs-like dataset to showcase the system)</li> </ul>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#2-or-upload-your-own-data","title":"2. .. or Upload Your Own Data","text":"<ul> <li>Create your own project and upload datasets in your favorite tabular format (CSV, Parquet, etc.)</li> </ul>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#3-create-interactive-dashboards","title":"3. Create Interactive Dashboards","text":"<ul> <li>Figures: Scatter plots, bar charts, histograms, ...</li> <li>Tables: Sortable, filterable data tables</li> <li>Metrics Cards: Key performance indicators</li> <li>Interactive Components: Sliders, dropdowns, segmented controls, and more</li> </ul>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#4-experience-real-time-interactivity","title":"4. Experience Real-time Interactivity","text":"<ul> <li>Use box selection on scatter plots</li> <li>Apply multiple filters simultaneously</li> <li>Reset filters with a single click</li> </ul>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#whats-next","title":"\ud83d\uddfa\ufe0f What's Next?","text":"<p>Get a look at our roadmap to see what we're working on next:</p> <ul> <li>Support MultiQC Integration - Seamless quality control workflows</li> <li>JBrowse2 Integration - Interactive genome browser for genomic data</li> <li>TUI (Terminal User Interface) for project creation - Create project configuration using UI on the terminal</li> <li>Workflow Templates - Pre-configured dashboards for popular pipelines like nf-core</li> </ul>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/depictio-goes-live-/#join-our-community-and-contribute","title":"\ud83e\udd1d Join Our Community and Contribute","text":"<p>Depictio is open-source and community-driven. We welcome contributions, feedback, and ideas to make it better!</p> <ul> <li>\ud83d\udc19 GitHub: github.com/depictio/depictio</li> <li>\ud83d\udcac Discussions: Share feedback and ask questions</li> <li>\ud83d\udc1b Issues: Report bugs or request features</li> <li>\u2b50 Star us: Help spread the word!</li> </ul> <p>Questions? Feedback? We'd love to hear from you! Open an issue on GitHub or reach out directly.</p> <p>Thomas Weber August 2025</p>","tags":["dashboard","visualization","demo","bioinformatics","launch"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/","title":"\ud83d\udcca Depictio Project Types: Choose Your Data Strategy","text":"<p>From simple CSV files to complex bioinformatics pipelines - discover which project type fits your needs.</p> <p>\ud83c\udfac Projects Management Overview: Discover how Depictio's project types organize your data workflow - from simple file uploads to complex bioinformatics pipelines</p>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#general-features-of-depictio-projects","title":"General features of Depictio Projects","text":"<p>Projects are designed to help you organize your data and structure your analysis, corresponding to the top-level entity in Depictio. Each project can contain multiple workflows and data collections (advanced type), which are essentially groups of related data files relevant to your analysis. User can then create interactive dashboards out of these data collections, allowing for flexible and powerful data visualization.</p> <p>Generic features of Depictio projects include:</p> <ul> <li>Data Organization: Projects help you structure your data, making it easier to manage and analyze.</li> <li>Workflow Integration (advanced): Projects can be linked to specific workflows, allowing you to track and manage your data processing pipelines.</li> <li>Interactive Dashboards: Create visualizations and dashboards based on the data within your projects.</li> <li>Role Management: Control access to projects, related data and resulting dashboards through user roles and permissions. Each user can be either : Owner, Editor, or Viewer of a project.</li> </ul>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#two-approaches-a-large-number-of-possibilities","title":"\ud83c\udfaf Two Approaches, a large number of possibilities","text":"<p>Depictio offers two distinct project types designed for different data scenarios. Think of them as different answers for organizing your data - each optimized for specific use cases.</p> <p>Whether you're looking for a plotly studio like experience for immediate analysis of a tabular dataset, or a bioinformatician managing complex pipeline outputs, choosing the right project type sets the foundation for effective data exploration.</p>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#basic-projects-your-gateway-to-interactive-dashboards","title":"\ud83c\udfe0 Basic Projects: Your Gateway to Interactive Dashboards","text":"<p>Perfect for: Direct data analysis</p> <p>Basic projects are designed for users who want to quickly visualize and explore tabular data without the overhead of complex configurations. They are ideal for one-off analyses or exploratory data visualization.</p>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#main-features-of-basic-projects","title":"Main Features of Basic Projects","text":"<ul> <li>Start Quickly - Upload files and start visualizing within minutes</li> <li>Minimal configuration required - Works with any tabular data format</li> <li>Perfect for exploration - Ideal when you want to \"see what the data tells you\"</li> </ul> <p>\ud83c\udfac Basic Project Creation: Watch how to create a basic project from scratch - upload data, configure settings, and start visualizing in minutes</p>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#advanced-projects-suited-for-bioinformatics-workflows","title":"\ud83e\uddec Advanced Projects: Suited for Bioinformatics Workflows","text":"<p>Perfect for: Standardised workflows outputs, multi-sample studies</p> <p>Advanced projects are tailored for bioinformatics workflows executed in core facilities-like setup. Users can discover and organize files generated by complex pipelines like nf-core, Snakemake, or Nextflow in a structured, centralized manner in order to create interactive dashboards that aggregate data across multiple samples, timepoints, or experimental conditions.</p>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#main-features-of-advanced-projects-compared-to-basic-projects","title":"Main Features of Advanced Projects compared to Basic Projects","text":"<ul> <li>Sequencing run data organisation compatible - Automatically finds and organizes files based on naming conventions and directory structures, perfect for core facilities managing recurrent sequencing projects relying on standardized processing pipelines.</li> <li>Multi-sample analysis - Handles large datasets with hundreds of samples, automatically aggregating results across multiple runs or timepoints.</li> <li>Combine multiple data collections - Joins different data types (e.g., gene expression, variant calls) into unified dashboards. Ingest data without modifying the original data files at the workflow level by doing post-processing in Depictio.</li> </ul>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#quick-decision-guide","title":"\ud83d\udccb Quick Decision Guide","text":"","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#choose-basic-when","title":"Choose Basic when:","text":"<p>\u2705 You have limited number of files ready to analyze (CSV, Excel, Parquet) \u2705 One-time analysis or ad-hoc exploration \u2705 Manual data preparation is acceptable \u2705 Quick insights are the primary goal  </p>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#choose-advanced-when","title":"Choose Advanced when:","text":"<p>\u2705 Automated pipeline generates your data (nf-core, Snakemake, etc.) \u2705 Standardized file organization and naming conventions exist \u2705 You need to aggregate data across multiple samples or runs \u2705 Regular data updates are expected</p>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#getting-started-paths","title":"\ud83c\udfed Getting Started Paths","text":"","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#basic-project-quickstart","title":"Basic Project Quickstart","text":"<p>Through the Web Interface:</p> <ol> <li>Visit demo.depictio.embl.org</li> <li>Click \"Create Project\" \u2192 Choose \"Basic\" and fill in project details</li> <li>Travels to your newly created project and click \"Create Data Collection\"</li> <li>Fill in details and upload your tabular file as data collection</li> <li>Go to the \"Dashboards\" tab</li> <li>Start creating dashboard components corresponding to your project</li> </ol> <p>Common File Formats Supported:</p> <ul> <li>CSV files (most common) &amp; TSV files (tab-separated values)</li> <li>Excel spreadsheets (.xlsx, .xls)  </li> <li>Parquet files (efficient for large datasets)</li> <li>Feather files (.feather)</li> </ul>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#advanced-project-quickstart","title":"Advanced Project Quickstart","text":"<p>Project Structure Setup: Advanced projects require a YAML configuration file that describes your data organization patterns. This tells Depictio how to automatically discover and organize your files.</p> <p>Example Study Structure:</p> <pre><code>study_directory/\n\u251c\u2500\u2500 depictio_project.yaml    # Depictio configuration\n\u251c\u2500\u2500 run_001/                 # First batch of samples - run 001\n\u2502   \u251c\u2500\u2500 sample_A/\n\u2502   \u2502   \u251c\u2500\u2500 stats/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 sample_A_stats.tsv # Statistics for sample A\n\u2502   \u2502   \u2514\u2500\u2500 analysis_results/\n\u2502   \u2502       \u2514\u2500\u2500 sample_A_analysis.tsv # Analysis results for sample A\n\u2502   \u2514\u2500\u2500 sample_B/\n\u2502       \u251c\u2500\u2500 stats/\n\u2502       \u2502   \u2514\u2500\u2500 sample_B_stats.tsv # Statistics for sample B\n\u2502       \u2514\u2500\u2500 analysis_results/\n\u2502           \u2514\u2500\u2500 sample_B_analysis.tsv\n\u2514\u2500\u2500 run_002/                 # Second batch of samples - run 002\n    \u251c\u2500\u2500 sample_C/\n    \u2502   \u251c\u2500\u2500 stats/\n    \u2502   \u2502   \u2514\u2500\u2500 sample_C_stats.tsv\n    \u2502   \u2514\u2500\u2500 analysis_results/\n    \u2502       \u2514\u2500\u2500 sample_C_analysis.tsv\n    \u2514\u2500\u2500 sample_D/\n        \u251c\u2500\u2500 stats/\n        \u2502   \u2514\u2500\u2500 sample_D_stats.tsv\n        \u2514\u2500\u2500 analysis_results/\n            \u2514\u2500\u2500 sample_D_analysis.tsv\n</code></pre> <p>The configuration file below describes patterns for finding and organizing these files automatically.</p> <p>Example depictio_project.yaml:</p> <pre><code># =============================================================================\n# DEPICTIO PROJECT CONFIGURATION\n# Complete configuration for the study structure shown above\n# =============================================================================\n\n\n# Project identification - displayed in Depictio web interface\nname: \"My Bioinformatics Study\"\n\n# Description of the project\ndescription: \"A comprehensive study of multiple samples with detailed statistics and analysis results\"\n\n# Project type\n# This is an advanced project with structured data discovery\ntype: \"advanced\"\n\n# Data management platform project URL\n# Optional: link to external project management system\ndata_management_platform_project_url: \"https://example.com/project/my-bioinformatics-study\"\n\n# Public/private visibility\n# Set to true if you want this project to be publicly accessible\nis_public: false\n\n# =============================================================================\n# WORKFLOW DEFINITIONS\n# Define the pipelines that generated your data\n# =============================================================================\nworkflows:\n  - name: \"bioinformatics_pipeline\"\n\n    # Engine that executed the workflow\n    engine:\n      name: \"nextflow\"           # Workflow management system used\n      version: \"24.10.3\"         # Version for reproducibility\n\n    description: \"Multi-sample bioinformatics analysis pipeline\"\n    version: \"3.1\"               # Your pipeline version\n\n    # =============================================================================\n    # DATA DISCOVERY CONFIGURATION  \n    # Tell Depictio where to find your data and how it's organized\n    # =============================================================================\n    config:\n      # Where your workflow output directories are located\n      parent_runs_location:\n        # Environment variables (like {DATA_LOCATION}) are resolved at runtime\n        # This allows flexible deployment across different systems\n        - \"{DATA_LOCATION}/study_directory\"\n\n      # Regular expression to identify run directories\n      # \"run_.*\" matches: run_001, run_002, run_abc, etc.\n      runs_regex: \"run_.*\"\n\n      # =============================================================================\n      # DATA COLLECTIONS\n      # Define the different types of data files to be ingested\n      # =============================================================================\n      data_collections:\n\n        # COLLECTION 1: Sample Statistics\n        # ========================================\n        - data_collection_tag: \"sample_stats\"\n          description: \"Statistics for each sample\"\n\n          config:\n            # Table = tabular data (CSV, TSV, Excel, etc.)\n            # Futur Alternative: JBrowse2, GeoJSON, etc.\n            type: \"Table\"\n\n            # Aggregate = combine multiple files into one dataset\n            # Alternative: Metadata = single file per run\n            metatype: \"Aggregate\"\n\n            # File discovery settings\n            scan:\n              # recursive = search through subdirectories\n              # single = look for one specific file per run\n              mode: \"recursive\"\n\n              scan_parameters:\n                regex_config:\n                  # Find all files matching this pattern within each run directory\n                  # Example matches: run_001/sample_A/stats/sample_A_stats.tsv\n                  #                 run_001/sample_B/stats/sample_B_stats.tsv\n                  pattern: \"stats/.*_stats.tsv\"\n\n            # Data processing configuration specific to type Table\n            dc_specific_properties:\n              format: \"TSV\"        # Tab-separated values\n\n              # Polars DataFrame configuration (high-performance data processing)\n              polars_kwargs:\n                separator: \"\\t\"    # Tab separator\n                has_header: true   # First row contains column names\n                # Other options: skip_rows, column_types, etc.\n\n              # Only keep these columns (improves performance and reduces memory)\n              keep_columns:\n                - \"sample_id\"      # Links samples across datasets\n                - \"total_reads\"    # Sequencing depth metric\n                - \"mapped_reads\"   # Alignment quality metric  \n                - \"quality_score\"  # Overall sample quality\n\n              # Human-readable descriptions for dashboard tooltips\n              columns_description:\n                sample_id: \"Unique sample identifier\"\n                total_reads: \"Total number of sequencing reads\"\n                mapped_reads: \"Successfully aligned reads\" \n                quality_score: \"Overall sample quality metric\"\n\n        # COLLECTION 2: Analysis Results  \n        # ========================================\n        - data_collection_tag: \"analysis_results\"\n          description: \"Analysis results for each sample\"\n\n          config:\n            type: \"Table\"\n            metatype: \"Aggregate\"\n\n            scan:\n              mode: \"recursive\"\n              scan_parameters:\n                regex_config:\n                  # Find analysis result files in each sample directory\n                  # Example: run_001/sample_A/analysis_results/sample_A_analysis.tsv\n                  pattern: \"analysis_results/.*_analysis.tsv\"\n\n            dc_specific_properties:\n              format: \"TSV\"\n              polars_kwargs:\n                separator: \"\\t\"\n                has_header: true\n\n              keep_columns:\n                - \"sample_id\"        # Join key for linking datasets\n                - \"gene_expression\"  # Expression analysis results\n                - \"variant_count\"    # Variant calling results\n                - \"pathway_enrichment\"  # Functional analysis results\n\n          # =============================================================================\n          # DATA JOINING\n          # Combine this collection with others for integrated analysis\n          # =============================================================================\n          join:\n            # Columns used to match records between datasets\n            on_columns:\n              - \"sample_id\"        # Common identifier across collections\n\n            # Type of join (inner = only samples present in both datasets)\n            # Options: inner, left, right, outer\n            how: \"inner\"\n\n            # Other collections to join with\n            with_dc:\n              - \"sample_stats\"     # Combine analysis with quality metrics\n</code></pre>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#technical-deep-dive","title":"\ud83d\udd27 Technical Deep Dive","text":"","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#cli-workflow-commands","title":"CLI Workflow Commands","text":"<p>Once you have your configuration file, use the CLI to process your project:</p> <pre><code># Complete workflow: validate \u2192 sync \u2192 scan \u2192 process\ndepictio-cli run --project-config-path ./bioinfoinformatics_project.yaml\n</code></pre> <p>This single command handles the entire pipeline automatically. For detailed CLI usage and individual step commands, see the CLI documentation.</p>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#data-processing-pipeline-using-depictio-cli","title":"Data Processing Pipeline using <code>depictio-cli</code>","text":"<p>Using the <code>run</code> command, the CLI executes this pipeline for advanced projects:</p> <ol> <li>\u2705 Server Check - Verify connection to Depictio backend</li> <li>\u2705 S3 Storage Check - Validate cloud storage configuration  </li> <li>\u2705 Config Validation - Ensure YAML structure is correct</li> <li>\u2705 Config Sync - Register project with server</li> <li>\u2705 File Scan - Discover files matching patterns</li> <li>\u2705 Data Process - Convert files to Delta Lake format for dashboarding</li> </ol> <p>Each step can be skipped with flags like <code>--skip-scan</code> or <code>--skip-process</code> for debugging.</p> <p>\ud83c\udfac \ud83d\udda5\ufe0f `depictio-cli run` command example</p>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#file-discovery-patterns","title":"File Discovery Patterns","text":"<p>Depictio supports two main scanning modes that adapt to different data organization structures:</p> <p>Single File Collection:</p> <p>This is usually suitable for metadata files or summary statistics that are generated once at the project level.</p> <pre><code>scan:\n  mode: \"single\" \n  scan_parameters:\n    filename: \"multiqc_data/multiqc_general_stats.txt\"\n</code></pre> <p>Finds one specific file per run directory. This is adapted for cases where you have a single summary file per sample or run.</p> <p>Recursive File Collection:</p> <pre><code>scan:\n  mode: \"recursive\"\n  scan_parameters:\n    regex_config:\n      pattern: \"star_salmon/.*/quant.sf\"\n</code></pre> <p>Uses regex patterns to find files at any depth in the directory structure.</p>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#project-types-comparison","title":"\ud83d\udcca Project Types Comparison","text":"<p>Choosing the right project type is crucial for your data analysis success. Here's a comprehensive comparison to help you decide:</p> Feature Basic Projects Advanced Projects Setup Complexity Minimal - Web UI or CLI CLI with YAML config required Data Compatibility Simple tabular data (CSV, Excel) Complex bioinformatics workflows Multi-sample Support Limited to single datasets Designed for hundreds of samples Data Processing Direct conversion to Delta table Aggregation &amp; joining capabilities Best For Quick analysis Production workflows, core facilities Learning Curve Immediate - no learning required Moderate - requires YAML reference knowledge Scalability Small to medium datasets Large-scale, multi-run studies","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#key-takeaway","title":"\ud83d\udca1 Key Takeaway","text":"<p>Basic Projects excel at getting you from data to insights quickly, perfect for exploratory analysis and presentations. Advanced Projects are useful when you need systematic, reproducible data management for complex, multi-sample studies with standardized workflows.</p> <p>Both project types deliver the same rich, interactive dashboard experience - the difference lies in how your data is processed and gets ingested by the system.</p>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"blog/-depictio-project-types-choose-your-data-strategy/#whats-next","title":"\ud83d\uddfa\ufe0f What's Next?","text":"<p>Now that you understand project types, you're ready to create your first interactive dashboard:</p> <ul> <li>\ud83c\udfa8 Create Your First Dashboard - Step-by-step tutorial</li> <li>\ud83d\udcca CLI Usage Guide - Complete command documentation</li> <li>\ud83d\udd27 Advanced Configuration - Multi-collection joins, custom workflows</li> </ul> <p>Thomas Weber August 2025</p>","tags":["basics","projects","project-types","bioinformatics","data-management"]},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v031","title":"v0.3.1","text":""},{"location":"changelog/#docker-images","title":"Docker Images","text":"<pre><code>ghcr.io/depictio/depictio:0.3.1\nghcr.io/depictio/depictio:latest\nghcr.io/depictio/depictio:stable\nghcr.io/depictio/depictio:edge\n</code></pre>"},{"location":"changelog/#bug-fixes","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Helm Chart &amp; Deployment: Adjusted resource limits and logging verbosity for backend services. Ensured proper permissions for frontend mounted directories and fixed authentication defaults in values.yaml. (1ddc1d5e, 47214581, e574a013)</li> <li>Data Integrity: Ensured depictio_run_id is included in joins for proper run isolation and normalized column data types in precompute_columns_specs function. (e21ef1eb, f5ce756d)</li> </ul>"},{"location":"changelog/#improvements","title":"\ud83d\ude80 Improvements","text":"<ul> <li>Code Cleanliness &amp; Consistency: Standardized import statements across multiple files and removed unused imports. (0349df19, 53b6b467)</li> <li>Testing: Implemented robust typing commands for improved input reliability in tests. (f85a98e4)</li> </ul>"},{"location":"changelog/#chores","title":"\ud83e\uddf9 Chores","text":"<ul> <li>Logging: Enhanced logging in API calls and data collection processing functions. (0d662764)</li> <li>UMAP: Disabled UMAP visualization temporarily. (593ad1dd)</li> </ul>"},{"location":"changelog/#v030","title":"v0.3.0","text":""},{"location":"changelog/#docker-images_1","title":"Docker Images","text":"<pre><code>ghcr.io/depictio/depictio:0.3.0\nghcr.io/depictio/depictio:latest\nghcr.io/depictio/depictio:stable\nghcr.io/depictio/depictio:edge\n</code></pre>"},{"location":"changelog/#major-features","title":"\u2728 Major Features","text":"<ul> <li>Enhanced Data Management: Optimized DataFrame loading with lazy scanning and adaptive memory management. Implemented total storage size calculation and progress indicators for data collections. (a308c300, 8afcdf2e, bfcb6fd8)</li> <li>Comprehensive Project &amp; Data Collection Management: Introduced new modal-based UI to manage workflows and data collection per project. Added features for creating, updating, deleting, and viewing data collections and projects. (b9cb4727, 78b93457, fb06d84e)</li> </ul>"},{"location":"changelog/#bug-fixes_1","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Temp users data handling: Improved error handling for temporary user cleanup. (1253e8a6, 6fd41333)</li> <li>Figures &amp; Components Logic: Added validation to prevent df reassignment in user code. Fix \u201cEdit mode\u201d for figure components. Enhanced figure generation to allow editing existing figures even with auto-generation disabled. (318c7ae9, 48f91115)</li> <li>UI &amp; Layout: Corrected project update logic and improved modal ID handling. (f6b68c73, 93d72bba)</li> </ul>"},{"location":"changelog/#improvements_1","title":"\ud83d\ude80 Improvements","text":"<ul> <li>CLI &amp; Theming Enhancements: Added customizable ASCII logo display for the CLI. Implemented theme-aware color handling for card and interactive components. (63a0e62f, 7d5957f0, 1c201684)</li> </ul>"},{"location":"changelog/#v021","title":"v0.2.1","text":""},{"location":"changelog/#docker-images_2","title":"Docker Images","text":"<pre><code>ghcr.io/depictio/depictio:0.2.1\nghcr.io/depictio/depictio:latest\nghcr.io/depictio/depictio:stable\nghcr.io/depictio/depictio:edge\n</code></pre>"},{"location":"changelog/#features","title":"\u2728 Features","text":"<ul> <li>Theming &amp; Components: Plotly templates were updated to 'mantine_light' and 'mantine_dark'. AG Grid and text components now have theme-aware styling. (04e4069e, 97e6c0f5)</li> <li>Interactivity &amp; Access: Interactive components can now restore saved configurations and values. Added EMBL-specific security contexts for unauthenticated mode. (892de076, 08a6e311, db18d84f)</li> </ul>"},{"location":"changelog/#bug-fixes_2","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Security &amp; Stability: Addressed security vulnerabilities by updating seccompProfile. Fixed an UnboundLocalError and ensured metadata store indices are consistent. (1b18d95a, e828952a, 5a550856)</li> <li>Layout &amp; Visuals: Resolved footer positioning issues and adjusted default component dimensions for better layout consistency. (f245982e, 2e16fdb9)</li> <li>Visuals: Updated logo images in the README for improved visibility in both light and dark modes. (ca46ddc1)</li> </ul>"},{"location":"changelog/#improvements_2","title":"\ud83d\ude80 Improvements","text":"<ul> <li>Code Refactoring: Simplified input handling in save and text component callbacks. (8937bea3)</li> </ul>"},{"location":"changelog/#chores_1","title":"\ud83e\uddf9 Chores","text":"<ul> <li>Logging: Refactored logging in various modules to reduce verbosity. (322c80c1)</li> <li>Version: Bumped the project version from 0.2.0 to 0.2.1. (8cd1e0e2)</li> </ul>"},{"location":"changelog/#v020","title":"v0.2.0","text":""},{"location":"changelog/#docker-images_3","title":"Docker Images","text":"<pre><code>ghcr.io/depictio/depictio:0.2.0\nghcr.io/depictio/depictio:latest\nghcr.io/depictio/depictio:stable\nghcr.io/depictio/depictio:edge\n</code></pre>"},{"location":"changelog/#major-features_1","title":"\u2728 Major Features","text":"<ul> <li>UI Theming &amp; UX: Fully functional dark/light theme (68af2cc0, b085b89b). Switched from dash-draggable to dash-dynamic-react-grid (aacea638). Revised UX with improved component buttons layout. Implemented progressive loading over dashboard restore + logo animation (e40ba587, d8d696d2).</li> <li>Figure component: UI mode completely revised &gt; switching from documentation parsing to function signature inspection and organisation into pydantic models. New code mode allowing user to write/port existing code with RestrictedPython providing code filtering and restricted execution environment to limit dangerous operations. (691a2678, b5c229b2)</li> <li>Table component: Infinite scrolling and pagination for the table component (99f8e5a2, 5466aa76).</li> <li>Text component: Inline editable text components (using markdown headers style) with adjustable positioning (justify). (2b2d267a, 114f713e, 59c8fc80)</li> <li>Card component: improved styling &amp; provide trend information to show difference compare to non filtered data (increase/decrease) (9f2ab88c, 6d51e3af)</li> <li>Interactive component: switched every component to DMC. Implemented scale (log/linear) + number of marks for slider &amp; rangeslider components. (c73f4204, 9f2ab88c, 7f99958f)</li> <li>Notes &amp; documentation footer: notes taking using dmc.RichTextEditor (markdown style, links, bullet points, code blocks \u2026) with fullscreen mode and responsive layout. (d226f52b, 3af94fd3, b06eb2ee, f245982e)</li> <li>Buttons: Reset button functionality and visibility logic for interactive components (583aa04f, 166a2af1, 52684721, 8e5ef9cc).</li> </ul>"},{"location":"changelog/#bug-fixes_3","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Component &amp; UI Fixes:</li> <li>Resolved circular reference issues in the dashboard context and fixed AG Grid popup visibility (2b9e64c9, f5bf946d).</li> <li>Addressed layout issues for Accordion components on the projects page and improved styles for draggable components in dark mode (d8907eae, 6c9febbf).</li> <li>Authentication &amp; CI: Fixed Google OAuth configuration and routes, and addressed CI issues related to authentication (19396605, 78dbc295).</li> <li>Cypress Tests: Updated header element selectors and improved modal visibility checks in Cypress tests (b17fb7bb).</li> </ul>"},{"location":"changelog/#improvements_3","title":"\ud83d\ude80 Improvements","text":"<ul> <li>Dash Component Refactoring: Refactored Dash components to use updated props and styling conventions, ensuring compatibility with Dash v3 and Dash Mantine 2.0+ (8ed8f068, a7a0e3bb).</li> <li>Code &amp; Styling Refactoring: Improved overall code structure for enhanced readability and maintainability, and refactored auth modal styles for better appearance (3ff3e54d, 7ed7c995).</li> </ul>"},{"location":"changelog/#chores_2","title":"Chores \ud83e\uddf9","text":"<ul> <li>Dependencies: Added SVG format for logos (9a9ceb9f).</li> <li>Pre-commit: Improved pre-commit hooks for code quality enforcement (75cb3058).</li> </ul>"},{"location":"changelog/#v011","title":"v0.1.1","text":""},{"location":"changelog/#docker-images_4","title":"Docker Images","text":"<pre><code>ghcr.io/depictio/depictio:0.1.1\nghcr.io/depictio/depictio:latest\nghcr.io/depictio/depictio:stable\nghcr.io/depictio/depictio:edge\n</code></pre>"},{"location":"changelog/#major-features_2","title":"\u2728 Major Features","text":"<ul> <li>UI Theming: Implemented functional dark/light modes with auto-theming, including progress on Plotly figures, dashboard button visibility, and projects section theming (a851f175, d6d83410).</li> </ul>"},{"location":"changelog/#bug-fixes_4","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Cypress Tests: Updated header element selectors and improved modal visibility checks in Cypress tests (b17fb7bb).</li> <li>Authentication: Removed unused expiry_minutes parameters from user upgrade API calls and fixed CI issues related to authentication (b9c5241f, 78dbc295).</li> <li>CLI Configuration: Resolved inconsistencies in CLI configuration field names and updated mock configurations for tests (ce91c581, 846fd4c1).</li> </ul>"},{"location":"changelog/#improvements_4","title":"\ud83d\ude80 Improvements","text":"<ul> <li>Dash Components: Refactored Dash components to use updated props and styling conventions, ensuring compatibility with Dash v3 and Dash Mantine 2.0+ (8ed8f068, a7a0e3bb).</li> <li>Code Structure: Improved overall code structure for enhanced readability and maintainability across various modules (3ff3e54d, 89e62ec9).</li> </ul>"},{"location":"changelog/#chores_3","title":"\ud83e\uddf9Chores","text":"<ul> <li>Pre-commit: Initialized pre-commit hooks for code quality enforcement (75cb3058).</li> </ul>"},{"location":"changelog/#v010","title":"v0.1.0","text":""},{"location":"changelog/#docker-images_5","title":"Docker Images","text":"<pre><code>ghcr.io/depictio/depictio:0.1.0\nghcr.io/depictio/depictio:latest\nghcr.io/depictio/depictio:stable\nghcr.io/depictio/depictio:edge\n</code></pre>"},{"location":"changelog/#major-features_3","title":"\u2728 Major Features","text":"<ul> <li> <p>Backup &amp; Restore: Implemented a comprehensive S3 backup and restore strategy manager, including CLI commands and endpoints for seamless integration (92ce14ff, c126e407).</p> </li> <li> <p>Unauthenticated Mode &amp; Temporary Users: Added full support for an unauthenticated mode with automatic anonymous login and temporary user creation for defined time, including session management, upgrade options, and automated creation and cleanup features  (38ff59d7, 6caf2863, 7622d11f, a5d70429).</p> </li> <li>Google OAuth: Implemented Google OAuth authentication endpoints and updated related configurations (a07364cb, 19396605).</li> </ul>"},{"location":"changelog/#bug-fixes_5","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>Screenshot Generation: Resolved screenshot endpoint authentication and CI timeout issues, and simplified screenshot generation tests (faecb4ec, 98598ee5).</li> </ul>"},{"location":"changelog/#improvements_5","title":"\ud83d\ude80 Improvements","text":"<ul> <li>Performance &amp; Caching: Implemented caching for iterative joins, component data, workflows, and data collection specs to significantly enhance performance (78a7704a, cc7d7dbe).</li> <li>E2E Tests: Enhanced Cypress tests with improved Chrome configuration and reliability, including better login handling and dashboard navigation (dba2e3e3, ca9fac6c).</li> <li>Code Structure: Refactored the code structure across multiple modules for improved readability and maintainability (3f1f1b9b, dfeaf1f6).</li> <li>Type checking: Implemented type checking with <code>ty</code> for better code quality and consistency.</li> <li>Logging: Reduced logging verbosity across various modules for improved log management and clarity (edd44b51, 4e408f36).</li> </ul>"},{"location":"changelog/#chores_4","title":"\ud83e\uddf9Chores","text":"<ul> <li>Changelog &amp; CI: Updated changelog generation, fixed release DNS issues in Helm CI, and added a CODEOWNERS file (dd019370).</li> </ul>"},{"location":"changelog/#v006","title":"v0.0.6","text":"<pre><code>ghcr.io/depictio/depictio:0.0.6\nghcr.io/depictio/depictio:latest\nghcr.io/depictio/depictio:stable\nghcr.io/depictio/depictio:edge\n</code></pre> <p>This release focuses on significant enhancements across Authentication, User Management, and Security, making the application more robust and secure. Key improvements include refresh token, fix issues related to outdated tokens and provide a consolidated CI workflows for the CLI.</p>"},{"location":"changelog/#features-improvements","title":"\u2728 Features &amp; Improvements","text":"<ul> <li>Authentication: Implemented refresh token support across token management, enhancing security and user session persistence (6a198be9, ae25380f).</li> <li>User Management: Updated the user creation process to allow optional user IDs and group parameters, and improved user existence checks (66d6aec9).</li> <li>Security: Added a Flask security assessment scanner for comprehensive application security checks (caa5476c).</li> </ul>"},{"location":"changelog/#cli-highlights","title":"\u2328\ufe0f CLI Highlights","text":"<ul> <li>CI/CD: Consolidated CI workflows by adding test, lint, build, and publish steps for depictio-cli (83abfc65).</li> <li>Project Structure: Updated CI workflows and initial CLI structure, removing setup.py and adjusting pyproject.toml for dependencies (2915d3d2).</li> <li>Packaging: Fixed package directory mapping and license format in pyproject.toml (9147327f, af37c922).</li> </ul>"},{"location":"changelog/#gitpod-dev-environment-highlights","title":"\ud83d\udcbb Gitpod &amp; Dev Environment Highlights","text":"<ul> <li>Setup: Added and enhanced Gitpod workspace setup, including zsh, starship configuration, and Docker permissions (e47b0c27, a1e50c03).</li> <li>Configuration: Made backend and MinIO ports visible in Gitpod configuration for easier access during development (d091cfc6).</li> <li>Environment: Updated environment configuration for Gitpod setup and adjusted logging verbosity for a cleaner development experience (6b74b5f2).</li> </ul>"},{"location":"changelog/#testing-ci-highlights","title":"\ud83e\uddea Testing &amp; CI Highlights","text":"<ul> <li>Connectivity: Enhanced inter-service connectivity tests with readiness checks and improved error handling (ea147c59).</li> <li>Release Process: Enhanced release name generation in CI to ensure DNS compliance (86d5feaf).</li> <li>Issue Templates: Improved issue templates for bug reports and feature requests to streamline contributions (a0fa5096).</li> </ul>"},{"location":"changelog/#docker-helm-highlights","title":"\ud83d\udc33 Docker &amp; Helm Highlights","text":"<ul> <li>Gunicorn: Fixed a single-worker issue with Gunicorn and optimized timeouts (16d3a92d).</li> <li>Helm: Updated public URLs in ConfigMaps and improved MongoDB connection logic and MinIO configuration in Helm charts (b93ee6cf, dce087f8).</li> <li>Helm: Fixed an issue with backend service name in the ConfigMap to enable screenshot generation (965ca53b).</li> </ul>"},{"location":"changelog/#v005","title":"v0.0.5","text":""},{"location":"changelog/#docker-images_6","title":"Docker Images","text":"<pre><code>ghcr.io/depictio/depictio:0.0.5\nghcr.io/depictio/depictio:latest\nghcr.io/depictio/depictio:stable\nghcr.io/depictio/depictio:edge\n</code></pre> <p>This version brings substantial updates to S3 &amp; Services configuration, streamlining data handling and external service integration. Notable progress has also been made in CLI execution logic and Docker build workflows, alongside critical Helm chart improvements.</p>"},{"location":"changelog/#setup-configuration-highlights","title":"\u2699\ufe0f Setup &amp; Configuration Highlights","text":"<ul> <li>S3 &amp; Services: Enhanced S3 configuration handling, logging, and URL management for better integration between internal and external services (54fec27c, 49ded59c, 5eb17f50).</li> <li>Data: Added the Palmer Penguins dataset to test and validate the sequencing-runs ingestion pipeline (0b7b1845).</li> <li>Environment: Added a step to generate the .env file from an example in deployment workflows to ensure consistency (f5ad8f11).</li> </ul>"},{"location":"changelog/#cli-highlights_1","title":"\u2328\ufe0f CLI Highlights","text":"<ul> <li>CI/CD: Added a dedicated GitHub Actions workflow for testing, linting, and building the depictio-cli package (46503f33).</li> <li>Execution: Refactored the scan/processing logic to improve logging and implemented a run function for a full, end-to-end execution of all steps (c3335e41).</li> <li>Commands: Added run and standalone commands, improved logging, and updated command documentation (0bad4848, b3d6a8a9).</li> </ul>"},{"location":"changelog/#docker-highlights","title":"\ud83d\udc33 Docker Highlights","text":"<ul> <li>CI/CD: Enhanced the Docker build workflow with improved security, better output management, and service health checks (e684982b, bb65a818).</li> <li>Configuration: Corrected the path for admin_config.yaml in the Docker copy command (77d3c4ee).</li> </ul>"},{"location":"changelog/#testing-ci-highlights_1","title":"\ud83e\uddea Testing &amp; CI Highlights","text":"<ul> <li>CI/CD Workflow Refactoring: Refactored the main deployment workflow by splitting it into smaller, more manageable CI jobs with enhanced logging (1d605c88, e8f1bbf2).</li> <li>Integration Tests: Enhanced the Iris dataset integration test with verification checks for project, deltatable, and dashboard creation (9a8a6b00).</li> <li>Test Environment: Added and refined test fixtures to properly set the DEPICTIO_CONTEXT environment variable for tests (cb64d183, 596395e6).</li> </ul>"},{"location":"changelog/#helm-highlights","title":"\u2388 Helm Highlights","text":"<ul> <li>CI/CD: Added a dedicated GitHub Actions workflow for testing, building, and pushing the Helm chart (4c965fa6).</li> <li>Configuration: Improved service port variables, initContainers, MongoDB connection logic, and MinIO configuration (959ee2e9, dce087f8).</li> <li>Storage: Added persistent volume claims for keys and adjusted default storage sizes for various components (fc0926ac, cd1de3f8).</li> <li>Ingress: Enhanced the ingress configuration with default annotations, timeout settings, and correct service hostnames (4d75fb17, 770d8e5d).</li> </ul>"},{"location":"changelog/#v004","title":"v0.0.4","text":"<p>Generating changelog from dev to v0.0.4</p>"},{"location":"changelog/#docker-images_7","title":"Docker Images","text":"<pre><code>ghcr.io/depictio/depictio:0.0.4\nghcr.io/depictio/depictio:latest\nghcr.io/depictio/depictio:stable\nghcr.io/depictio/depictio:edge\n</code></pre> <p>This release introduces a first version of project-level permissions and user management features, enhancing access control for collaboration. Major UI/UX improvements and a fundamental backend refactoring to a project-centric architecture also define this version.</p>"},{"location":"changelog/#features-improvements_1","title":"\u2728 Features &amp; Improvements","text":"<ul> <li>Permissions &amp; User Management: Introduced initial project-level permissions management, user and group management features, including endpoints and UI modals for creation, deletion, and management (d17f3690, 10af7623).</li> <li>Authentication &amp; API: Added SAML integration, API calls for token management, password editing, user registration, and improved API key validation (47e9cd43, 7b9f5437).</li> <li>Dashboarding: Enhanced dashboard public/private toggles, edit functionality, and project-specific handling, including screenshot capturing (532e9b7c, 9c192bd0).</li> </ul>"},{"location":"changelog/#ui-ux-highlights","title":"\ud83c\udfa8 UI &amp; UX Highlights","text":"<ul> <li>Modals &amp; Components: Introduced new UI components like password editing modals and stylish modals for dashboard/item creation and deletion confirmations (767908fc, 50e510b8).</li> <li>Layout &amp; Styling: Improved the layout and styling across the application, notably for project items and admin management sections, with added branding favicons (c66f4d87, 6f70d027).</li> </ul>"},{"location":"changelog/#setup-configuration","title":"\u2699\ufe0f Setup &amp; Configuration","text":"<ul> <li>Environment &amp; Logging: Refined environment variable handling and implemented centralized logging initialization (a835bb16, 2f20b67c).</li> <li>Database &amp; Storage: Enhanced MongoDB connection handling and initial project/user creation during database initialization, alongside MinIO configuration (93e3d610, cd9fa0b9).</li> </ul>"},{"location":"changelog/#docker-dev-environment-highlights","title":"\ud83d\udc33 Docker &amp; Dev Environment Highlights","text":"<ul> <li>Docker Workflows &amp; Builds: Refactored Docker workflows, enhanced environment variables, and added support for AMD64/ARM64 builds (d052856e, e0139c67).</li> <li>Devcontainer Configurations: Enhanced Gitpod and devcontainer configurations to streamline local development setup (2ae702cc).</li> </ul>"},{"location":"changelog/#testing-ci-highlights_2","title":"\ud83e\uddea Testing &amp; CI Highlights","text":"<ul> <li>GitHub Actions Workflows: Added comprehensive GitHub Actions workflows for automated release creation, changelog generation, and Docker image builds (74536b3d, 76544d7c).</li> <li>End-to-End &amp; Unit Tests: Implemented extensive end-to-end tests for user authentication and dashboard management, and comprehensive unit tests for various modules (72550ffa, df44475b).</li> </ul>"},{"location":"changelog/#beanie-implementation","title":"\ud83e\uddf1 Beanie Implementation","text":"<ul> <li>User &amp; Group Management: Implemented FastAPI user and group management with Beanie ODM, including helpers for user and group creation (6470af84).</li> <li>Testing &amp; Model Integration: Added Beanie setup for various tests and updated model references for consistent integration (ec008e0f).</li> </ul>"},{"location":"changelog/#code-refactoring","title":"\u267b\ufe0f Code Refactoring","text":"<ul> <li>Code Organization &amp; Clarity: Performed refactoring of import statements, code organization, and whitespace across numerous files (f8b0f913, 239ad86e).</li> <li>API &amp; Data Models: Refactored API and data models to use depictio-models as a centralized library and updated dependencies to Pydantic v2 (2170ae17, e8397589).</li> </ul>"},{"location":"changelog/#bug-fixes_6","title":"\ud83d\udc1b Bug Fixes","text":"<ul> <li>CI/CD &amp; Deployment: Corrected workflow triggers and addressed various Docker and Helm deployment issues, including volume paths and logging (14539146, a376bf98).</li> <li>Data &amp; Configuration Paths: Corrected various file paths, IDs, and configurations for consistency and relative access (a835bb16, 214659e3).</li> <li>User &amp; Authentication: Addressed issues with user fetching functions, replacing deprecated calls and ensuring proper asynchronous execution (f334386c, 725c3d98).</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<p>Full documentation: https://depictio.github.io/depictio-docs/</p>"},{"location":"changelog/#v003","title":"v0.0.3","text":""},{"location":"changelog/#bug-fixes_7","title":"Bug Fixes","text":"<ul> <li>Component size were modified to reflect better size on the dashboard</li> </ul>"},{"location":"changelog/#features_1","title":"Features","text":"<ul> <li>Edit component (goes to design part (step 3 of component creation))</li> <li>Display/hide component options</li> <li>Component options to dmc.ActionIcon (smaller icons without text)</li> <li>Reset all filters button</li> <li>Change offcanvas sidebar layout</li> <li>Admin view (list dashboards)</li> <li>Graph interaction (click, select data through \"Box select\")</li> <li>Reset graph interaction (via dedicated button)</li> <li>Public/private dashboard (public dashboards are visible but not editable by all users ; possibility to copy public dashboard to private personal dashboard)</li> </ul>"},{"location":"changelog/#v002","title":"v0.0.2","text":""},{"location":"changelog/#bug-fixes_8","title":"Bug Fixes","text":"<ul> <li>Switch from dashboard &amp; component ID increment to UUID</li> <li>Fix double click on add component button</li> </ul>"},{"location":"changelog/#features_2","title":"Features","text":"<ul> <li>Autosave dashboard</li> <li>Duplicate dashboard</li> <li>Edit dashboard name</li> <li>Admin view (list users)</li> </ul>"},{"location":"changelog/#v001","title":"v0.0.1","text":""},{"location":"changelog/#features_3","title":"Features","text":"<ul> <li>Initial release of the project</li> <li>Support for creating dashboards with multiple components (figure, metrics card, interactive &amp; table)</li> <li>Drag &amp; layout components on the dashboard</li> <li>Delete components</li> </ul>"},{"location":"depictio-cli/minimal_config/","title":"Minimal Reference Configuration","text":"<p>Warning</p> <p>This is not recommended to copy and paste the configuration as is. The configuration is meant to be a example and should be modified to fit your specific use case.</p> <p>This is a minimal reference configuration example file for the Depictio CLI. It includes the minimum required options and their descriptions. You can use this as a template to create your own configuration file.</p> <pre><code>name: \"Example project\"\n# Workflows section\nworkflows:\n  - name: \"example_workflow\"\n    engine:\n      name: \"python\"\n    config:\n      parent_runs_location:\n        - \"/home/user/data/example_workflow\"\n      runs_regex: \".*\"\n    # Data collections section\n    data_collections:\n      - data_collection_tag: \"example_data_collection\"\n        config:\n          type: \"Table\"\n          metatype: \"Aggregate\"\n          scan:\n            mode: recursive\n            scan_parameters:\n              regex_config:\n                pattern: \"*.stats.tsv\"\n          dc_specific_properties:\n            format: \"TSV\"\n            polars_kwargs:\n              separator: \"\\t\"\n</code></pre>"},{"location":"depictio-cli/usage/","title":"Depictio CLI Usage","text":"<p>Note about the CLI</p> <p>The depictio-cli is a command line interface that allows you to interact with the Depictio backend. It is used to register projects information including workflow files metadata. The depictio-cli is currently in development and is not yet ready for production use.</p>"},{"location":"depictio-cli/usage/#table-of-contents","title":"\ud83d\udcda Table of Contents","text":"<ul> <li>Installation</li> <li>Quick Reference</li> <li>Global Options</li> <li>\ud83d\ude80 Commands<ul> <li>\ud83c\udfc3 Run Command</li> <li>\ud83d\udccb Config Commands</li> <li>\ud83d\udcca Data Commands</li> <li>\ud83d\udcbe Backup Commands</li> </ul> </li> <li>\ud83d\udee0\ufe0f Common Use Cases</li> <li>\ud83d\udd27 Error Handling</li> </ul>"},{"location":"depictio-cli/usage/#installation","title":"Installation","text":"<p>See the installation guide for instructions on how to install the depictio-cli.</p>"},{"location":"depictio-cli/usage/#quick-reference","title":"Quick Reference","text":"Command Description Access Level <code>version</code> Show CLI version All users <code>run</code> Execute complete workflow All users <code>config show-cli-config</code> Display CLI configuration All users <code>config check-s3-storage</code> Validate S3 storage setup All users <code>config check-server-accessibility</code> Test server connection All users <code>config validate-project-config</code> Validate project configuration All users <code>config sync-project-config-to-server</code> Sync project config to server All users <code>data scan</code> Scan project files All users <code>data process</code> Process data collections All users <code>backup backup</code> Create system backup Admin only <code>backup restore</code> Restore from backup Admin only <code>backup list-backups</code> List available backups Admin only"},{"location":"depictio-cli/usage/#global-options","title":"Global Options","text":"Option Short Type Default Description <code>--verbose</code> <code>-v</code> <code>boolean</code> <code>false</code> Enable verbose logging <code>--verbose-level</code> <code>-vl</code> <code>string</code> <code>\"INFO\"</code> Set verbose logging level"},{"location":"depictio-cli/usage/#commands","title":"\ud83d\ude80 Commands","text":""},{"location":"depictio-cli/usage/#run-command","title":"\ud83c\udfc3 Run Command","text":"<p>\ud83c\udfac \ud83d\udda5\ufe0f `depictio-cli run` command example</p> <p>Execute the complete Depictio workflow: validate \u2192 sync \u2192 scan \u2192 process</p> <pre><code>depictio-cli run [OPTIONS]\n</code></pre> <p>Quick Start:</p> <pre><code>depictio-cli run --project-config-path ./config.yaml\n</code></pre> <p>Pipeline Steps:</p> <ol> <li>\u2705 Check server accessibility</li> <li>\u2705 Check S3 storage configuration</li> <li>\u2705 Validate project configuration</li> <li>\u2705 Sync project configuration to server</li> <li>\u2705 Scan data files</li> <li>\u2705 Process data collections</li> </ol> \ud83d\udccb Basic Configuration Parameter Type Default Description <code>--CLI-config-path</code> <code>string</code> <code>~/.depictio/CLI.yaml</code> CLI configuration file path <code>--project-config-path</code> <code>string</code> <code>\"\"</code> Pipeline configuration file path <code>--workflow-name</code> <code>string</code> <code>null</code> Specific workflow to process <code>--data-collection-tag</code> <code>string</code> <code>null</code> Data collection tag to process \u2699\ufe0f Flow Control Options Parameter Type Default Description <code>--skip-server-check</code> <code>boolean</code> <code>false</code> Skip server accessibility check <code>--skip-s3-check</code> <code>boolean</code> <code>false</code> Skip S3 storage validation <code>--skip-sync</code> <code>boolean</code> <code>false</code> Skip config sync to server <code>--skip-scan</code> <code>boolean</code> <code>false</code> Skip data scanning step <code>--skip-process</code> <code>boolean</code> <code>false</code> Skip data processing step \ud83d\udd04 Sync &amp; Scan Options Parameter Type Default Description <code>--update-config</code> <code>boolean</code> <code>false</code> Update project configuration on server <code>--rescan-folders</code> <code>boolean</code> <code>false</code> Reprocess all runs for data collection <code>--sync-files</code> <code>boolean</code> <code>false</code> Update files for data collection <code>--overwrite</code> <code>boolean</code> <code>false</code> Overwrite workflow if it already exists \ud83d\udda5\ufe0f Output &amp; Control Parameter Type Default Description <code>--rich-tables</code> <code>boolean</code> <code>false</code> Show detailed execution summary <code>--continue-on-error</code> <code>boolean</code> <code>false</code> Continue execution on step failure <code>--dry-run</code> <code>boolean</code> <code>false</code> Show execution plan without running <p>Examples:</p> Basic Usage <pre><code># Complete workflow execution\ndepictio-cli run --project-config-path ./config.yaml\n</code></pre> Development <pre><code># With detailed output and error handling\ndepictio-cli run \\\n  --project-config-path ./config.yaml \\\n  --continue-on-error \\\n  --rich-tables\n</code></pre> Dry Run <pre><code># Preview execution without running\ndepictio-cli run \\\n  --project-config-path ./config.yaml \\\n  --dry-run\n</code></pre> Skip Steps <pre><code># Skip server checks for faster execution\ndepictio-cli run \\\n  --project-config-path ./config.yaml \\\n  --skip-server-check \\\n  --skip-s3-check\n</code></pre>"},{"location":"depictio-cli/usage/#config-commands","title":"\ud83d\udccb Config Commands","text":"<p>Command Group: <code>depictio-cli config</code></p> <p>All commands in this section are part of the <code>config</code> command family. Use them to manage Depictio configurations and validate connections.</p> <p>Manage Depictio configurations and validate connections.</p>"},{"location":"depictio-cli/usage/#config-show-cli-config","title":"<code>config show-cli-config</code>","text":"<p>Display the current CLI configuration.</p> <pre><code>depictio-cli config show-cli-config [OPTIONS]\n</code></pre> Parameter Type Default Description <code>--CLI-config-path</code> <code>string</code> <code>~/.depictio/CLI.yaml</code> CLI configuration file path <pre><code>depictio-cli config show-cli-config\n</code></pre>"},{"location":"depictio-cli/usage/#config-check-s3-storage","title":"<code>config check-s3-storage</code>","text":"<p>Validate S3 storage configuration.</p> <pre><code>depictio-cli config check-s3-storage [OPTIONS]\n</code></pre> Parameter Type Default Description <code>--CLI-config-path</code> <code>string</code> <code>~/.depictio/CLI.yaml</code> CLI configuration file path <pre><code>depictio-cli config check-s3-storage\n</code></pre>"},{"location":"depictio-cli/usage/#config-check-server-accessibility","title":"<code>config check-server-accessibility</code>","text":"<p>Test connection to Depictio server.</p> <pre><code>depictio-cli config check-server-accessibility [OPTIONS]\n</code></pre> Parameter Type Default Description <code>--CLI-config-path</code> <code>string</code> <code>~/.depictio/CLI.yaml</code> CLI configuration file path <pre><code>depictio-cli config check-server-accessibility\n</code></pre>"},{"location":"depictio-cli/usage/#config-show-depictio-project-metadata-on-server","title":"<code>config show-depictio-project-metadata-on-server</code>","text":"<p>Display metadata for registered projects.</p> <pre><code>depictio-cli config show-depictio-project-metadata-on-server [OPTIONS]\n</code></pre> Parameter Type Default Description <code>--CLI-config-path</code> <code>string</code> <code>~/.depictio/CLI.yaml</code> CLI configuration file path <code>--project-name</code> <code>string</code> <code>\"\"</code> Specific project name <pre><code>depictio-cli config show-depictio-project-metadata-on-server --project-name my-project\n</code></pre>"},{"location":"depictio-cli/usage/#config-validate-project-config","title":"<code>config validate-project-config</code>","text":"<p>Validate project configuration file.</p> <pre><code>depictio-cli config validate-project-config [OPTIONS]\n</code></pre> Parameter Type Default Description <code>--CLI-config-path</code> <code>string</code> <code>~/.depictio/CLI.yaml</code> CLI configuration file path <code>--project-config-path</code> <code>string</code> <code>\"\"</code> Pipeline configuration file path <pre><code>depictio-cli config validate-project-config --project-config-path ./config.yaml\n</code></pre>"},{"location":"depictio-cli/usage/#config-sync-project-config-to-server","title":"<code>config sync-project-config-to-server</code>","text":"<p>Sync project configuration to server.</p> <pre><code>depictio-cli config sync-project-config-to-server [OPTIONS]\n</code></pre> Parameter Type Default Description <code>--CLI-config-path</code> <code>string</code> <code>~/.depictio/CLI.yaml</code> CLI configuration file path <code>--project-config-path</code> <code>string</code> <code>\"\"</code> Pipeline configuration file path <code>--update</code> <code>boolean</code> <code>false</code> Update existing project configuration <pre><code>depictio-cli config sync-project-config-to-server --project-config-path ./config.yaml --update\n</code></pre>"},{"location":"depictio-cli/usage/#data-commands","title":"\ud83d\udcca Data Commands","text":"<p>Command Group: <code>depictio-cli data</code></p> <p>All commands in this section are part of the <code>data</code> command family. Use them to manage data scanning and processing operations.</p> <p>Manage data scanning and processing operations.</p>"},{"location":"depictio-cli/usage/#data-scan","title":"<code>data scan</code>","text":"<p>Scan project files for data collections.</p> <pre><code>depictio-cli data scan [OPTIONS]\n</code></pre> Parameter Type Default Description <code>--CLI-config-path</code> <code>string</code> <code>~/.depictio/CLI.yaml</code> CLI configuration file path <code>--project-config-path</code> <code>string</code> <code>\"\"</code> Pipeline configuration file path <code>--workflow-name</code> <code>string</code> <code>null</code> Specific workflow to scan <code>--data-collection-tag</code> <code>string</code> <code>null</code> Data collection tag to scan <code>--rescan-folders</code> <code>boolean</code> <code>false</code> Reprocess all runs for data collection <code>--sync-files</code> <code>boolean</code> <code>false</code> Update files for data collection <pre><code>depictio-cli data scan --project-config-path ./config.yaml --workflow-name my-workflow\n</code></pre>"},{"location":"depictio-cli/usage/#data-process","title":"<code>data process</code>","text":"<p>Process data collections for workflow execution.</p> <pre><code>depictio-cli data process [OPTIONS]\n</code></pre> Parameter Type Default Description <code>--CLI-config-path</code> <code>string</code> <code>~/.depictio/CLI.yaml</code> CLI configuration file path <code>--project-config-path</code> <code>string</code> <code>\"\"</code> Pipeline configuration file path <code>--overwrite</code> <code>boolean</code> <code>false</code> Overwrite existing workflow <pre><code>depictio-cli data process --project-config-path ./config.yaml --overwrite\n</code></pre>"},{"location":"depictio-cli/usage/#backup-commands","title":"\ud83d\udcbe Backup Commands","text":"<p>Command Group: <code>depictio-cli backup</code></p> <p>All commands in this section are part of the <code>backup</code> command family. Use them to backup and restore system data and configurations.</p> <p>Backup and restore system data and configurations.</p> <p>Admin Access Required</p> <p>Backup and restore commands require administrator privileges. Only users with admin access can perform backup and restore operations. Ensure your CLI configuration includes admin credentials.</p>"},{"location":"depictio-cli/usage/#backup-backup","title":"<code>backup backup</code>","text":"<p>Create a backup of database and S3 storage data.</p> <pre><code>depictio-cli backup backup [OPTIONS]\n</code></pre> Parameter Type Default Description <code>--CLI-config-path</code> <code>string</code> <code>~/.depictio/CLI.yaml</code> CLI configuration file path <code>--backup-name</code> <code>string</code> <code>timestamp</code> Name for the backup <code>--include-s3</code> <code>boolean</code> <code>true</code> Include S3 storage data in backup <code>--include-db</code> <code>boolean</code> <code>true</code> Include database data in backup <code>--output-path</code> <code>string</code> <code>./backups</code> Path where backup files are stored <pre><code>depictio-cli backup backup --backup-name production-backup --output-path ./backups\n</code></pre>"},{"location":"depictio-cli/usage/#backup-restore","title":"<code>backup restore</code>","text":"<p>Restore data from a previously created backup.</p> <pre><code>depictio-cli backup restore [OPTIONS]\n</code></pre> Parameter Type Default Description <code>--CLI-config-path</code> <code>string</code> <code>~/.depictio/CLI.yaml</code> CLI configuration file path <code>--backup-path</code> <code>string</code> required Path to backup file or directory <code>--restore-s3</code> <code>boolean</code> <code>true</code> Restore S3 storage data <code>--restore-db</code> <code>boolean</code> <code>true</code> Restore database data <code>--force</code> <code>boolean</code> <code>false</code> Force restore without confirmation <pre><code>depictio-cli backup restore --backup-path ./backups/production-backup --force\n</code></pre>"},{"location":"depictio-cli/usage/#backup-list-backups","title":"<code>backup list-backups</code>","text":"<p>List all available backups.</p> <pre><code>depictio-cli backup list-backups [OPTIONS]\n</code></pre> Parameter Type Default Description <code>--backup-path</code> <code>string</code> <code>./backups</code> Path to backup directory <pre><code>depictio-cli backup list-backups --backup-path ./backups\n</code></pre>"},{"location":"depictio-cli/usage/#common-use-cases","title":"\ud83d\udee0\ufe0f Common Use Cases","text":""},{"location":"depictio-cli/usage/#quick-start","title":"\ud83d\ude80 Quick Start","text":"Complete Setup <pre><code># 1. Validate your project configuration\ndepictio-cli config validate-project-config --project-config-path ./config.yaml\n\n# 2. Run the complete workflow\ndepictio-cli run --project-config-path ./config.yaml\n</code></pre> Step by Step <pre><code># 1. Check system status\ndepictio-cli config check-server-accessibility\ndepictio-cli config check-s3-storage\n\n# 2. Validate and sync configuration\ndepictio-cli config validate-project-config --project-config-path ./config.yaml\ndepictio-cli config sync-project-config-to-server --project-config-path ./config.yaml\n\n# 3. Scan and process data\ndepictio-cli data scan --project-config-path ./config.yaml\ndepictio-cli data process --project-config-path ./config.yaml\n</code></pre>"},{"location":"depictio-cli/usage/#development-workflow","title":"\ud83d\udd27 Development Workflow","text":"Testing Changes <pre><code># Preview changes without execution\ndepictio-cli run --project-config-path ./config.yaml --dry-run\n\n# Test with specific workflow\ndepictio-cli run --project-config-path ./config.yaml --workflow-name test-workflow\n</code></pre> Debugging <pre><code># Enable verbose logging\ndepictio-cli run --project-config-path ./config.yaml --verbose --continue-on-error\n\n# Skip problematic steps\ndepictio-cli run --project-config-path ./config.yaml --skip-server-check --skip-s3-check\n</code></pre>"},{"location":"depictio-cli/usage/#backup-operations","title":"\ud83d\udcbe Backup Operations","text":"<p>Admin Access Required</p> <p>All backup operations require administrator privileges.</p> Create Backup <pre><code># Create timestamped backup\ndepictio-cli backup backup --backup-name \"backup-$(date +%Y%m%d-%H%M%S)\"\n\n# Custom backup location\ndepictio-cli backup backup --backup-name production-backup --output-path /secure/backups\n</code></pre> Restore Backup <pre><code># List available backups\ndepictio-cli backup list-backups --backup-path /secure/backups\n\n# Restore specific backup\ndepictio-cli backup restore --backup-path /secure/backups/production-backup --force\n</code></pre>"},{"location":"depictio-cli/usage/#data-management","title":"\ud83d\udcca Data Management","text":"Rescan Data <pre><code># Rescan all folders\ndepictio-cli data scan --project-config-path ./config.yaml --rescan-folders\n\n# Sync file updates\ndepictio-cli data scan --project-config-path ./config.yaml --sync-files\n</code></pre> Process Updates <pre><code># Overwrite existing workflow\ndepictio-cli data process --project-config-path ./config.yaml --overwrite\n\n# Update and reprocess\ndepictio-cli run --project-config-path ./config.yaml --update-config --overwrite\n</code></pre>"},{"location":"depictio-cli/usage/#error-handling","title":"\ud83d\udd27 Error Handling","text":""},{"location":"depictio-cli/usage/#exit-codes","title":"Exit Codes","text":"Code Description Solution <code>0</code> Success Command completed successfully <code>1</code> Configuration error Check configuration file paths and syntax <code>2</code> Server connection failed Verify server URL and network connectivity <code>3</code> S3 storage error Validate S3 credentials and bucket configuration <code>4</code> Data processing failed Check data file permissions and formats"},{"location":"depictio-cli/usage/#common-issues","title":"Common Issues","text":"Connection Problems <p>Error: \"Server not accessible\"</p> <p>Solutions: <pre><code># Check server accessibility\ndepictio-cli config check-server-accessibility\n\n# Verify CLI configuration\ndepictio-cli config show-cli-config\n</code></pre></p> Configuration Errors <p>Error: \"Project config validation failed\"</p> <p>Solutions: <pre><code># Validate configuration with verbose output\ndepictio-cli config validate-project-config --project-config-path ./config.yaml --verbose\n\n# Check configuration examples\n# See: minimal_config.md and full_reference_config.md\n</code></pre></p> Permission Issues <p>Error: \"Admin access required\"</p> <p>Solutions: - Ensure you're logged in with admin credentials - Check CLI configuration includes admin access tokens - Contact system administrator for proper permissions</p>"},{"location":"depictio-cli/usage/#troubleshooting-steps","title":"Troubleshooting Steps","text":"<p>1. Check Prerequisites:</p> <ul> <li>Depictio server is running and accessible</li> <li>CLI configuration file exists (<code>~/.depictio/CLI.yaml</code>)</li> <li>Project configuration file is valid YAML</li> <li>Proper permissions for file access</li> </ul> <p>2. Enable Verbose Logging:</p> <pre><code>depictio-cli [command] --verbose --verbose-level DEBUG\n</code></pre> <p>3. Test Components Individually:</p> <pre><code>depictio-cli config check-server-accessibility\ndepictio-cli config check-s3-storage\ndepictio-cli config validate-project-config --project-config-path ./config.yaml\n</code></pre> <p>4. Use Dry Run Mode:</p> <pre><code>depictio-cli run --project-config-path ./config.yaml --dry-run\n</code></pre>"},{"location":"depictio-cli/usage/#configuration-references","title":"\ud83d\udcd6 Configuration References","text":"<ul> <li>Minimal YAML Configuration</li> <li>Full Reference Configuration</li> </ul>"},{"location":"developer/","title":"Developer","text":""},{"location":"developer/#developer-documentation","title":"Developer Documentation","text":"<p>This section provides information for developers who want to contribute to Depictio. Whether you're interested in fixing bugs, adding new features, or improving documentation, you'll find guidance to help you get started.</p>"},{"location":"developer/#contributing-to-depictio","title":"Contributing to Depictio","text":"<p>Depictio is an open-source project that welcomes contributions from the community. There are many ways to contribute:</p> <ul> <li>Code contributions: Implement new features, develop new components, or fix bugs</li> <li>Testing: Help test features or report bugs</li> <li>Design: Contribute to the UI/UX design*</li> <li>Documentation: Improve or expand the documentation</li> <li>Community support: Help answer questions and support other users</li> </ul> <p>For detailed information on how to contribute, see the Contributing Guide.</p>"},{"location":"developer/#in-this-section","title":"In This Section","text":"<ul> <li>Contributing Guide - Detailed instructions for contributing to Depictio</li> </ul>"},{"location":"developer/#getting-started","title":"Getting Started","text":"<p>To begin contributing to Depictio, we recommend:</p> <ol> <li>Familiarize yourself with the project architecture</li> <li>Read the contributing guidelines</li> <li>Set up your development environment</li> <li>Start with small, manageable contributions</li> </ol> <p>We look forward to your contributions and are here to help you get started!</p>"},{"location":"developer/contributing/","title":"Contributing to Depictio","text":"<p>Thank you for your interest in contributing to Depictio! This guide outlines the process for contributing to the project and provides resources to help you get started.</p>"},{"location":"developer/contributing/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Getting Started</li> <li>Development Environment</li> <li>Project Structure</li> <li>Development Workflow</li> <li>Testing</li> <li>Code Style and Standards</li> <li>Documentation</li> <li>Issue Reporting</li> <li>Pull Requests</li> <li>Code Review Process</li> <li>Community</li> <li>License</li> </ul>"},{"location":"developer/contributing/#getting-started","title":"Getting Started","text":""},{"location":"developer/contributing/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Python 3.11 or higher</li> <li>Docker and Docker Compose</li> <li>Git</li> </ul>"},{"location":"developer/contributing/#fork-and-clone","title":"Fork and Clone","text":"<ol> <li>Fork the repository on GitHub</li> <li>Clone your fork locally:</li> </ol> <pre><code>git clone https://github.com/YOUR-USERNAME/depictio.git\ncd depictio\n</code></pre> <ol> <li>Add the original repository as an upstream remote:</li> </ol> <pre><code>git remote add upstream https://github.com/depictio/depictio.git\n</code></pre>"},{"location":"developer/contributing/#development-environment","title":"Development Environment","text":""},{"location":"developer/contributing/#setting-up-test-environment","title":"Setting up test environment","text":"<ol> <li>Create a virtual environment using Python's <code>venv</code> module or your preferred tool (e.g., <code>virtualenv</code>, <code>conda</code>, <code>uv</code>):</li> </ol> <p>Example using <code>venv</code>:</p> <pre><code>python -m venv depictio-dev-venv\nsource depictio-dev-venv/bin/activate\n</code></pre> <p>Example using <code>uv</code>:</p> <pre><code>uv venv depictio-dev-venv --python 3.12\n</code></pre> <ol> <li>Install development dependencies:</li> </ol> <pre><code>pip install -e \".[dev]\"\n</code></pre> <ol> <li>Set up pre-commit hooks:</li> </ol> <pre><code>pre-commit install\n</code></pre>"},{"location":"developer/contributing/#running-depictio-locally-using-docker-compose","title":"Running Depictio Locally using Docker Compose","text":"<p>To modify and test Depictio locally, you can use Docker Compose to set up the development environment. This will allow you to run both the backend and frontend services and modify the code as needed from the <code>depictio</code> directory (mounted as a volume in the Docker container).</p> <pre><code>volumes:\n   - ./depictio:/app/depictio\n</code></pre> <ol> <li>To build the Docker images and start the services, run the following command from the root of the project:</li> </ol> <pre><code>docker compose -f docker-compose.dev.yaml \\\n               -f docker-compose/docker-compose.minio.yaml \\\n               --env-file docker-compose/.env up \\\n               --build --detach\n</code></pre> <ol> <li>Access the backend API at <code>http://localhost:8058</code> and the frontend at <code>http://localhost:5080</code>.</li> </ol>"},{"location":"developer/contributing/#dependencies","title":"Dependencies","text":"<p>Currently, Depictio is using a single container for both the backend and frontend services (<code>docker-images/Dockerfile_depictio.dockerfile</code>). This is done to simplify the development process. The container is built using a micromamba environment that includes all necessary dependencies for both the backend and frontend (<code>conda_ens/depictio.yaml</code>). As the project grows, we may consider splitting the backend and frontend into separate containers for better scalability and maintainability. The current container build process also includes a Playwright installation to generate thumbnails to be served on the landing page of the dashboard. As Cypress is currently used for end-to-end testing, we might consider switching to it for thumbnail generation in the future.</p>"},{"location":"developer/contributing/#environment-variables","title":"Environment Variables","text":"<p>Depictio uses environment variables for configuration. You can set these in a <code>.env</code> file in the root directory or pass them directly to Docker Compose. The <code>.env.example</code> file provides a template for the required variables.</p> <p>Important variables during development include:</p> <ul> <li><code>DEV_MODE</code>: Set to <code>true</code> to use development mode from FastAPI and Plotly Dash.</li> <li><code>DEPICTIO_MONGODB_WIPE</code>: Set to <code>true</code> to wipe the MongoDB database on startup (useful for development).</li> <li><code>DEPICTIO_LOGGING_VERBOSITY_LEVEL</code>: Set to <code>DEBUG</code> for detailed logging during development.</li> </ul>"},{"location":"developer/contributing/#project-structure","title":"Project Structure","text":"<p>The Depictio codebase is organized into several key directories:</p> <ul> <li><code>depictio/api/</code> - Backend microservice (FastAPI, port 8058)<ul> <li><code>endpoints/</code> - API endpoints for workflows, dashboards, data collections</li> <li><code>models/</code> - Database models and validation</li> </ul> </li> <li><code>depictio/dash/</code> - Frontend microservice (Dash, port 5080)<ul> <li><code>modules/</code> - Dash Component (see below)</li> <li><code>layouts/</code> - Dashboard layouts and stepper UI</li> </ul> </li> <li><code>depictio/models/</code> - Shared Pydantic models</li> <li><code>depictio/cli/</code> - Command-line interface for data management</li> <li><code>depictio/tests/</code> - Unit, integration and E2E tests</li> <li><code>helm-charts/</code> - Kubernetes deployment manifests</li> </ul>"},{"location":"developer/contributing/#component-development-key-feature","title":"Component Development (Key Feature)","text":"<p>Depictio uses a modular component system in <code>depictio/dash/modules/</code>:</p> <ul> <li><code>card_component/</code> - Text and summary cards</li> <li><code>figure_component/</code> - Plotly visualizations</li> <li><code>interactive_component/</code> - Sliders, filters, dropdowns</li> <li><code>table_component/</code> - Data tables</li> <li><code>text_component/</code> - Text display components</li> </ul> <p>Each component follows this structure:</p> <pre><code>component_name/\n\u251c\u2500\u2500 frontend.py      # Dash callbacks and UI\n\u2514\u2500\u2500 utils.py         # Component building logic\n</code></pre>"},{"location":"developer/contributing/#development-workflow","title":"Development Workflow","text":"<ol> <li> <p>Create a new branch for your feature or bugfix:</p> <pre><code>git checkout -b &lt;issue-type&gt;/&lt;issue-number&gt;-&lt;short-description&gt;\n# Example: git checkout -b feature/123-add-new-component / bugfix/456-fix-data-processing\n</code></pre> </li> <li> <p>Make your changes and commit them:</p> <pre><code>git add .\ngit commit -m \"Description of your changes\"\n</code></pre> </li> <li> <p>Keep your branch updated with the upstream:</p> <pre><code>git fetch upstream\ngit rebase upstream/main\n</code></pre> </li> <li> <p>Push your branch to GitHub:</p> <pre><code>git push origin &lt;issue-type&gt;/&lt;issue-number&gt;-&lt;short-description&gt;\n</code></pre> </li> <li> <p>Create a pull request on GitHub.</p> </li> </ol>"},{"location":"developer/contributing/#testing-local-changes","title":"Testing local changes","text":""},{"location":"developer/contributing/#running-tests","title":"Running Tests","text":"<p>Run the test suite to ensure your changes don't break existing functionality:</p> <pre><code>pytest\n</code></pre>"},{"location":"developer/contributing/#writing-tests","title":"Writing Tests","text":"<ul> <li>Place tests in the <code>depictio/tests/</code> directory</li> <li>Follow the existing test structure (e.g., <code>depictio/tests/api/</code>, <code>depictio/tests/dash/</code>, <code>depictio/tests/cli/</code>)</li> </ul>"},{"location":"developer/contributing/#code-style-and-standards","title":"Code Style and Standards","text":"<p>Depictio follows these coding standards:</p> <ul> <li>PEP 8 for Python code style</li> <li>Type hints for all function parameters and return values</li> <li>Docstrings for all modules, classes, and functions</li> </ul> <p>We use pre-commit hooks to enforce code style, which includes:</p> <ul> <li><code>ruff</code> for code formatting and linting with isort for import sorting</li> <li><code>ty</code> for static type checking</li> </ul>"},{"location":"developer/contributing/#documentation","title":"Documentation","text":""},{"location":"developer/contributing/#repository","title":"Repository","text":"<p>The documentation for Depictio is maintained in the <code>depictio-docs</code> repository at the following location: https://github.com/depictio/depictio-docs.</p>"},{"location":"developer/contributing/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Apply the same procedure as for the main repository to fork the <code>depictio-docs</code> repository, clone it locally, and set up the development environment.</li> <li>Install the</li> </ul>"},{"location":"developer/contributing/#writing-documentation","title":"Writing Documentation","text":"<ul> <li>Documentation is built using MkDocs</li> <li>Source files are in the <code>docs/</code> directory</li> <li>Write in Markdown format</li> <li>Include code examples where appropriate</li> </ul>"},{"location":"developer/contributing/#building-documentation","title":"Building Documentation","text":"<p>To build and preview the documentation locally:</p> <pre><code>cd docs\nmkdocs serve\n</code></pre>"},{"location":"developer/contributing/#issue-reporting","title":"Issue Reporting","text":""},{"location":"developer/contributing/#bug-reports","title":"Bug Reports","text":"<p>When reporting a bug, please include:</p> <ul> <li>A clear, descriptive title</li> <li>Steps to reproduce the issue</li> <li>Expected behavior</li> <li>Actual behavior</li> <li>Screenshots if applicable</li> <li>Environment information</li> </ul>"},{"location":"developer/contributing/#feature-requests","title":"Feature Requests","text":"<p>When requesting a feature, please include:</p> <ul> <li>A clear, descriptive title</li> <li>Detailed description of the proposed feature</li> <li>Rationale for adding the feature</li> <li>Implementation suggestions if applicable</li> </ul>"},{"location":"developer/contributing/#pull-requests","title":"Pull Requests","text":""},{"location":"developer/contributing/#pr-guidelines","title":"PR Guidelines","text":"<ul> <li>Keep PRs focused on a single feature or bugfix</li> <li>Include tests for new functionality</li> <li>Update documentation as needed</li> <li>Reference related issues</li> <li>Follow the commit message format</li> </ul>"},{"location":"developer/contributing/#pr-template","title":"PR Template","text":"<p>Your PR description should include:</p> <ul> <li>What changes were made</li> <li>Why the changes were made</li> <li>How to test the changes</li> <li>Any additional context or notes</li> </ul>"},{"location":"developer/contributing/#code-review-process","title":"Code Review Process","text":"<p>All submissions require review. The review process typically includes:</p> <ol> <li>Automated checks (CI/CD pipeline)</li> <li>Code review by maintainers</li> <li>Addressing feedback</li> <li>Final approval and merge</li> </ol>"},{"location":"developer/contributing/#community","title":"Community","text":""},{"location":"developer/contributing/#communication-channels","title":"Communication Channels","text":"<ul> <li>GitHub Issues for bug reports and feature requests</li> <li>Discussions for general questions and ideas</li> </ul>"},{"location":"developer/contributing/#license","title":"License","text":"<p>By contributing to Depictio, you agree that your contributions will be licensed under the project's license.</p>"},{"location":"developer/developer/","title":"Developer guide","text":"<p>While Depictio is not yet operational, we welcome ideas, suggestions, and feedback from the community. If you have insights or want to contribute to the project, please feel free to open an issue or submit a pull request.</p>"},{"location":"developer/developer/#contribution-guide","title":"Contribution guide","text":""},{"location":"developer/developer/#repositories-organisation","title":"Repositories organisation","text":""},{"location":"developer/developer/#modules-organisation-code-structure","title":"Modules organisation (code structure)","text":""},{"location":"documentation/","title":"Documentation Guide","text":"<p>This section provides an overview of the Depictio documentation structure and guidelines for contributors.</p>"},{"location":"documentation/#overview","title":"Overview","text":"<p>The Depictio documentation aims to be:</p> <ul> <li>Comprehensive: Covering all aspects of the platform</li> <li>Clear: Easy to understand for users of all levels</li> <li>Well-organized: Logically structured for easy navigation</li> <li>Up-to-date: Reflecting the latest version of the software</li> </ul>"},{"location":"documentation/#documentation-structure","title":"Documentation Structure","text":"<p>The documentation is organized into several main sections:</p> <ul> <li>Home: Overview and introduction to Depictio</li> <li>Installation: Setup guides for different environments</li> <li>Usage: Instructions for using the platform</li> <li>Features: Detailed descriptions of capabilities</li> <li>API: Reference for programmatic interaction</li> <li>Developer: Resources for contributors</li> <li>FAQ: Common questions and answers</li> <li>Changelog: Version history and updates</li> </ul>"},{"location":"documentation/#for-contributors","title":"For Contributors","text":"<p>If you're interested in improving the documentation:</p> <ul> <li>Review our content guidelines</li> <li>Follow the project's contribution workflow</li> <li>Use the standard tools: MkDocs with Material theme and Markdown</li> </ul>"},{"location":"documentation/#in-this-section","title":"In This Section","text":"<ul> <li>Documentation Outline - Detailed structure and future plans</li> </ul>"},{"location":"documentation/#building-locally","title":"Building Locally","text":"<p>To preview the documentation on your machine:</p> <pre><code>git clone https://github.com/depictio/depictio-docs.git\npip install -r requirements.txt\nmkdocs serve\n</code></pre> <p>Then visit <code>http://localhost:8000</code> in your browser.</p>"},{"location":"features/","title":"Features","text":""},{"location":"features/#overview","title":"Overview","text":"<p>Depictio is built to address the challenges of visualizing and analyzing large-scale bioinformatics datasets generated by production workflows like nf-core, WorkflowHub, or the Snakemake Workflow Catalog. It provides a user-friendly interface for creating interactive dashboards that can be shared with collaborators, making it easier to explore and interpret complex data.</p> <p>Its key capabilities include:</p> <ul> <li>Interactive Dashboards for real-time data exploration</li> <li>Scalable Architecture for handling large datasets</li> <li>Data Integration from multiple sources</li> <li>User Management for secure access control</li> <li>Security Features with restricted code execution and comprehensive protection</li> <li>Customizable Components for tailored visualizations</li> </ul>"},{"location":"features/#in-this-section","title":"In This Section","text":"<ul> <li>Architecture - Detailed overview of Depictio's microservices architecture</li> <li>Modularity - Information about Depictio's modular design and extensibility</li> <li>Security - Comprehensive security features and restricted code execution</li> </ul>"},{"location":"features/#key-components","title":"Key Components","text":"<p>Depictio consists of several integrated components:</p> <ul> <li>Backend API (FastAPI) - Handles data processing and business logic</li> <li>Frontend (Plotly Dash) - Provides the user interface</li> <li>Database (MongoDB) - Stores metadata and configurations</li> <li>Storage (MinIO) - Manages data files and assets</li> </ul> <p>Explore the detailed documentation to learn more about each feature and how they work together to provide a comprehensive visualization platform.</p>"},{"location":"features/architecture/","title":"Architecture","text":"<p>Depictio is built on a modern microservices architecture that provides flexibility, scalability, and maintainability. This page describes the overall architecture and how the different components interact.</p> <p> </p>"},{"location":"features/architecture/#microservices-overview","title":"Microservices Overview","text":"<p>Depictio's architecture consists of four main components:</p> <ol> <li>FastAPI Backend - RESTful API service that handles metadata processing, authentication, and business logic</li> <li>MongoDB Database - Document database for storing metadata, user information, and dashboard configurations</li> <li>MinIO S3 Storage - Object storage for managing data files and assets</li> <li>Plotly Dash Frontend - Interactive web interface for creating and using dashboards</li> </ol>"},{"location":"features/architecture/#fastapi-backend","title":"FastAPI Backend","text":"<p>The backend service is built with FastAPI, a modern, high-performance web framework for building APIs with Python. Key features include:</p> <ul> <li>RESTful API endpoints for all platform functionality</li> <li>JWT-based authentication and authorization</li> <li>Asynchronous request handling for improved performance</li> <li>Pydantic models for data validation and serialization</li> <li>Beanie ODM for MongoDB integration</li> </ul>"},{"location":"features/architecture/#mongodb-database","title":"MongoDB Database","text":"<p>MongoDB serves as the primary database for Depictio, storing:</p> <ul> <li>User accounts and authentication information</li> <li>Project metadata and configurations</li> <li>Workflow definitions and run information</li> <li>Dashboard layouts, structure and content</li> <li>Data collection metadata</li> </ul>"},{"location":"features/architecture/#minio-s3-storage-optional","title":"MinIO S3 Storage (Optional)","text":"<p>MinIO provides S3-compatible object storage for:</p> <ul> <li>Processed data ready for visualization (Delta lake, genome-browser compatible data, etc.)</li> </ul>"},{"location":"features/architecture/#plotly-dash-frontend","title":"Plotly Dash Frontend","text":"<p>The frontend is built with Plotly Dash (React), a framework for building analytical web applications. Features include:</p> <ul> <li>Interactive data visualization components</li> <li>Real-time data updates</li> <li>Draggagle and customizable dashboard layouts</li> <li>Integration with the backend API for data retrieval and processing</li> </ul>"},{"location":"features/frontend_components/","title":"Frontend components","text":""},{"location":"features/frontend_components/#generic-components-data-collection-table","title":"Generic components (Data collection Table)","text":"<p>There are currently 4 main components supported to build your dashboard:</p> <ul> <li>Figures: Bar, Line, Scatter, Box and Histogram plots.</li> <li>Metrics cards: Cards displaying metrics values.</li> <li>Interactive components: (slider, dropdown, input text, etc.)</li> <li>Tables: Interactive tables with sorting, filtering and searching functionalities.</li> </ul>"},{"location":"features/frontend_components/#specific-components","title":"Specific components","text":"<ul> <li>JBrowse: Genome browser to visualize genomic data.</li> <li>Graphs: Network graphs to visualize interactions between entities.</li> <li>Geomap: Geographical map.</li> </ul>"},{"location":"features/frontend_components/#ui-to-metadata-mapping","title":"UI to metadata mapping","text":"<ul> <li>Explain how the frontend components are mapped to metadata, metadata then turned into polars filters.</li> </ul>"},{"location":"features/frontend_components/#dynamic-joining-of-data-collections","title":"Dynamic joining of data collections","text":"<ul> <li>Explain how data collections can be joined dynamically between different component types.</li> </ul>"},{"location":"features/modularity/","title":"Modularity","text":"<p>Depictio code structure is designed with a modular architecture, allowing for easy integration of new features and functionalities. The frontend and backend components are decoupled, enabling independent development and deployment of each module. The platform is built to be scalable and adaptable to various needs, with a focus on user-friendly interfaces and interactive data visualization tools.</p>"},{"location":"features/modularity/#general-object-model-and-database-design","title":"General object model and database design","text":"<p>Depictio object model was designed to reflect production-oriented workflows. The architecture is built to ensure a clear separation of concerns, with distinct layers for workflows, workflow run configurations, runs, files generated, and data collections. This modular approach is reflected in both the database schema and the API structure.</p>"},{"location":"features/modularity/#project-workflow-object-design","title":"Project &amp; Workflow Object Design","text":"<ul> <li>Project : The top-level entity that encapsulates that represents one or multiple production-oriented pipeline/workflow.</li> <li>Workflow: Standardised / production-oriented workflow</li> <li>Run Configurations: These define the parameters and settings that were used to run a workflow.</li> <li>Runs: Instances of a production workflow executed using a specific run configuration. Each run generates output files, that are structured the same way across runs. These files can then be associated into data collections.</li> <li>Files: Artifacts produced by each run. These can be intermediate or final results of the workflow.</li> <li>Data Collections: Aggregated data from files following the same structure.</li> </ul> <p>The following diagram illustrates a \"Workflow\" object and its relationships with other objects in the system. The workflow object is at the center, with run configurations, runs, files, and data collections branching out from it. The files generated by each run can be organized into data collections, which can be used for visualization and analysis. Multiple workflows can be associated with a single project, enabling users to manage and visualize data, e.g., multi-omics data, from different workflows (nf-core/rnaseq and nf-core/atacseq) in a single dashboard.</p> <p></p>"},{"location":"features/modularity/#code-architecture","title":"Code architecture","text":"<p>The code organisation clearly separates each of the frontend components and the API endpoints, making it easy to understand and extend the platform.</p> <p></p>"},{"location":"features/modularity/#api-structure","title":"API structure","text":"<p>The API is structured to mirror the object design specified above, with each major component of the workflow having its own set of endpoints and models. The organization within <code>depictio/api/v1/endpoints</code> is as follows:</p> <ul> <li>dashboards_endpoints: Manages endpoints related to dashboards.</li> <li>datacollections_endpoints: Handles endpoints for data collections, mapping closely to the Data Collection objects in the design.</li> <li>deltatables_endpoints: Provides endpoints for delta tables, which are specific types of data collections with versioning.</li> <li>files_endpoints: Manages file-related endpoints, directly corresponding to the File objects.</li> <li>user_endpoints: Manages user authentication and authorization, including models and routes for user management.</li> <li>utils_endpoints: Provides utility endpoints, typically for internal or auxiliary operations.</li> <li>workflow_endpoints: Focuses on managing workflows, run configurations, and runs, reflecting the core of the workflow architecture.</li> <li>project_endpoints: Handles project-related endpoints, including project creation, management, and permissions.</li> </ul> <p>Each endpoint is defined in a separate subfolder, where the <code>routes.py</code> file contains the API routes and the <code>models.py</code> file contains the object models associated.</p> <p></p>"},{"location":"features/modularity/#dashboard-components","title":"Dashboard components","text":"<p>The frontend components in Depictio are organized in the depictio/dash/modules folder, with each component defined in a separate subfolder. This modular design ensures easy integration and maintainability.</p>"},{"location":"features/modularity/#component-structure","title":"Component Structure","text":"<p>Each component folder typically contains:</p> <ul> <li>frontend.py: Implements Dash callback functions.</li> <li>utils.py: Contains helper functions for rendering and state management.</li> </ul> <p>Each of the frontend components is designed to be modular and can be easily integrated into the dashboard. Each component is defined in a separate folder, containing the component logic and styling. The <code>frontend.py</code> file contains the dash callback functions implementation and the <code>utils.py</code> file contains the helpers functions used by the component, allowing the component to be re-rendered in different scenarios (first design, reload/restore, refresh after data update).</p> <p></p>"},{"location":"features/security/","title":"Security Features","text":"<p>Depictio implements comprehensive security measures to protect your data and ensure safe operation in production environments.</p>"},{"location":"features/security/#authentication-authorization","title":"Authentication &amp; Authorization","text":""},{"location":"features/security/#jwt-based-authentication","title":"JWT-Based Authentication","text":"<ul> <li>Token Security: Public/private key encryption for session tokens</li> <li>Session Management: Configurable token lifetime and refresh mechanisms</li> <li>Role-Based Access: User and group-based permissions for projects and dashboards</li> </ul>"},{"location":"features/security/#code-execution-security-code-mode","title":"Code Execution Security (Code Mode)","text":""},{"location":"features/security/#restrictedpython-security","title":"RestrictedPython Security","text":"<ul> <li>Battle-Tested Security: Uses RestrictedPython (Zope Foundation) for code execution</li> <li>Compile-Time Restrictions: Unsafe operations blocked during code compilation</li> <li>Safe Execution Environment: Pre-approved globals and built-ins only</li> <li>No System Access: File system, network, and OS operations completely blocked</li> </ul>"},{"location":"features/security/#security-architecture","title":"Security Architecture","text":"<ul> <li>Restricted Compilation: Code compiled with <code>compile_restricted()</code> before execution</li> <li>Safe Guards: Custom guards for pandas DataFrame operations (<code>_getitem_</code>, <code>_getattr_</code>)</li> <li>Isolated Globals: Execution environment contains only approved libraries and functions</li> <li>Memory Protection: DataFrame operations work on copies to prevent data corruption</li> </ul>"},{"location":"features/security/#allowed-libraries-operations","title":"Allowed Libraries &amp; Operations","text":"<pre><code># Available libraries in Code Mode\nimport plotly.express as px      # Visualization library\nimport plotly.graph_objects as go # Advanced plotting\nimport pandas as pd              # Data manipulation\ndf                              # Your dataset (read-only copy)\n\n# Safe built-in functions\nlen(), range(), str(), int(), float(), sum(), min(), max()\n</code></pre>"},{"location":"features/security/#automatically-blocked-operations","title":"Automatically Blocked Operations","text":"<p>RestrictedPython prevents these operations at compile-time:</p> <ul> <li>File Operations: <code>open()</code>, file I/O, filesystem access</li> <li>Network Access: <code>requests</code>, <code>urllib</code>, socket operations</li> <li>System Calls: <code>os.*</code>, <code>sys.*</code>, <code>subprocess</code>, shell commands</li> <li>Dangerous Built-ins: <code>exec()</code>, <code>eval()</code>, <code>__import__()</code>, <code>compile()</code></li> <li>Attribute Access: Private attributes (underscore methods) on unsafe objects</li> </ul>"},{"location":"features/security/#security-reporting","title":"Security Reporting","text":"<p>If you discover a security vulnerability, please report it through appropriate channels:</p> <ul> <li>Report code execution restriction bypass attempts immediately</li> <li>Document and report any unauthorized data access</li> </ul> <p>Security is a shared responsibility. While Depictio provides robust security features, proper configuration and operational practices are essential for maintaining a secure environment.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#depictio-server","title":"Depictio (server)","text":"Docker Compose <p>For development, testing, and small-scale deployments.</p> Guide Kubernetes <p>For production environments and scalable deployments.</p> Guide"},{"location":"installation/#depictio-cli","title":"Depictio-CLI","text":"Depictio-CLI <p>For data ingestion and management.</p> Guide"},{"location":"installation/#configuration","title":"Configuration","text":"Environment Variables <p>Configure authentication, backups, and advanced features.</p> Guide"},{"location":"installation/#wants-a-customizable-hands-on-preview","title":"Wants a customizable hands-on preview?","text":"Gitpod <p>For a quick preview of Depictio, you can use Gitpod to launch a temporary workspace with Depictio pre-installed.</p> Open in Gitpod"},{"location":"installation/cli/","title":"CLI Installation","text":"<p>This guide will walk you through installing and configuring the Depictio CLI tool, which is used for data ingestion and management.</p>"},{"location":"installation/cli/#overview","title":"Overview","text":"<p>The Depictio CLI is a command-line tool that allows you to:</p> <ul> <li>Scan and process data files</li> <li>Upload data to the Depictio platform</li> <li>Manage projects and workflows</li> <li>Configure data collections</li> </ul>"},{"location":"installation/cli/#prerequisites","title":"Prerequisites","text":"<p>Before installing the CLI, ensure you have:</p> <ul> <li>Python 3.11 or higher</li> <li>pip (Python package manager)</li> <li>Access to a running Depictio instance</li> </ul>"},{"location":"installation/cli/#installation-methods","title":"Installation Methods","text":""},{"location":"installation/cli/#install-via-pip","title":"Install via pip","text":"<p>As <code>depictio-cli</code> is available on pypi, you can install the Depictio CLI using plain pip or through your preferred package manager like <code>uv</code>:</p> <pre><code>pip install depictio-cli\n</code></pre> <p>If you prefer using <code>uv</code>, you can install it like this:</p> <pre><code>uv venv depictio-cli-env --python 3.11\nsource depictio-cli-env/bin/activate\npip install depictio-cli\n</code></pre>"},{"location":"installation/cli/#install-from-source","title":"Install from Source","text":"<p>You can also install the CLI directly from the source code:</p> <pre><code>git clone https://github.com/depictio/depictio.git\ncd depictio/cli\npython -m venv depictio-cli-env\nsource depictio-cli-env/bin/activate\npip install -e .\n</code></pre> <p>This will install the CLI in development mode, allowing you to modify the code if needed.</p>"},{"location":"installation/cli/#verifying-the-installation","title":"Verifying the Installation","text":"<p>After installation, verify that the CLI is working correctly:</p> <pre><code>depictio-cli --help\n</code></pre> <p>This should display the help message with available commands and options.</p>"},{"location":"installation/cli/#configuration","title":"Configuration","text":"<p>Before using the CLI, you need to configure it to connect to your Depictio instance.</p> <p>You need to have access to the Depictio web interface in order to generate a configuration file:</p> <ol> <li>Log in to the Depictio web interface</li> <li>Navigate to your user profile</li> <li>Click on \"Generate CLI Config\"</li> <li>Copy the generated YAML configuration into your clipboard using the \"Copy to clipboard\" icon button</li> <li>Place the configuration file in the following location:</li> <li><code>~/.depictio/CLI.yaml</code> (recommended, default location)</li> </ol>"},{"location":"installation/cli/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/cli/#common-issues","title":"Common Issues","text":""},{"location":"installation/cli/#connection-errors","title":"Connection Errors","text":"<p>If you see connection errors:</p> <ol> <li>Verify that your Depictio instance is running</li> <li>Check that the API URL in your configuration is correct</li> <li>Ensure your token is valid and has not expired</li> </ol>"},{"location":"installation/cli/#authentication-issues","title":"Authentication Issues","text":"<p>If you see authentication errors:</p> <ol> <li>Check that your token is correct</li> <li>Verify that your user account has the necessary permissions</li> <li>Generate a new token if needed</li> </ol>"},{"location":"installation/cli/#s3-storage-issues","title":"S3 Storage Issues","text":"<p>If you have issues with S3 storage:</p> <ol> <li>Verify that MinIO is running</li> <li>Check that your S3 credentials are correct</li> <li>Ensure the bucket exists and is accessible</li> </ol>"},{"location":"installation/cli/#next-steps","title":"Next Steps","text":"<p>Now that you have installed and configured the CLI, you can:</p> <ul> <li>Learn how to use the CLI</li> <li>Understand the YAML configuration</li> <li>Get started with Depictio</li> </ul>"},{"location":"installation/configuration/","title":"Environment Variables Configuration","text":"<p>Depictio uses environment variables to configure various aspects of the application. This guide covers the key environment variables you can set to customize your deployment.</p>"},{"location":"installation/configuration/#base-configuration","title":"Base Configuration","text":"<p>The base configuration is available in the .env.example file in the repository. Copy this file to <code>.env</code> and modify the values as needed.</p>"},{"location":"installation/configuration/#basic-setup","title":"Basic Setup","text":"<pre><code># Application Context\nDEPICTIO_CONTEXT=server\nDEPICTIO_LOGGING_VERBOSITY_LEVEL=ERROR\n\n# MinIO Storage Configuration\nDEPICTIO_MINIO_ROOT_USER=minio\nDEPICTIO_MINIO_ROOT_PASSWORD=minio123\nDEPICTIO_MINIO_PUBLIC_URL=http://localhost:9000\n\n# MongoDB Configuration\nDEPICTIO_MONGODB_DB_NAME=depictioDB\nDEPICTIO_MONGODB_PORT=27018\nDEPICTIO_MONGODB_SERVICE_NAME=mongo\nDEPICTIO_MONGODB_WIPE=false\n\n# FastAPI Server Configuration\nDEPICTIO_FASTAPI_HOST=0.0.0.0\nDEPICTIO_FASTAPI_PORT=8058\nDEPICTIO_FASTAPI_SERVICE_NAME=depictio-backend\nDEPICTIO_FASTAPI_PUBLIC_URL=http://localhost:8058\n\n# Dash Frontend Configuration\nDEPICTIO_DASH_HOST=0.0.0.0\nDEPICTIO_DASH_PORT=5080\nDEPICTIO_DASH_SERVICE_NAME=depictio-frontend\n</code></pre>"},{"location":"installation/configuration/#storage-configuration","title":"Storage Configuration","text":"<p>Depictio can use MinIO for object storage. You can either use an external MinIO service or the built-in one.</p>"},{"location":"installation/configuration/#external-minio-service","title":"External MinIO Service","text":"<p>If you have an external MinIO service, configure it as follows:</p> <p>For Docker Compose, add the following to your <code>.env</code> file:</p> <pre><code># External MinIO service configuration\nDEPICTIO_MINIO_PUBLIC_URL=http://minio.example.com\nDEPICTIO_MINIO_ROOT_USER=minioadmin\nDEPICTIO_MINIO_ROOT_PASSWORD=minioadmin123\nDEPICTIO_MINIO_BUCKET_NAME=your-bucket-name\nDEPICTIO_MINIO_EXTERNAL_SERVICE=true\n</code></pre> <p>For Kubernetes, you can set these values in your custom <code>values.yaml</code> file:</p> <pre><code>minio:\n  enabled: false  # Set to true if using built-in MinIO\n  env:\n    DEPICTIO_MINIO_PUBLIC_URL: \"http://minio.example.com\"\n    DEPICTIO_MINIO_ROOT_USER: \"minioadmin\"\n    DEPICTIO_MINIO_ROOT_PASSWORD: \"minioadmin123\"\n    DEPICTIO_MINIO_BUCKET_NAME: \"your-bucket-name\"\n    DEPICTIO_MINIO_EXTERNAL_SERVICE: true\n</code></pre> <p>Setting those values will disable the built-in MinIO service and use the external one instead.</p>"},{"location":"installation/configuration/#authentication-configuration","title":"Authentication Configuration","text":""},{"location":"installation/configuration/#unauthenticated-mode","title":"Unauthenticated Mode","text":"<p>Enable unauthenticated mode to allow anonymous access to your Depictio instance:</p> <pre><code># Enable unauthenticated mode (allows anonymous access)\nDEPICTIO_AUTH_UNAUTHENTICATED_MODE=true\n\n# Anonymous user configuration\nDEPICTIO_AUTH_ANONYMOUS_USER_EMAIL=anonymous@depict.io\nDEPICTIO_AUTH_TEMPORARY_USER_EXPIRY_HOURS=24\n</code></pre>"},{"location":"installation/configuration/#google-oauth-integration","title":"Google OAuth Integration","text":"<p>Configure Google OAuth for user authentication:</p> <pre><code># Enable Google OAuth authentication\nDEPICTIO_AUTH_GOOGLE_OAUTH_ENABLED=true\n\n# Google OAuth credentials (obtain from Google Cloud Console)\nDEPICTIO_AUTH_GOOGLE_OAUTH_CLIENT_ID=your-google-client-id.apps.googleusercontent.com\nDEPICTIO_AUTH_GOOGLE_OAUTH_CLIENT_SECRET=your-google-client-secret\n\n# OAuth redirect URI (adjust to your domain)\nDEPICTIO_AUTH_GOOGLE_OAUTH_REDIRECT_URI=http://localhost:8058/auth/google/callback\n</code></pre>"},{"location":"installation/configuration/#setting-up-google-oauth","title":"Setting up Google OAuth","text":"<ol> <li>Create a Google Cloud Project:</li> <li>Go to Google Cloud Console</li> <li> <p>Create a new project or select an existing one</p> </li> <li> <p>Enable Google+ API:</p> </li> <li>Navigate to \"APIs &amp; Services\" \u2192 \"Library\"</li> <li> <p>Search for \"Google+ API\" and enable it</p> </li> <li> <p>Create OAuth 2.0 Credentials:</p> </li> <li>Go to \"APIs &amp; Services\" \u2192 \"Credentials\"</li> <li>Click \"Create Credentials\" \u2192 \"OAuth 2.0 Client ID\"</li> <li>Configure the consent screen if prompted</li> <li>Set application type to \"Web application\"</li> <li> <p>Add authorized redirect URIs:</p> <ul> <li><code>http://localhost:8058/auth/google/callback</code> (for local development)</li> <li><code>https://your-domain.com/auth/google/callback</code> (for production)</li> </ul> </li> <li> <p>Copy the credentials to your environment variables</p> </li> </ol>"},{"location":"installation/configuration/#authentication-keys","title":"Authentication Keys","text":"<p>Configure JWT authentication keys:</p> <pre><code># Authentication key configuration\nDEPICTIO_AUTH_KEYS_DIR=depictio/keys\nDEPICTIO_AUTH_KEYS_ALGORITHM=RS256\nDEPICTIO_AUTH_CLI_CONFIG_DIR=depictio/.depictio\nDEPICTIO_AUTH_INTERNAL_API_KEY=your-internal-api-key\n</code></pre>"},{"location":"installation/configuration/#custom-internal-api-key","title":"Custom Internal API Key","text":"<p>If you want to use your own internal API key instead of the auto-generated one:</p> <pre><code># Set your custom internal API key\nDEPICTIO_AUTH_INTERNAL_API_KEY=your-custom-internal-api-key-here\n</code></pre> <p>Generating a secure API key:</p> <pre><code># Generate a secure random API key (Linux/macOS)\nopenssl rand -hex 32\n\n# Or use Python\npython -c \"import secrets; print(secrets.token_hex(32))\"\n</code></pre>"},{"location":"installation/configuration/#custom-publicprivate-key-pairs","title":"Custom Public/Private Key Pairs","text":"<p>By default, Depictio generates RS256 key pairs automatically. To use your own custom keys:</p>"},{"location":"installation/configuration/#1-generate-your-own-key-pair","title":"1. Generate Your Own Key Pair","text":"<pre><code># Generate private key\nopenssl genrsa -out private_key.pem 2048\n\n# Generate public key from private key\nopenssl rsa -in private_key.pem -pubout -out public_key.pem\n</code></pre>"},{"location":"installation/configuration/#2-configure-key-directory","title":"2. Configure Key Directory","text":"<pre><code># Set custom keys directory\nDEPICTIO_AUTH_KEYS_DIR=/path/to/your/custom/keys\n\n# Ensure the directory contains:\n# - private_key.pem\n# - public_key.pem\n</code></pre>"},{"location":"installation/configuration/#3-file-structure","title":"3. File Structure","text":"<p>Your custom keys directory should contain:</p> <pre><code>/path/to/your/custom/keys/\n\u251c\u2500\u2500 private_key.pem    # Your private key\n\u2514\u2500\u2500 public_key.pem     # Your public key\n</code></pre>"},{"location":"installation/configuration/#4-security-considerations-for-custom-keys","title":"4. Security Considerations for Custom Keys","text":"<ul> <li>Secure Storage: Store keys in a secure location with proper file permissions</li> <li>Key Rotation: Regularly rotate your keys for security</li> <li>Backup: Securely backup your keys</li> <li>Access Control: Limit access to key files</li> </ul> <pre><code># Set proper permissions for key files\nchmod 600 /path/to/your/custom/keys/private_key.pem\nchmod 644 /path/to/your/custom/keys/public_key.pem\n</code></pre>"},{"location":"installation/configuration/#5-dockerkubernetes-deployment-with-custom-keys","title":"5. Docker/Kubernetes Deployment with Custom Keys","text":"<p>Docker Compose:</p> <pre><code>version: '3.8'\nservices:\n  depictio-backend:\n    image: depictio/depictio:latest\n    volumes:\n      - /path/to/your/custom/keys:/app/depictio/keys:ro\n    environment:\n      - DEPICTIO_AUTH_KEYS_DIR=/app/depictio/keys\n</code></pre> <p>Kubernetes Secret:</p> <pre><code># Create secret from your key files\nkubectl create secret generic depictio-keys \\\n  --from-file=private_key.pem=/path/to/your/custom/keys/private_key.pem \\\n  --from-file=public_key.pem=/path/to/your/custom/keys/public_key.pem\n\n# Mount secret in your deployment\napiVersion: v1\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n      - name: depictio-backend\n        volumeMounts:\n        - name: depictio-keys\n          mountPath: /app/depictio/keys\n          readOnly: true\n        env:\n        - name: DEPICTIO_AUTH_KEYS_DIR\n          value: /app/depictio/keys\n      volumes:\n      - name: depictio-keys\n        secret:\n          secretName: depictio-keys\n</code></pre>"},{"location":"installation/configuration/#backup-and-restore-configuration","title":"Backup and Restore Configuration","text":"<p>Configure backup and restore functionality:</p> <pre><code># Backup Configuration\nDEPICTIO_BACKUP_BASE_DIR=/path/to/backup/base\nDEPICTIO_BACKUP_BACKUP_DIR=backups\nDEPICTIO_BACKUP_S3_BACKUP_STRATEGY=s3_to_s3\nDEPICTIO_BACKUP_S3_LOCAL_BACKUP_DIR=backups/s3_data_backups\nDEPICTIO_BACKUP_COMPRESS_LOCAL_BACKUPS=true\nDEPICTIO_BACKUP_BACKUP_FILE_RETENTION_DAYS=30\n</code></pre>"},{"location":"installation/configuration/#backup-to-separate-s3-bucket","title":"Backup to Separate S3 Bucket","text":"<p>For production deployments, it's recommended to backup to a separate S3 bucket:</p> <pre><code># Enable backup to separate S3 bucket\nDEPICTIO_BACKUP_BACKUP_S3_ENABLED=true\nDEPICTIO_BACKUP_BACKUP_S3_BUCKET=depictio-backups\nDEPICTIO_BACKUP_BACKUP_S3_ENDPOINT_URL=https://s3.amazonaws.com\nDEPICTIO_BACKUP_BACKUP_S3_ACCESS_KEY=your-backup-s3-access-key\nDEPICTIO_BACKUP_BACKUP_S3_SECRET_KEY=your-backup-s3-secret-key\nDEPICTIO_BACKUP_BACKUP_S3_REGION=us-east-1\n</code></pre>"},{"location":"installation/configuration/#backup-strategies","title":"Backup Strategies","text":"<p>Choose from different backup strategies:</p> <ul> <li><code>s3_to_s3</code>: Direct S3 to S3 backup (recommended for production)</li> <li><code>local</code>: Local file system backup</li> <li><code>both</code>: Both local and S3 backup</li> </ul>"},{"location":"installation/configuration/#performance-configuration","title":"Performance Configuration","text":"<p>Configure timeouts and performance settings:</p> <pre><code># HTTP and API Timeouts\nDEPICTIO_PERFORMANCE_HTTP_CLIENT_TIMEOUT=30\nDEPICTIO_PERFORMANCE_API_REQUEST_TIMEOUT=60\n\n# Browser/Screenshot Timeouts\nDEPICTIO_PERFORMANCE_BROWSER_NAVIGATION_TIMEOUT=60000\nDEPICTIO_PERFORMANCE_BROWSER_PAGE_LOAD_TIMEOUT=90000\nDEPICTIO_PERFORMANCE_SCREENSHOT_CAPTURE_TIMEOUT=90000\n\n# Service Readiness Configuration\nDEPICTIO_PERFORMANCE_SERVICE_READINESS_RETRIES=5\nDEPICTIO_PERFORMANCE_SERVICE_READINESS_DELAY=3\nDEPICTIO_PERFORMANCE_SERVICE_READINESS_TIMEOUT=10\n</code></pre>"},{"location":"installation/configuration/#development-settings","title":"Development Settings","text":"<p>Configuration for development and testing:</p> <pre><code># Development Mode\nDEV_MODE=true\nDEPICTIO_PLAYWRIGHT_DEV_MODE=true\nDEPICTIO_TEST_MODE=true\n\n# Version Information\nDEPICTIO_VERSION=latest\n</code></pre>"},{"location":"installation/configuration/#dockerkubernetes-configuration","title":"Docker/Kubernetes Configuration","text":"<p>For containerized deployments:</p> <pre><code># Container Configuration\nUID=502\nGID=20\n\n# Kubernetes-specific (if deploying to Kubernetes)\nKUBERNETES_NAMESPACE=depictio\nKUBERNETES_NODE_NAME=node-1\n</code></pre>"},{"location":"installation/configuration/#complete-example","title":"Complete Example","text":"<p>Here's a complete example configuration for a production deployment with all features enabled:</p> <pre><code># ============================================================================\n# DEPICTIO PRODUCTION CONFIGURATION\n# ============================================================================\n\n# Application Context\nDEPICTIO_CONTEXT=server\nDEPICTIO_LOGGING_VERBOSITY_LEVEL=INFO\nDEPICTIO_VERSION=latest\n\n# MinIO Storage Configuration\nDEPICTIO_MINIO_ROOT_USER=minio\nDEPICTIO_MINIO_ROOT_PASSWORD=secure-minio-password\nDEPICTIO_MINIO_PUBLIC_URL=https://minio.yourdomain.com\n\n# MongoDB Configuration\nDEPICTIO_MONGODB_DB_NAME=depictioDB\nDEPICTIO_MONGODB_PORT=27017\nDEPICTIO_MONGODB_SERVICE_NAME=mongo\nDEPICTIO_MONGODB_WIPE=false\n\n# FastAPI Server Configuration\nDEPICTIO_FASTAPI_HOST=0.0.0.0\nDEPICTIO_FASTAPI_PORT=8058\nDEPICTIO_FASTAPI_SERVICE_NAME=depictio-backend\nDEPICTIO_FASTAPI_PUBLIC_URL=https://api.yourdomain.com\n\n# Dash Frontend Configuration\nDEPICTIO_DASH_HOST=0.0.0.0\nDEPICTIO_DASH_PORT=5080\nDEPICTIO_DASH_SERVICE_NAME=depictio-frontend\n\n# Authentication Configuration\nDEPICTIO_AUTH_UNAUTHENTICATED_MODE=false\nDEPICTIO_AUTH_KEYS_DIR=depictio/keys\nDEPICTIO_AUTH_KEYS_ALGORITHM=RS256\n\n# Google OAuth Configuration\nDEPICTIO_AUTH_GOOGLE_OAUTH_ENABLED=true\nDEPICTIO_AUTH_GOOGLE_OAUTH_CLIENT_ID=your-client-id.apps.googleusercontent.com\nDEPICTIO_AUTH_GOOGLE_OAUTH_CLIENT_SECRET=your-client-secret\nDEPICTIO_AUTH_GOOGLE_OAUTH_REDIRECT_URI=https://yourdomain.com/auth/google/callback\n\n# Backup Configuration\nDEPICTIO_BACKUP_BASE_DIR=/var/backups/depictio\nDEPICTIO_BACKUP_BACKUP_DIR=backups\nDEPICTIO_BACKUP_S3_BACKUP_STRATEGY=s3_to_s3\nDEPICTIO_BACKUP_BACKUP_S3_ENABLED=true\nDEPICTIO_BACKUP_BACKUP_S3_BUCKET=depictio-backups\nDEPICTIO_BACKUP_BACKUP_S3_ENDPOINT_URL=https://s3.amazonaws.com\nDEPICTIO_BACKUP_BACKUP_S3_ACCESS_KEY=your-backup-access-key\nDEPICTIO_BACKUP_BACKUP_S3_SECRET_KEY=your-backup-secret-key\nDEPICTIO_BACKUP_BACKUP_S3_REGION=us-east-1\nDEPICTIO_BACKUP_COMPRESS_LOCAL_BACKUPS=true\nDEPICTIO_BACKUP_BACKUP_FILE_RETENTION_DAYS=30\n\n# Performance Configuration\nDEPICTIO_PERFORMANCE_HTTP_CLIENT_TIMEOUT=30\nDEPICTIO_PERFORMANCE_API_REQUEST_TIMEOUT=60\nDEPICTIO_PERFORMANCE_BROWSER_NAVIGATION_TIMEOUT=60000\n\n# JBrowse Integration\nDEPICTIO_JBROWSE_ENABLED=true\n\n# Development Settings (set to false for production)\nDEV_MODE=false\nDEPICTIO_PLAYWRIGHT_DEV_MODE=false\nDEPICTIO_TEST_MODE=false\n</code></pre>"},{"location":"installation/configuration/#security-considerations","title":"Security Considerations","text":"<ul> <li>Never commit sensitive credentials to version control</li> <li>Use strong passwords for MinIO and other services</li> <li>Enable HTTPS in production environments</li> <li>Regularly rotate API keys and OAuth credentials</li> <li>Set appropriate backup retention policies</li> <li>Use separate S3 buckets for primary data and backups</li> <li>Enable authentication in production (disable unauthenticated mode)</li> </ul>"},{"location":"installation/configuration/#environment-variable-validation","title":"Environment Variable Validation","text":"<p>Depictio validates environment variables on startup. Check the logs for any configuration errors:</p> <pre><code># Check application logs for configuration validation\ndocker compose logs depictio-backend\ndocker compose logs depictio-frontend\n</code></pre> <p>For more detailed configuration options, refer to the source code settings models.</p>"},{"location":"installation/docker/","title":"Docker Compose Installation","text":"<p>This guide will walk you through installing and running Depictio using Docker Compose, which is the simplest way to get started with Depictio.</p>"},{"location":"installation/docker/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Docker (version 20.10.0 or higher)</li> <li>Docker Compose (version 2.0.0 or higher)</li> <li>Git (optional, for cloning the repository)</li> </ul>"},{"location":"installation/docker/#installation-steps","title":"Installation Steps","text":""},{"location":"installation/docker/#1-clone-the-repository-optional","title":"1. Clone the Repository (Optional)","text":"<p>If you want to use the latest development version, you can clone the repository:</p> <pre><code>git clone https://github.com/depictio/depictio.git\ncd depictio\n</code></pre> <p>Alternatively, you can download a release version from the GitHub releases page.</p>"},{"location":"installation/docker/#2-configure-environment-variables","title":"2. Configure Environment Variables","text":"<p>Create a <code>.env</code> file in the root directory of the project. You can use the provided example as a starting point:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Or manually create the <code>.env</code> file and add the following content:</p> Env-variables <pre><code># ============================================================================\n# DEPICTIO ENVIRONMENT VARIABLES\n# ============================================================================\n# Description: Configuration file for Depictio application services\n# ----------------------------------------------------------------------------\n# Depictio Version\n# ----------------------------------------------------------------------------\n# DEPICTIO_VERSION=latest\n\n# ----------------------------------------------------------------------------\n# Application Context\n# ----------------------------------------------------------------------------\n# Defines the runtime context (options: server, client)\nDEPICTIO_CONTEXT=server\nDEPICTIO_LOGGING_VERBOSITY_LEVEL=INFO\n\n# ----------------------------------------------------------------------------\n# MinIO Storage Configuration\n# ----------------------------------------------------------------------------\n# Object storage server configuration (S3DepictioCLIConfig)\nDEPICTIO_MINIO_ROOT_USER=minio\nDEPICTIO_MINIO_ROOT_PASSWORD=minio123\n# DEPICTIO_MINIO_PUBLIC_URL=http://localhost:9000\n\n# ----------------------------------------------------------------------------\n# MongoDB Configuration\n# ----------------------------------------------------------------------------\n# Database name\n# DEPICTIO_MONGODB_DB_NAME=depictioDB\n# DEPICTIO_MONGODB_PORT=27018\n# DEPICTIO_MONGODB_SERVICE_NAME=mongo\n# DEPICTIO_MONGODB_WIPE=false\n\n# ----------------------------------------------------------------------------\n# FastAPI Server Configuration\n# ----------------------------------------------------------------------------\n# API server network settings\n# DEPICTIO_FASTAPI_HOST=0.0.0.0\n# DEPICTIO_FASTAPI_PORT=8058\n# DEPICTIO_FASTAPI_SERVICE_NAME=depictio-backend\n# DEPICTIO_FASTAPI_LOGGING_LEVEL=INFO\n# DEPICTIO_FASTAPI_WORKERS=1\n# DEPICTIO_FASTAPI_SSL=false\n# DEPICTIO_FASTAPI_PUBLIC_URL=http://localhost:8058\n\n# ----------------------------------------------------------------------------\n# Dash Frontend Configuration\n# ----------------------------------------------------------------------------\n# Dashboard server network settings\n# DEPICTIO_DASH_HOST=0.0.0.0\n# DEPICTIO_DASH_PORT=5080\n# DEPICTIO_DASH_SERVICE_NAME=depictio-frontend\n# DEPICTIO_DASH_WORKERS=1\n# DEPICTIO_DASH_DEBUG=true\n\n# ----------------------------------------------------------------------------\n# Authentication Configuration\n# ----------------------------------------------------------------------------\n# Authentication and key management\n# DEPICTIO_AUTH_TMP_TOKEN=eyJhb...\n# DEPICTIO_AUTH_KEYS_DIR=depictio/keys\n# DEPICTIO_AUTH_KEYS_ALGORITHM=RS256\n# DEPICTIO_AUTH_CLI_CONFIG_DIR=depictio/.depictio\n# DEPICTIO_AUTH_UNAUTHENTICATED_MODE=false\n\n# Google OAuth2 Configuration\n# DEPICTIO_AUTH_GOOGLE_OAUTH_ENABLED=true\n# DEPICTIO_AUTH_GOOGLE_OAUTH_CLIENT_ID=\"64285070862-***.apps.googleusercontent.com\"\n# DEPICTIO_AUTH_GOOGLE_OAUTH_CLIENT_SECRET=\"GOCSPX-***\"\n# DEPICTIO_AUTH_GOOGLE_OAUTH_REDIRECT_URI=\"http://localhost:5080/auth\"\n\n# ----------------------------------------------------------------------------\n# System Configuration\n# ----------------------------------------------------------------------------\n# Container user and group IDs (uncomment to set specific values)\n#UID=502\n#GID=20\n\n# ----------------------------------------------------------------------------\n# Development Settings (Keep at the end for contributors)\n# ----------------------------------------------------------------------------\n# Toggle development mode for the application\n# DEV_MODE=false\n\n# Enable Playwright development mode for testing\n# DEPICTIO_PLAYWRIGHT_DEV_MODE=false\n# ============================================================================\n</code></pre> <p>Edit the <code>.env</code> file to customize your configuration if needed. The default values should work for most users.</p>"},{"location":"installation/docker/#3-start-the-services-including-minio","title":"3. Start the Services (including MinIO)","text":"<p>Start all Depictio services using Docker Compose:</p> <pre><code>docker compose -f docker-compose.yaml \\\n               -f docker-compose/docker-compose.minio.yaml \\\n               up -d\n</code></pre> <p>This command will:</p> <ul> <li>Pull the necessary Docker images (latest by default, can be changed in the <code>.env</code> file)</li> <li>Create and start containers for MongoDB, the Depictio backend &amp; frontend, and MinIO</li> <li>Set up the required network connections between services</li> </ul> <p>Note</p> <p>If you wish to use your own MinIO instance, you can skip the <code>docker-compose/docker-compose.minio.yaml</code> file. In this case, make sure to set the <code>MINIO_</code> variables accordingly in your <code>.env</code> file to point to your MinIO instance.</p>"},{"location":"installation/docker/#4-verify-the-installation","title":"4. Verify the Installation","text":"<p>After starting the services, you can verify that everything is running correctly:</p> <pre><code>docker compose ps\n</code></pre> <p>You should see all services in the \"Up\" state.</p>"},{"location":"installation/docker/#accessing-depictio","title":"Accessing Depictio","text":"<p>Once the services are running, you can access:</p> <ul> <li>Frontend (Dash): http://localhost:5080</li> <li>Backend API: http://localhost:8058</li> <li>API Documentation: http://localhost:8058/docs</li> <li>Minio UI: http://localhost:9001</li> </ul> <p>Default credentials are:</p> <ul> <li>Depictio Admin credentials: login: <code>admin@example.com</code> / password: <code>changeme</code></li> <li>MinIO credentials: login: <code>minio</code> / password: <code>minio123</code></li> </ul>"},{"location":"installation/docker/#managing-the-services","title":"Managing the Services","text":""},{"location":"installation/docker/#stopping-the-services","title":"Stopping the Services","text":"<p>To stop all services while preserving data:</p> <pre><code>docker compose stop\n</code></pre>"},{"location":"installation/docker/#stopping-and-removing-containers","title":"Stopping and Removing Containers","text":"<p>To stop all services and remove the containers:</p> <pre><code>docker compose down\n</code></pre>"},{"location":"installation/docker/#stopping-and-removing-everything","title":"Stopping and Removing Everything","text":"<p>To stop all services, remove the containers, and delete all data:</p> <pre><code>docker compose down -v\n</code></pre> <p>Warning: This will delete all data stored in MongoDB and MinIO.</p>"},{"location":"installation/docker/#viewing-logs","title":"Viewing Logs","text":"<p>To view the logs from all services:</p> <pre><code>docker compose logs\n</code></pre> <p>To view logs from a specific service:</p> <pre><code>docker compose logs depictio-backend\n</code></pre> <p>To follow the logs in real-time:</p> <pre><code>docker compose logs -f\n</code></pre>"},{"location":"installation/docker/#configuration-options","title":"Configuration Options","text":""},{"location":"installation/docker/#ports","title":"Ports","text":"<p>By default, Depictio uses the following ports:</p> <ul> <li>5080: Frontend (Dash)</li> <li>8058: Backend API</li> <li>27018: MongoDB</li> <li>9000: MinIO API</li> <li>9001: MinIO UI</li> </ul> <p>If you need to change these ports, edit the <code>.env</code> file.</p>"},{"location":"installation/docker/#development-mode","title":"Development Mode","text":"<p>To run Depictio using Flask/Dash/gunicorn and FastAPI/uvicorn debug mode, which enables additional debugging features, modify the <code>.env</code> file:</p> <pre><code>DEV_MODE=true\n</code></pre> <p>and then start the services:</p> <pre><code>docker compose up -d\n</code></pre> <p>Or:</p> <pre><code>DEV_MODE=true docker compose up -d\n</code></pre>"},{"location":"installation/docker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/docker/#container-fails-to-start","title":"Container Fails to Start","text":"<p>If a container fails to start, check the logs:</p> <pre><code>docker compose logs &lt;service_name&gt;\n</code></pre> <p>Common issues include:</p> <ul> <li>Port conflicts (another application is using the same port)</li> <li>Insufficient permissions for mounted volumes</li> <li>MongoDB connection issues</li> </ul>"},{"location":"installation/docker/#cannot-connect-to-services","title":"Cannot Connect to Services","text":"<p>If you cannot connect to the services, check:</p> <ol> <li>That the containers are running: <code>docker-compose ps</code></li> <li>That you're using the correct ports</li> <li>That there are no firewall rules blocking the connections</li> </ol>"},{"location":"installation/docker/#data-persistence-issues","title":"Data Persistence Issues","text":"<p>By default, MongoDB data is stored in the <code>./depictioDB</code> directory. Make sure this directory has the correct permissions.</p>"},{"location":"installation/docker/#next-steps","title":"Next Steps","text":"<p>Now that you have Depictio running, you can:</p> <ul> <li>Get started with using Depictio</li> <li>Learn how to create dashboards</li> <li>Configure the CLI for data ingestion</li> </ul>"},{"location":"installation/install/","title":"Install","text":""},{"location":"installation/install/#system-requirements","title":"System Requirements","text":"<p>Before installing Depictio, ensure your system meets the following requirements:</p>"},{"location":"installation/install/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>CPU: 2 cores</li> <li>RAM: 4GB</li> <li>Disk Space: 10GB (plus additional space for your data)</li> <li>Operating System: Linux, macOS, or Windows with Docker support</li> </ul>"},{"location":"installation/kubernetes/","title":"Kubernetes Installation","text":"<p>This guide will walk you through deploying Depictio on a Kubernetes cluster using Helm charts.</p>"},{"location":"installation/kubernetes/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>Kubernetes 1.19+</li> <li>Helm 3.2.0+</li> <li>PV provisioner support in the underlying infrastructure (if persistence is enabled)</li> </ul>"},{"location":"installation/kubernetes/#installation-steps","title":"Installation Steps","text":""},{"location":"installation/kubernetes/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<pre><code>git clone https://github.com/depictio/depictio.git\ncd depictio\n</code></pre>"},{"location":"installation/kubernetes/#step-2-install-the-chart","title":"Step 2: Install the Chart","text":"<p>To install the chart with the release name <code>depictio</code>:</p> <pre><code>helm install &lt;RELEASE_NAME&gt; depictio ./helm-charts/depictio -f ./helm-charts/depictio/values.yaml -n &lt;YOUR_NAMESPACE&gt;\n</code></pre> <p>This command deploys Depictio on the Kubernetes cluster with the default configuration.</p>"},{"location":"installation/kubernetes/#step-3-verify-the-installation","title":"Step 3: Verify the Installation","text":"<p>Check that all pods are running:</p> <pre><code>kubectl get pods -n &lt;YOUR_NAMESPACE&gt;\n</code></pre> <p>You should see pods for the backend, frontend, MongoDB, and MinIO.</p>"},{"location":"installation/kubernetes/#accessing-depictio","title":"Accessing Depictio","text":"<p>After deploying the chart, you can access the Depictio application:</p> <ul> <li>If using ClusterIP (default), use port-forwarding to access the frontend service:</li> </ul> <pre><code>kubectl port-forward -n &lt;YOUR_NAMESPACE&gt; service/depictio-frontend 5080:80\n</code></pre> <p>Then visit http://localhost:5080 in your browser.</p>"},{"location":"installation/kubernetes/#customizing-the-installation","title":"Customizing the Installation","text":"<p>You can customize the chart by overriding its values in a separate YAML file:</p> <pre><code>helm install &lt;RELEASE_NAME&gt; ./helm-charts/depictio \\\n    -f ./helm-charts/depictio/values.yaml \\\n    -f ./my-custom-values.yaml \\\n    -n &lt;YOUR_NAMESPACE&gt;\n</code></pre> <p>For a complete list of configurable parameters, refer to the <code>values.yaml</code> file or run:</p> <pre><code>helm show values ./helm-charts/depictio\n</code></pre>"},{"location":"installation/kubernetes/#uninstalling","title":"Uninstalling","text":"<p>To uninstall/delete the  deployment: <pre><code>helm uninstall &lt;RELEASE_NAME&gt;\n</code></pre>"},{"location":"installation/kubernetes/#key-configuration-parameters","title":"Key Configuration Parameters","text":"<p>Here are some of the key parameters you can configure:</p>"},{"location":"installation/kubernetes/#storage","title":"Storage","text":"<p>The chart supports persistence for various components:</p> <ul> <li>MongoDB data</li> <li>MinIO storage</li> <li>Screenshots</li> <li>Example data</li> </ul> <p>By default, all persistence is enabled with appropriate storage sizes.</p>"},{"location":"installation/kubernetes/#services","title":"Services","text":"<ul> <li>Backend API: Accessible on port 8058</li> <li>Frontend: Accessible on port 5080</li> <li>MongoDB: Accessible on port 27018</li> <li>MinIO: Accessible on ports 9000 (API) and 9001 (Console)</li> </ul> <p>For more detailed configuration options, please refer to the Helm chart README.</p>"},{"location":"more/","title":"Additional Resources","text":"<p>This section provides supplementary information and resources related to the Depictio project.</p>"},{"location":"more/#in-this-section","title":"In This Section","text":"<ul> <li>Funding - Information about how the Depictio project is funded</li> <li>Color Palette - Official color palette and design guidelines</li> </ul>"},{"location":"more/#community","title":"Community","text":"<p>Depictio is an open-source project with an active community. Connect with us through:</p> <ul> <li>GitHub: github.com/depictio/depictio</li> </ul>"},{"location":"more/#license","title":"License","text":"<p>Depictio is open-source software released under the MIT License.</p>"},{"location":"more/#acknowledgements","title":"Acknowledgements","text":"<p>We thank all contributors and the following projects that make Depictio possible:</p> <ul> <li>FastAPI</li> <li>Plotly Dash</li> <li>MongoDB</li> <li>MinIO</li> <li>Docker</li> <li>Kubernetes</li> </ul>"},{"location":"more/#contact","title":"Contact","text":"<ul> <li>General Inquiries: thomas.weber@embl.de</li> <li>Technical Support: GitHub Issues</li> </ul>"},{"location":"more/funding/","title":"Funding","text":"<p>Funding and Support</p> <p>Depictio is developed with the support of academic and public funding, enabling us to provide a free and open-source platform for the bioinformatics community.</p> Marie Sk\u0142odowska-Curie Grant <p>This project has received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sk\u0142odowska-Curie grant agreement No 945405</p> Learn More ARISE Programme <p>ARISE is a postdoctoral research programme for technology developers, hosted at EMBL.</p> Learn More EMBL <p>The European Molecular Biology Laboratory is Europe's flagship laboratory for the life sciences.</p> Learn More"},{"location":"more/funding/#academic-partners","title":"Academic Partners","text":"SciLifeLab Data Centre <p>SciLifeLab Data Centre provides data-driven life science research infrastructure and expertise to accelerate open science in Sweden and beyond.</p> Learn More"},{"location":"more/palette/","title":"Color Palette","text":"<p>This page demonstrates the Depictio brand colors and how to use them in your applications.</p>"},{"location":"more/palette/#brand-colors","title":"Brand Colors","text":"<p>The Depictio brand uses a consistent color palette to maintain visual identity across all platforms and applications.</p>"},{"location":"more/palette/#using-the-colors-in-your-code","title":"Using the Colors in Your Code","text":""},{"location":"more/palette/#python","title":"Python","text":"<pre><code># Colors definition for Python applications\ncolors = {\n    \"purple\": \"#9966CC\",\n    \"violet\": \"#7A5DC7\",\n    \"blue\": \"#6495ED\",\n    \"teal\": \"#45B8AC\",\n    \"green\": \"#8BC34A\",\n    \"yellow\": \"#F9CB40\",\n    \"orange\": \"#F68B33\",\n    \"pink\": \"#E6779F\",\n    \"red\": \"#E53935\",\n    \"black\": \"#000000\",\n}\n\n# Color combinations\ncolor_sequences = {\n    \"main\": [colors[\"purple\"], colors[\"blue\"], colors[\"teal\"], colors[\"green\"],\n            colors[\"yellow\"], colors[\"orange\"], colors[\"pink\"]],\n    \"cool\": [colors[\"purple\"], colors[\"violet\"], colors[\"blue\"], colors[\"teal\"]],\n    \"warm\": [colors[\"yellow\"], colors[\"orange\"], colors[\"red\"], colors[\"pink\"]],\n    \"alert\": [colors[\"green\"], colors[\"yellow\"], colors[\"orange\"], colors[\"red\"]],\n}\n\n# Example usage in Dash\nimport dash_mantine_components as dmc\n\nbutton = dmc.Button(\n    \"Primary Action\",\n    styles={\n        \"root\": {\n            \"backgroundColor\": colors[\"blue\"],\n            \"&amp;:hover\": {\"backgroundColor\": colors[\"blue\"] + \"cc\"},\n        }\n    },\n)\n</code></pre>"},{"location":"more/palette/#css","title":"CSS","text":"<pre><code>:root {\n  --depictio-purple: #9966cc;\n  --depictio-violet: #7a5dc7;\n  --depictio-blue: #6495ed;\n  --depictio-teal: #45b8ac;\n  --depictio-green: #8bc34a;\n  --depictio-yellow: #f9cb40;\n  --depictio-orange: #f68b33;\n  --depictio-pink: #e6779f;\n  --depictio-red: #e53935;\n  --depictio-black: #000000;\n}\n\n.btn-primary {\n  background-color: var(--depictio-blue);\n  color: white;\n}\n\n.btn-danger {\n  background-color: var(--depictio-red);\n  color: white;\n}\n\n.btn-success {\n  background-color: var(--depictio-green);\n  color: white;\n}\n</code></pre>"},{"location":"more/stories/","title":"Stories","text":"<p>This section is under construction and will be updated soon.</p>"},{"location":"roadmap/","title":"Roadmap","text":""},{"location":"roadmap/#big-picture-what-we-want-to-achieve","title":"Big Picture - What we want to achieve","text":"<p>Visualization Studio</p> Phase 1: Foundation \u2705<p>Interactive dashboards with modern web components and real-time data binding</p> <p>Data Ingestion</p> Phase 1: Foundation \u2705<p>Support for multiple tabular formats: Parquet, CSV, JSON, TSV with automated processing</p> <p>MultiQC Integration</p> Phase 2: Specialization \ud83d\udea7<p>Seamless integration with bioinformatics quality control reports</p> <p>Configuration Assistant</p> Phase 2: Specialization \ud83d\udea7<p>CLI-based project setup wizard with intelligent recommendations</p> <p>Workflow Templates</p> Phase 3: Ecosystem \ud83d\udccb<p>Pre-configured dashboards for popular bioinformatics workflows and pipelines</p>"},{"location":"roadmap/#what-we-have-now","title":"What we have now","text":""},{"location":"roadmap/#data-ingestion-data-types-supported","title":"Data ingestion &amp; data types supported","text":"<ul> <li> Data ingestion using Depictio-CLI (python package based typer) using YAML configuration file</li> <li> Polars-compatible data format (Parquet, CSV, JSON, TSV) ingestion and transformation into Delta Lake format</li> <li> Delta lake push to S3 bucket (on-premise or remote MinIO)</li> <li> Comprehensive S3 backup and restore strategy with CLI commands and API endpoints</li> <li> Performance optimization with caching for iterative joins and component data</li> <li> Enhanced CLI execution with run commands and improved logging</li> </ul>"},{"location":"roadmap/#authentication","title":"Authentication","text":"<ul> <li> Basic authentication (username/password) &gt; register, login, logout</li> <li> JWT token management</li> <li> Refresh token support with enhanced security and session persistence</li> <li> Public/private &amp; API internal key creation</li> <li> Profile management (change password)</li> <li> Create CLI configuration through the web interface (YAML to be copy-pasted)</li> <li> Google OAuth authentication integration</li> <li> Unauthenticated mode with automatic anonymous login for public access</li> <li> Temporary user functionality with session management and upgrade options</li> </ul>"},{"location":"roadmap/#dashboards-management","title":"Dashboards management","text":"<ul> <li> Create a dashboard for a project</li> <li> Edit name, duplicate, delete a dashboard</li> <li> Make public/private a dashboard at the instance level</li> </ul>"},{"location":"roadmap/#dashboard-design-and-interactivity","title":"Dashboard design and interactivity","text":"<ul> <li> Dashboard design using generic components (figure, metrics card, interactive component, table)</li> <li> Add/delete components</li> <li> Resize and relayout components</li> <li> Edit components (title, aggregation applied)</li> <li> Duplicate components</li> <li> Enable/disable interactivity</li> <li> Enable/disable edit mode</li> <li> Auto-save dashboard + manual save (trigger screenshot to be used as thumbnail)</li> </ul>"},{"location":"roadmap/#project-management","title":"Project management","text":"<ul> <li> Project management UI to list workflows and data collections</li> <li> List and edit project permissions</li> <li> Turn public/private a project</li> </ul>"},{"location":"roadmap/#admin","title":"Admin","text":"<ul> <li> Admin interface to list and manage users (delete functionality only)</li> <li> Admin interface to list projects</li> <li> Admin interface to list dashboards</li> </ul>"},{"location":"roadmap/#testing-quality-assurance","title":"Testing &amp; Quality Assurance","text":"<ul> <li> Pre-commit hooks for code quality enforcement</li> <li> Comprehensive end-to-end testing with Cypress</li> <li> Enhanced CI/CD workflows with automated testing</li> <li> Integration tests for various components and workflows</li> <li> Flask security assessment scanner integration</li> <li> Improved test reliability and coverage</li> </ul>"},{"location":"roadmap/#infrastructure-deployment","title":"Infrastructure &amp; Deployment","text":"<ul> <li> Docker containerization with multi-architecture support (AMD64/ARM64)</li> <li> Kubernetes deployment with Helm charts</li> <li> Enhanced Helm chart configuration with persistent volumes and ingress</li> <li> Gitpod workspace setup for streamlined development</li> <li> Automated release workflows with changelog generation</li> <li> Implement astral/ty as static type checking &amp; in pre-commit hooks</li> <li> Allow users to provide their own set of public/private keys</li> </ul>"},{"location":"roadmap/#ui","title":"UI","text":"<ul> <li> Functional dark/light mode theming with auto-theme detection</li> <li> Upgrade dash to the latest version (v3+)</li> <li> Upgrade dash mantine components to the latest version (2.0+) with enhanced components and styling</li> <li> Improve UI/UX (e.g., loading spinner, error handling, etc.)</li> <li> Improve dashboard layout and component resizing with vertical and horizontal growing</li> </ul>"},{"location":"roadmap/#what-we-plan-for-the-future","title":"What we plan for the future","text":""},{"location":"roadmap/#data-ingestion-data-types-supported_1","title":"Data ingestion &amp; data types supported","text":"<ul> <li> Support MultiQC report integration (leverage MultiQC 1.29 with parquet file)</li> <li> Support for genome-browser tracks through JBrowse2 (e.g., VCF, BAM, BED, GFF)</li> <li> Data ingestion template for heavily-used and standardized nf-core community workflows (<code>depictio-cli scan --template nf-core/sarek .</code>)</li> <li> Single file loading (HTTP polars) without using CLI</li> <li> S3 bucket automatic cleanup when delta not listed in DB</li> </ul>"},{"location":"roadmap/#authentication_1","title":"Authentication","text":"<ul> <li> OAuth2 authentication (GitHub, etc.) - Google OAuth already implemented</li> <li> SSO/SAML authentication - partial SAML integration completed</li> <li> Groups management</li> </ul>"},{"location":"roadmap/#dashboards-management_1","title":"Dashboards management","text":"<ul> <li> Dashboard sharing with specific users or groups</li> <li> Tagging system for dashboards</li> </ul>"},{"location":"roadmap/#dashboard-design-and-interactivity_1","title":"Dashboard design and interactivity","text":"<ul> <li> Implement JBrowse2 component for genome browser tracks</li> <li> High-dimensional data methods (e.g., UMAP, PCA, t-SNE)</li> <li> Omics data visualization methods (e.g., Volcano plot, ...)</li> <li> Markdown component</li> <li> Extend interactive component (date, radio, ...)</li> <li> Improve component (e.g., slider values range, figure styling and properties, etc.)</li> <li> Add more grouping functionalities</li> </ul>"},{"location":"roadmap/#admin_1","title":"Admin","text":"<ul> <li> Move admin interface to a dedicated FastAPI dashboard using FastAPI-Users and FastAPI-Admin</li> <li> List and manage groups</li> <li> Admin interface to list and manage API keys</li> <li> Update endpoints policy (hide/unprotect when needed)</li> </ul>"},{"location":"roadmap/#development-infrastructure","title":"Development &amp; Infrastructure","text":"<ul> <li> Build separate containers for frontend and backend</li> <li> Performance testing for polars read/write from S3 with/without dashboard rendering</li> </ul>"},{"location":"roadmap/#templates-workflows","title":"Templates &amp; Workflows","text":"<ul> <li> Depictio templates system for workflow integration</li> <li> Dashboard templates for standardized nf-core workflows</li> <li> Template validation and CI/CD integration</li> <li> Template marketplace with screenshots and descriptions</li> </ul>"},{"location":"roadmap/#ui_1","title":"UI","text":"<ul> <li> Further theme customization (colors, fonts) and CSS styling enhancements</li> </ul>"},{"location":"usage/","title":"Usage","text":"<p>This section provides guidance on how to effectively use Depictio to create and manage interactive dashboards for visualizing bioinformatics data.</p>"},{"location":"usage/#getting-started","title":"Getting Started","text":"<p>After installing Depictio, you can begin by:</p> <ul> <li>Accessing the web interface</li> <li>Setting up your first project</li> <li>Creating your first dashboard</li> <li>Ingesting data using the CLI tool</li> </ul> <p>For a step-by-step introduction, see the Getting Started Guide.</p>"},{"location":"usage/#key-steps","title":"Key steps","text":"<p>Depictio supports several key steps:</p> <ol> <li>Data Ingestion - Import your data into Depictio using the CLI tool</li> <li>Project Management - Organize your data into projects</li> <li>Dashboard Creation - Design interactive dashboards to visualize your data</li> <li>Data Exploration - Interact with your data through filters and selections</li> <li>Sharing - Share your dashboards with collaborators in the same Depictio instance (for now)</li> </ol>"},{"location":"usage/#available-guides","title":"Available Guides","text":"<p>Explore our detailed guides to learn more about specific aspects of Depictio:</p> <ul> <li>Web UI Guide - Navigate and use the Depictio web interface</li> <li>Dashboard Creation Guide - Create and configure dashboards</li> <li>Dashboard Usage Guide - Interact with and explore dashboards</li> <li>Unauthenticated Mode Guide - Use Depictio without authentication for quick access</li> </ul>"},{"location":"usage/#cli-tool","title":"CLI Tool","text":"<p>The Depictio CLI tool is essential for data ingestion and management. Learn how to use it effectively:</p> <ul> <li>CLI Usage Guide - Basic and advanced CLI commands</li> <li>YAML Configuration Reference - Configure the CLI tool</li> </ul>"},{"location":"usage/administration/","title":"Admin UI","text":"<p>This section is under construction and will be updated soon.</p>"},{"location":"usage/get_started/","title":"Getting Started with Depictio","text":"<p>This guide will help you get started with Depictio after installation. It covers the basic concepts and workflows to help you begin visualizing your data.</p>"},{"location":"usage/get_started/#first-steps","title":"First Steps","text":""},{"location":"usage/get_started/#installation","title":"Installation","text":"<p>If you haven't installed Depictio yet, please refer to the installation guide for detailed instructions on how to set up Depictio using Docker Compose, or Helm.</p>"},{"location":"usage/get_started/#accessing-the-web-interface","title":"Accessing the Web Interface","text":"<p>After installation see the installation guide, you can access the Depictio web interface. If you used Docker Compose or the helm chart with a local setup, the default port is <code>5080</code>. Open your web browser and navigate to:</p> <pre><code>http://localhost:5080\n</code></pre>"},{"location":"usage/get_started/#logging-in","title":"Logging In","text":"<p>When you first access Depictio, you'll be prompted to log in. The default installation creates an admin user with:</p> <ul> <li>Email: <code>admin@example.com</code></li> <li>Password: <code>changeme</code></li> </ul> <p>Important</p> <p>Change the default password after your first login for security reasons.</p>"},{"location":"usage/get_started/#use-existing-demo-data","title":"Use existing demo data","text":"<p>If you want to explore Depictio with existing demo data, you can use the provided registered iris dataset. A demo dashboard is also already created for you to explore. You can access it by clicking on the \"Iris Dashboard\" on the landing page.</p>"},{"location":"usage/get_started/#register-your-first-project","title":"Register your first project","text":""},{"location":"usage/get_started/#using-the-web-interface","title":"Using the Web Interface","text":"<ol> <li>Open the Projects section: Click on the \"Projects\" link in the sidebar.</li> <li>Click on \"Create Project\": This will open the project creation form.</li> <li> <p>Select Basic Project and enter project details:</p> <ul> <li>Project Name: Enter a name for your project.</li> <li> <p>Description: Optionally, provide a description for your project.</p> <ul> <li>Advanced: For workflow-based projects with multiple data collections.</li> </ul> </li> </ul> </li> <li> <p>Navigate to the \"Data Collections\" tab: This is where you will add your data.</p> </li> <li> <p>Add Data Collections:</p> <ul> <li>Click on the \"Create Data Collection\" button.</li> <li>Enter a name for your data collection.</li> <li>Fill in required information such as:<ul> <li>Data Collection Name: A unique name for your data collection.</li> <li>Description: Optionally, provide a description for your data collection.</li> <li>File format: Choose the format of your data (e.g., CSV, Parquet).</li> </ul> </li> </ul> </li> <li> <p>Upload Data:</p> <ul> <li>Drag and drop your data files or use the file picker to select files from your local system.</li> <li>Supported formats include CSV, TSV, Excel, Parquet, and Feather.</li> </ul> </li> </ol> <p>\ud83c\udfac Basic Project Creation: Watch how to create a basic project from scratch - upload data, configure settings, and start visualizing in minutes</p>"},{"location":"usage/get_started/#using-depictio-cli","title":"Using depictio-cli","text":"<p> Use the command-line interface to programmatically manage your Depictio projects and data.</p>"},{"location":"usage/get_started/#install-the-depictio-cli-tool","title":"Install the depictio-cli tool","text":"<p>Depictio provides a command-line interface (CLI) tool (<code>depictio-cli</code>) for managing data ingestion and other tasks. You can install the CLI tool by following the instructions in the depictio-cli documentation.</p>"},{"location":"usage/get_started/#create-a-cli-configuration","title":"Create a CLI configuration","text":"<p>Once you have installed the CLI tool, you need to create a configuration file to interact with Depictio. This configuration file contains the necessary information to connect to your Depictio instance, including the base URL and user credentials. To do so, go to the profile section in the web interface (bottom left corner).</p> <p>Once in the profile section, click in the CLI Agents button.</p> <p>You will land on the CLI Agents page, where you can manage your CLI configurations. To create a new configuration, click on the Add new configuration button.</p> <p>Select a name for your configuration and click on the Save button.</p> <p>This will generate a YAML file with the necessary configuration to interact with Depictio via the CLI. Save this file in a secure location (e.g., <code>~/.depictio/CLI.yaml</code>), and ensure it is not publicly accessible. Depending of your installation, the file will look like this:</p> <pre><code># ~/.depictio/CLI.yaml\nbase_url: http://localhost:8058\ns3:\n  bucket: depictio-bucket\n  external_host: localhost\n  external_port: 9000\n  external_protocol: http\n  external_service: false\n  public_url: null\n  root_password: minio123\n  root_user: minio\n  service_name: minio\n  service_port: 9000\nuser:\n  description: null\n  email: admin@example.com\n  flexible_metadata: null\n  hash: null\n  id: 6845c5892bf43fee63e14bab\n  is_admin: true\n  token:\n    access_token: eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\n    created_at: '2025-06-08 19:34:21'\n    description: null\n    expire_datetime: '2026-06-08 19:34:21'\n    flexible_metadata: null\n    hash: null\n    id: 6845e5bdce243952fac3e444\n    logged_in: false\n    name: TEST2\n    token_lifetime: long-lived\n    token_type: bearer\n    user_id: 6845c5892bf43fee63e14bab\n</code></pre>"},{"location":"usage/get_started/#use-the-cli-tool","title":"Use the CLI tool","text":"<p>You can now use the CLI tool to interact with your Depictio instance. For example, you can list available workflows, upload data collections, and manage your projects. Refer to the depictio-cli documentation for detailed usage instructions.</p> <p>In that get started guide, you can use the palmer penguins dataset to test the CLI tool. This dataset mimics the palmer penguins dataset, which is a popular dataset for testing data visualization tools.</p> <pre><code>depictio-cli run \\\n    --CLI-config-path ~/.depictio/CLI.yaml \\\n    --project-config-path ../api/v1/configs/penguins_dataset/penguins_project.yaml\n</code></pre> <p>This command will run the CLI tool with the specified configuration file and project configuration file. This will create a new project in Depictio with the palmer penguins dataset, including 2 data collections: <code>physical_features</code> and <code>demographic_data</code>.</p> <p>Once the data ingested into the system, you can go to the web interface and see the project created in the Project Management section.</p>"},{"location":"usage/get_started/#video-tutorial","title":"Video Tutorial","text":""},{"location":"usage/get_started/#creating-your-first-dashboard","title":"Creating Your First Dashboard","text":"<p>To create your first dashboard using the palmer penguins dataset, click on + New Dashboard in the top right corner of the web interface.</p> <p>This will open the dashboard creation wizard. Select the Palmer Penguins Species Comparison project from the dropdown menu, and then click on Create Dashboard.</p> <p>You will see a new dashboard created using the Palmer Penguins Species Comparison project.</p> <p>Then follow the dashboard creation guide and dashboard usage guide. These guides will walk you through the process of designing a dashboard, adding components, and configuring interactivity.</p>"},{"location":"usage/get_started/#next-steps","title":"Next Steps","text":"<p>Now that you understand the basics, you can:</p> <ul> <li> Learn more about dashboard creation</li> <li> Explore the dashboard components</li> <li> Set up the CLI for your own data</li> <li> Understand the API for integration</li> </ul>"},{"location":"usage/get_started/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues:</p> <ul> <li> Check the FAQ for common problems and solutions</li> <li> Review the logs for error messages</li> <li> Ensure your data is in a supported format</li> <li> Verify that all services are running correctly</li> <li> Report an issue on GitHub for bugs or feature requests</li> </ul>"},{"location":"usage/guides/dashboard_creation/","title":"Dashboard Creation","text":""},{"location":"usage/guides/dashboard_creation/#video-example","title":"Video example","text":"<p>\ud83c\udfac Depictio UI overview: Discover how to build a dashboard with Depictio</p>"},{"location":"usage/guides/dashboard_creation/#add-a-component-to-the-dashboard","title":"Add a component to the dashboard","text":""},{"location":"usage/guides/dashboard_creation/#step-1-component-selection","title":"Step 1: Component Selection","text":"<ol> <li>Begin by clicking on the \"+ New Dashboard\" button to create a new dashboard.</li> <li>In the \"Design your new dashboard component\" modal:</li> <li>Choose from the available components (e.g., Figure, Card, Interactive, Table, Text).</li> <li>Once you\u2019ve chosen the component, click Next Step.</li> </ol>"},{"location":"usage/guides/dashboard_creation/#step-2-data-selection","title":"Step 2: Data Selection","text":"<ol> <li>For each selected component, choose the corresponding workflow and data collection from the dropdowns.</li> <li>Verify the Data Collection Info, such as Workflow ID, Table type, MongoDB ID, and Data preview.</li> <li>Click Next Step to proceed.</li> </ol>"},{"location":"usage/guides/dashboard_creation/#step-3-customize-your-component","title":"Step 3: Customize Your Component","text":"<ol> <li> <p>Customise your component:</p> <ul> <li>For Figure components, you can select the type of figure (e.g., scatter plot, histogram) and customize its appearance.</li> <li>For Interactive components, you can set up interactive elements like sliders or dropdowns to allow users to filter or manipulate the data dynamically.</li> <li>For Card components, you can display key metrics of your data.</li> </ul> </li> </ol> <p>All options are dependent on the type of column in your data collection. For example, if you select a <code>numeric</code> column, you can choose to between a Slider or a RangeSlider for interactive components, and metrics like Mean, Median, or Standard Deviation for card components. If you select a <code>string</code> column, you can choose to display the Select/Multiselect or a SegmentedControl for interactive components, and metrics like Count or Unique Count for card components.</p> Data Type Interactive Options Card Metrics Numeric Slider, RangeSlider Mean, Median, Standard Deviation, Variance, ... String Select, Multiselect, SegmentedControl Count, Unique Count, Most Frequent (mode) <ol> <li> <p>Set additional parameters:</p> </li> <li> <p>For Figure components, you can tweak visualization settings such as colors, axis labels, and bin sizes. Settings are categorised in the following way:</p> <ul> <li>Core parameters: Define key parameters such as X-axis and Y-axis and Color, and assign the relevant data columns from your dataset.</li> <li>Styling &amp; Layout: Adjust the layout of the figure, including titles and axis labels, colors, hover data, and more.</li> <li>Figure type specific options: Access additional options specific to the figure type, such as scatter plot or histogram settings.</li> <li>Advanced: For advanced users, additional settings can be configured here like facetting, animation and more.</li> </ul> </li> <li> <p>For Interactive components, you can set adjust sliders to have a given number of marks, use a linear or logarithmic scale.</p> </li> <li> <p>Finalize Customization:</p> </li> <li>Review the component preview and ensure all settings are accurate.</li> <li>Once complete, click Next Step to proceed to the final stage.</li> </ol> <p>Note</p> <p>Figure component as now a mode to create figure through code as well. This allows you to write custom code or port existing one to generate the figure, providing flexibility for advanced users. You can access this mode by clicking on the \"Code\" tab in the figure design interface. Switching from UI to code mode using existing UI settings will automatically generate the code for you, which you can then modify as needed.</p>"},{"location":"usage/guides/dashboard_creation/#component-design-examples","title":"Component design Examples:","text":""},{"location":"usage/guides/dashboard_creation/#figure-design-visualization-selection","title":"Figure design - visualization selection","text":""},{"location":"usage/guides/dashboard_creation/#figure-design-scatter-plot-ui-mode","title":"Figure design - scatter plot - UI mode","text":""},{"location":"usage/guides/dashboard_creation/#figure-design-scatter-plot-code-mode","title":"Figure design - scatter plot - code mode","text":""},{"location":"usage/guides/dashboard_creation/#interactive-design-rangeslider-example","title":"Interactive design - RangeSlider example","text":""},{"location":"usage/guides/dashboard_creation/#card-design-metrics-selection","title":"Card design - metrics selection","text":""},{"location":"usage/guides/dashboard_usage/","title":"Using the Dashboard","text":""},{"location":"usage/guides/dashboard_usage/#right-sidebar-parameters","title":"Right Sidebar Parameters","text":"<p>The right sidebar allows you to customize the appearance and behavior of the dashboard. Currently it includes the following options:</p>"},{"location":"usage/guides/dashboard_usage/#switches","title":"Switches","text":"<ul> <li>Edit Dashboard layout: allow you to enable or disable the layout editing mode, which allows you to modify the size and position of the components, as well as show or hide the options of the components at the top of each component. When hidden, the options will not be displayed (except the reset button). See the Component-wise options section for more details. Interactions with the components are still enabled in this mode and you can still interact with the components.</li> <li>Toggle interactivity: enable or disable the interactivity of the components. When disabled, the components will not respond to user interactions.</li> </ul>"},{"location":"usage/guides/dashboard_usage/#buttons","title":"Buttons","text":"<ul> <li>Remove all components: remove all components from the dashboard.</li> <li>Reset all filters: reset all filters applied to the components.</li> </ul>"},{"location":"usage/guides/dashboard_usage/#component-wise-options","title":"Component-wise options","text":"<p>When the Display components options switch is enabled, each component will display a set of options at the top of the component. These options allow you to perform the following actions:</p> <ul> <li> Draggable: Move and reposition components within the dashboard layout using drag handles.</li> <li> Delete: Remove the component from the dashboard.</li> <li> Edit: Open a modal to modify the component settings.</li> <li> Clone: Create a copy of the component.</li> <li> Reset filters: Clear all filters applied to the component.</li> <li> Align: Choose text alignment (left, center, right) for text components.</li> </ul>"},{"location":"usage/guides/dashboard_usage/#interactivity","title":"Interactivity","text":""},{"location":"usage/guides/dashboard_usage/#interactive-actions","title":"Interactive Actions","text":"<p>There are currently two types of interactive actions available in the dashboard:</p> <ul> <li>Through the interactive components (e.g., RangeSlider, MultiSelect, etc.).</li> <li>Through the graph components (only Scatter plots are handled yet).</li> <li>Click mode: When you click on a point in the scatter plot, the other components will be updated according to the data point clicked.</li> <li>Selection mode: When you select a region in the scatter plot (using the \"Box select\" option), the other components will be updated according to the data points in the selected region.</li> </ul>"},{"location":"usage/guides/dashboard_usage/#reset-filters","title":"Reset Filters","text":"<ul> <li>Reset all filters You can reset all filters applied to the components by clicking the Reset all filters button in the right sidebar. This will clear all filters applied to the components and reset them to their default state.</li> <li>Reset interactive component/scatter plot filter You can reset the filters applied to the graph components by clicking the orange  Reset button in the component options at the top of the box. This will clear the filters applied to the graph component and reset it to its default state.</li> </ul>"},{"location":"usage/guides/dashboard_usage/#saving-the-dashboard","title":"Saving the Dashboard","text":"<ol> <li>Once your dashboard is ready, click the Save icon (green button at the top right).</li> <li>A modal will appear confirming that your dashboard has been saved (e.g., \"Your amazing dashboard was successfully saved!\").</li> <li>Click Close to dismiss the modal.</li> <li>Your dashboard will now appear with a thumbnail under the Recently Viewed section on the landing page.</li> </ol>"},{"location":"usage/guides/dashboard_usage/#example-dashboard-result","title":"Example Dashboard result","text":""},{"location":"usage/guides/unauthenticated_mode/","title":"Unauthenticated Mode","text":""},{"location":"usage/guides/unauthenticated_mode/#overview","title":"Overview","text":""},{"location":"usage/guides/unauthenticated_mode/#what-is-unauthenticated-mode","title":"What is Unauthenticated Mode?","text":"<p>In unauthenticated mode, user lands as a temporary anonymous user with limited access. This anonymous user can only access the existing public dashboards and play with the interactive features in a stateless manner (no database persistence), but cannot create or modify dashboards. This mode is ideal for quick demonstrations or public sharing of dashboards without requiring user authentication.</p> <p>If the user wants to create its own dashboard, modify existing ones using the same dataset, or create its own basic project and upload a dataset, they can switch to a temporary authenticated user mode. The temporary user will have a limited session duration (24h by default), after which dashboards will be cleared.</p> <p>Example unauthenticated mode URL is available on documentation landing page: https://depictio.github.io/depictio-docs/latest/.</p>"},{"location":"usage/guides/unauthenticated_mode/#screenshots","title":"Screenshots","text":"<p>Unauthenticated mode landing page - AnonymousUser is logged as anonymous and needs to login to access more features (create/duplicate dashboards, create project, upload dataset)</p> <p>Account status switch modalOnce the user wants to access more features, they can switch to a temporary authenticated user mode. The user and the related session information (dashboards, projects, etc.) will be stored temporarily (24h by default).</p> <p>Unauthenticated mode landing page - Temporary userUser is now logged in as a temporary user and can access more features (create/duplicate dashboards, create project, upload dataset) for a limited time (24h by default).</p>"},{"location":"usage/guides/unauthenticated_mode/#configuration","title":"Configuration","text":""},{"location":"usage/guides/unauthenticated_mode/#environment-variables","title":"Environment Variables","text":"<p>Enable unauthenticated mode by setting these environment variables:</p> <pre><code># Enable unauthenticated access\nDEPICTIO_AUTH_UNAUTHENTICATED_MODE=true\n\n# Configure anonymous user settings\nDEPICTIO_AUTH_ANONYMOUS_USER_EMAIL=anonymous@depict.io\nDEPICTIO_AUTH_TEMPORARY_USER_EXPIRY_HOURS=24\n</code></pre>"},{"location":"usage/guides/unauthenticated_mode/#helm-deployment","title":"Helm Deployment","text":"<p>For Kubernetes deployments, use the provided values files:</p> <pre><code># Deploy with unauthenticated mode\nhelm upgrade --install your-release ./helm-charts/depictio \\\n  -f ./helm-charts/depictio/values.yaml \\\n  -f ./helm-charts/depictio/values-unauth.yaml \\\n  -n your-namespace\n</code></pre>"},{"location":"usage/guides/unauthenticated_mode/#limitations","title":"Limitations","text":"<ul> <li>Session-Based: Data and dashboards expire after configured time</li> <li>No Persistence: User data is not permanently stored</li> <li>No User Management: No user accounts, groups, or permissions</li> <li>Temporary Storage: All content is ephemeral</li> </ul>"},{"location":"usage/guides/unauthenticated_mode/#use-cases","title":"Use Cases","text":""},{"location":"usage/guides/unauthenticated_mode/#scientific-outreach-and-demonstrations","title":"Scientific Outreach and Demonstrations","text":"<ul> <li>Public sharing of dashboards</li> <li>Public demos and presentations</li> </ul>"},{"location":"usage/guides/unauthenticated_mode/#educational-use","title":"Educational Use","text":"<ul> <li>Training sessions</li> <li>Workshops and tutorials</li> <li>Proof-of-concept deployments</li> </ul>"},{"location":"usage/guides/unauthenticated_mode/#security-considerations","title":"Security Considerations","text":"<ul> <li>Public Access: Anyone can access the deployment</li> <li>Data Sensitivity: Only use with non-sensitive, public data (e.g., public &amp; published datasets ; data powering the visualizations could be extracted from the dashboard by scrapping the page)</li> <li>Resource Limits: Configure appropriate resource constraints</li> <li>Network Security: Use proper network isolation and ingress controls</li> </ul>"},{"location":"usage/guides/web_ui/","title":"Web UI","text":""},{"location":"usage/guides/web_ui/#register-and-login","title":"Register and login","text":""},{"location":"usage/guides/web_ui/#registering-an-account-sign-up","title":"Registering an Account (Sign Up)","text":"<ol> <li>Navigate to the Registration page by clicking the Register button on the login screen.</li> </ol> <ol> <li> <p>Enter your email address in the \"Email\" field.</p> </li> <li> <p>Create a password and enter it in the \"Password\" field. You can click the eye icon to view the password as you type and Confirm your password by re-entering it in the \"Confirm Password\" field.</p> </li> <li> <p>Click the Register button to submit your registration details.</p> </li> <li> <p>After successful registration, you can return to the login page by clicking the Back to Login button.</p> </li> </ol>"},{"location":"usage/guides/web_ui/#logging-in-sign-in","title":"Logging In (Sign In)","text":"<ol> <li>Open the Depictio Login page.</li> <li>Enter your email address in the \"Email\" field.</li> <li>Enter your password in the \"Password\" field.</li> <li>If you want to see the password as you type it, click the eye icon next to the password field.</li> <li>Once both fields are filled in, click the Login button.</li> <li>You will be redirected to the Depictio landing page (currently <code>/dashboards</code>).</li> </ol>"},{"location":"usage/guides/web_ui/#google-oauth-login","title":"Google OAuth Login","text":"<p>If you have configured Google OAuth for your Depictio instance (see Configuration), you can log in using your Google account. If the account does not exist, it will be created automatically.</p>"},{"location":"usage/guides/web_ui/#landing-page-dashboards-section-dashboards","title":"Landing page / Dashboards section (/dashboards)","text":""},{"location":"usage/guides/web_ui/#sidebar-navigation","title":"Sidebar Navigation","text":"<p>The left sidebar provides easy access to various sections of the application. This includes:</p> <ul> <li> Dashboards: View and manage your dashboards.</li> <li> Projects: Manage your projects and data collections.</li> <li> Administration (sysadmin users only): Access administrative features (only available to users with admin privileges).</li> <li> About: Information about the application and its repository.</li> <li> Profile: View and edit your user profile by clicking on the avatar icon in the bottom left corner.</li> </ul> <p>At the bottom of the sidebar, you will find:</p> <ul> <li>Theme toggle: Switch between light and dark themes.</li> <li>Server status: Displays the current server version and online status.</li> <li>User information: Displays your username and email (e.g., <code>test_user@example.com</code>).</li> </ul>"},{"location":"usage/guides/web_ui/#creating-a-new-dashboard","title":"Creating a New Dashboard","text":"<ol> <li>On the landing page, click the orange \"+ New Dashboard\" button located in the top right corner.</li> <li>A pop-up window will appear with a field labeled \"Dashboard Title\".</li> <li>Enter a name for your new dashboard.</li> <li>Your dashboard will be created with the title you provided and added to the section.</li> <li>Click the blue \"Create Dashboard\" button to create the dashboard.</li> <li>The new dashboard will appear in the section with informations including name, owner and status (public/private).</li> </ol>"},{"location":"usage/guides/web_ui/#functionalities","title":"Functionalities","text":""},{"location":"usage/guides/web_ui/#viewing-a-dashboard","title":"Viewing a Dashboard","text":"<ol> <li>Once a dashboard is created, it will appear under the section.</li> <li>Click the \"View\" button next to the dashboard name to open and explore its content.</li> </ol>"},{"location":"usage/guides/web_ui/#deleting-a-dashboard","title":"Deleting a Dashboard","text":"<ol> <li>To delete a dashboard, locate the dashboard in the section.</li> <li>Click the red \"Delete\" button next to the dashboard name.</li> <li>A confirmation pop-up will appear, asking \"Are you sure you want to delete this dashboard?\".</li> <li>Click \"Delete\" to permanently remove the dashboard, or \"Cancel\" to keep it.</li> </ol>"},{"location":"usage/guides/web_ui/#editing-dashboard-name","title":"Editing dashboard name","text":"<ol> <li>To edit the name of a dashboard, locate the dashboard in the section.</li> <li>Click the \"Edit name\" button next to the dashboard name.</li> <li>A pop-up window will appear with a field labeled \"New name\".</li> <li>Enter a new name for your dashboard.</li> <li>Click the blue \"Save\" button to save the new name.</li> </ol>"},{"location":"usage/guides/web_ui/#duplicating-a-dashboard","title":"Duplicating a dashboard","text":"<ol> <li>To duplicate a dashboard, locate the dashboard in the section.</li> <li>Click the \"Duplicate\" button next to the dashboard name.</li> <li>The dashboard will be duplicated and added to the section with the suffix \"(copy)\".</li> </ol> <p>Note</p> <p>  Both \"public\" and \"private\" dashboards are listed in the Dashboards section. Public dashboards are accessible to all users, while private dashboards are only visible to the user who created them. Only the user who created a private dashboard can edit, or delete it.</p>"},{"location":"usage/guides/web_ui/#projects-section-projects","title":"Projects section (/projects)","text":"<p>Complete Projects Documentation</p> <p>For comprehensive information about Projects in Depictio, see the dedicated Projects Guide.</p> <p>The Projects Guide covers:</p> <ul> <li>Project Types - Basic vs Advanced projects</li> <li>Creating Projects - Step-by-step instructions</li> <li>Configuration - YAML setup and examples</li> <li>Data Collections - File organization and processing</li> <li>Permissions - Access control and collaboration</li> <li>Best Practices - Optimization and troubleshooting</li> </ul> <p>Quick Links:</p> <ul> <li> Projects Guide - Complete project management</li> <li> YAML Examples - Configuration patterns</li> <li> Configuration Reference - Full parameter reference</li> </ul>"},{"location":"usage/guides/web_ui/#quick-overview","title":"Quick Overview","text":"<ul> <li>The left sidebar includes a \"Projects\" section where users can manage their projects</li> <li>Click on \"Projects\" to navigate and view them</li> <li>Projects organize your data and provide structure for dashboards</li> <li>You can access workflows and data collections recursively within each project</li> <li>Each entity allows you to view configuration details and preview data</li> </ul>"},{"location":"usage/guides/web_ui/#user-information-profile","title":"User Information (/profile)","text":"<p>You can access your user profile by clicking on the avatar icon in the bottom left corner of the sidebar. </p> <p>This section allows you to:</p> <ul> <li>View your username and email address</li> <li>Edit your password</li> <li>Generate CLI Configurations for command-line access (see CLI Usage)</li> </ul>"},{"location":"usage/guides/web_ui/#about-section-about","title":"About section (/about)","text":"<p>The About section provides information about the GitHub repository and the documentation.</p>"},{"location":"usage/guides/web_ui/#admin-section-admin","title":"Admin section (/admin)","text":"<p>The Admin section is only accessible to users with admin privileges. It allows admins to view users, projects and dashboards. The Users tab displays a list/delete/change status (sysadmin/standard) of all users registered in the system. The Dashboards tab displays a list of all dashboards while the Projects tab lists all projects. Admins can delete any project or dashboard, regardless of ownership.</p>"},{"location":"usage/projects/guide/","title":"Projects in Depictio","text":"<p>Projects are the foundation of data organization in Depictio. They serve as containers for your data and dashboards, providing structure and access control for your analysis.</p> <p>\ud83c\udfac Projects Management Overview: Discover how Depictio's project types organize your data workflow</p>"},{"location":"usage/projects/guide/#understanding-project-architecture","title":"Understanding Project Architecture","text":"<p>Every Depictio project contains:</p> <ul> <li>Core Project Information - Name, description, and metadata</li> <li>Data Organization - Either direct data collections (Basic) or workflow-based structure (Advanced)</li> <li>Permission System - Role-based access control with owners, editors, and viewers</li> <li>Dashboard Integration - Each  dashboard is linked to a project, allowing for interactive data exploration</li> <li>Storage Backend - Automatic conversion to Delta Lake format for optimal performance</li> </ul>"},{"location":"usage/projects/guide/#project-lifecycle","title":"Project Lifecycle","text":"<pre><code>graph TD\n    A[Create Project] --&gt; B{Project Type?}\n\n    B --&gt;|Basic| C1[Create Data Collection]\n    C1 --&gt; C2[Upload Data Files]\n    C2 --&gt; D[Data Processing]\n\n    B --&gt;|Advanced| D1[Define Project Config]\n    D1 --&gt; D2[Configure Workflows]\n    D2 --&gt; D2a{For each Workflow}\n    D2a --&gt; D3[Define 1 or Multiple&lt;br/&gt;Data Collections]\n    D3 --&gt; D2a\n    D2a --&gt;|All Workflows&lt;br/&gt;Configured| D4[Run CLI Validation]\n    D4 --&gt; D5[File Discovery &amp; Scanning]\n    D5 --&gt; D\n\n    D --&gt; E[Create Dashboards :material-view-dashboard:]\n    E --&gt; F[Share &amp; Collaborate]\n\n    %% Depictio teal theme styling - compatible with light/dark mode\n    classDef default fill:#45B8AC,stroke:#2E7D73,stroke-width:2px,color:#fff\n    classDef decision fill:#5FCBC4,stroke:#45B8AC,stroke-width:2px,color:#fff\n    classDef highlight fill:#2E7D73,stroke:#45B8AC,stroke-width:2px,color:#fff\n\n    class A,D,E,F highlight\n    class B,D2a decision</code></pre>"},{"location":"usage/projects/guide/#basic-projects","title":"Basic Projects","text":"<p>Perfect for: Direct data analysis and quick insights</p> <p>Use when: You have tabular data files ready for analysis and want immediate visualization capabilities.</p> <p>Basic projects provide an easy onboarding experience - upload your data and start creating interactive dashboards within minutes.</p> <p>\ud83c\udfac Basic Project Creation: Watch how to create a basic project from scratch - upload data and start visualizing in minutes</p>"},{"location":"usage/projects/guide/#core-features","title":"Core Features","text":"<ul> <li>\ud83d\ude80 Immediate Setup - No configuration files needed</li> <li>\ud83d\udcc1 Direct File Upload from WebUI - Drag and drop your data files</li> <li>\ud83d\udd04 Flexible Data Formats - CSV, Excel, Parquet, Feather</li> <li>\u26a1 Fast Processing - Direct conversion to Delta Lake format</li> <li>Instant Visualization - Start creating  dashboards immediately</li> </ul>"},{"location":"usage/projects/guide/#supported-file-formats","title":"Supported File Formats","text":"Format Extension Best Use Case CSV <code>.csv</code> Most common, universal compatibility TSV <code>.tsv</code> Tab-separated, good for scientific data Excel <code>.xlsx</code>, <code>.xls</code> Business data, multiple sheets Parquet <code>.parquet</code> Large datasets, optimal performance Feather <code>.feather</code> Fast I/O, preserves data types"},{"location":"usage/projects/guide/#creating-a-basic-project","title":"Creating a Basic Project","text":"Web Interface <ol> <li>Navigate to Projects - Click \"Projects\" in the main navigation</li> <li>Create Project - Click the \"Create Project\" button</li> <li>Choose Basic Type - Select \"Basic Project\" from the options</li> <li>Project Details - Fill in name and description</li> <li>Project data management - Navigate to the \"Data Collections\" tab</li> <li>Upload Data - Add your data files to collections by creating a new collection<ul> <li>Click \"Add Data Collection\"</li> <li>Drag and drop files or use the file picker</li> <li>Supported formats: CSV, TSV, Excel, Parquet, Feather</li> </ul> </li> <li>Start Visualizing - Create  dashboards with your data</li> </ol> CLI Method <ol> <li>Create Configuration File - Write a YAML file defining your project</li> </ol> <pre><code># Create a basic project configuration file - basic_project.yaml\nname: \"My Basic Project\"\nproject_type: \"basic\"\ndata_collections:\n  - data_collection_tag: \"my_data\"\n    config:\n      type: \"Table\"\n      metatype: \"Metadata\"\n      scan:\n        mode: \"single\"\n        scan_parameters:\n          filename: \"/path/to/data.csv\"\n      dc_specific_properties:\n        format: \"CSV\"\n        polars_kwargs:\n          separator: \",\"\n          has_header: true\n</code></pre> <ol> <li>Run CLI Command - Use the Depictio CLI to create the project</li> </ol> <pre><code># Process the project\ndepictio-cli run --project-config-path basic_project.yaml\n</code></pre>"},{"location":"usage/projects/guide/#advanced-projects","title":"Advanced Projects","text":"<p>Perfect for: Bioinformatics workflows and complex data pipelines</p> <p>Use when: You have automated pipelines generating data with standardized file organization and need to process multiple samples systematically.</p> <p>Advanced projects are designed for core facility-like setups where standardized workflows generate structured data across multiple samples, timepoints, or experimental conditions.</p>"},{"location":"usage/projects/guide/#core-features_1","title":"Core Features","text":"<ul> <li>\ud83d\udd2c Workflow Integration - Connect to nf-core, Nextflow, Snakemake, Galaxy pipelines</li> <li>\ud83d\udcca Multi-sample Analysis - Handle large number of samples</li> <li>\ud83d\udd0d File Discovery - Regex-based pattern matching for file organization</li> <li>\ud83d\udd17 Data Joining - Combine different data types into unified views</li> <li>\ud83d\udcc8 Scalable Processing - Delta Lake backend for large-scale data</li> </ul>"},{"location":"usage/projects/guide/#project-structure-example","title":"Project Structure Example","text":"<pre><code>study_directory/\n\u251c\u2500\u2500 depictio_project.yaml    # Configuration file\n\u251c\u2500\u2500 run_001/                 # First sample batch\n\u2502   \u251c\u2500\u2500 sample_A/\n\u2502   \u2502   \u251c\u2500\u2500 stats/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 sample_A_stats.tsv\n\u2502   \u2502   \u2514\u2500\u2500 analysis_results/\n\u2502   \u2502       \u2514\u2500\u2500 sample_A_analysis.tsv\n\u2502   \u2514\u2500\u2500 sample_B/\n\u2502       \u251c\u2500\u2500 stats/\n\u2502       \u2502   \u2514\u2500\u2500 sample_B_stats.tsv\n\u2502       \u2514\u2500\u2500 analysis_results/\n\u2502           \u2514\u2500\u2500 sample_B_analysis.tsv\n\u2514\u2500\u2500 run_002/                 # Second sample batch\n    \u251c\u2500\u2500 sample_C/\n    \u2502   \u251c\u2500\u2500 stats/\n    \u2502   \u2502   \u2514\u2500\u2500 sample_C_stats.tsv\n    \u2502   \u2514\u2500\u2500 analysis_results/\n    \u2502       \u2514\u2500\u2500 sample_C_analysis.tsv\n    \u2514\u2500\u2500 sample_D/\n        \u251c\u2500\u2500 stats/\n        \u2502   \u2514\u2500\u2500 sample_D_stats.tsv\n        \u2514\u2500\u2500 analysis_results/\n            \u2514\u2500\u2500 sample_D_analysis.tsv\n</code></pre>"},{"location":"usage/projects/guide/#configuration-file-format","title":"Configuration File Format","text":"<p>Advanced projects require a YAML configuration that describes data organization patterns:</p> <pre><code># =============================================================================\n# DEPICTIO ADVANCED PROJECT CONFIGURATION\n# =============================================================================\n\n# Project identification\nname: \"RNA-seq Expression Study\"\nproject_type: \"advanced\"\ndescription: \"Multi-sample RNA sequencing analysis\"\nis_public: false\n\n# Workflow definition\nworkflows:\n  - name: \"rnaseq_pipeline\"\n\n    # Workflow engine information\n    engine:\n      name: \"nextflow\" # or \"snakemake\", \"python\"\n      version: \"24.10.3\"\n\n    description: \"nf-core RNA-seq analysis pipeline\"\n    repository_url: \"https://github.com/my-org/my-nf-wf-rnaseq\"\n\n    # Data organization configuration\n    config:\n      # Data location settings\n      parent_runs_location:\n        - \"{DATA_LOCATION}/rnaseq-results\" # Environment variable\n        - \"/absolute/path/to/data\" # Alternative absolute path\n\n      # Run identification pattern\n      runs_regex: \".*\" # Matches all directories\n\n      # Data collections definition\n      data_collections:\n        # Sample statistics collection\n        - data_collection_tag: \"sample_stats\"\n          description: \"Per-sample quality control statistics\"\n\n          config:\n            type: \"Table\"\n            metatype: \"Aggregate\" # Combine multiple files\n\n            # File discovery settings\n            scan:\n              mode: \"recursive\"\n              scan_parameters:\n                regex_config:\n                  pattern: \"stats/.*_stats.tsv\"\n\n            # Processing configuration\n            dc_specific_properties:\n              format: \"TSV\"\n              polars_kwargs:\n                separator: \"\\t\"\n                has_header: true\n\n              # Column selection for performance\n              keep_columns:\n                - \"sample_id\"\n                - \"total_reads\"\n                - \"mapped_reads\"\n                - \"quality_score\"\n\n              # Human-readable descriptions\n              columns_description:\n                sample_id: \"Unique sample identifier\"\n                total_reads: \"Total sequencing reads\"\n                mapped_reads: \"Successfully aligned reads\"\n                quality_score: \"Overall sample quality metric\"\n\n        # Analysis results collection\n        - data_collection_tag: \"gene_expression\"\n          description: \"Gene expression analysis results\"\n\n          config:\n            type: \"Table\"\n            metatype: \"Aggregate\"\n\n            scan:\n              mode: \"recursive\"\n              scan_parameters:\n                regex_config:\n                  pattern: \"analysis_results/.*_analysis.tsv\"\n\n            dc_specific_properties:\n              format: \"TSV\"\n              polars_kwargs:\n                separator: \"\\t\"\n                has_header: true\n\n              keep_columns:\n                - \"sample_id\"\n                - \"gene_id\"\n                - \"expression_level\"\n                - \"p_value\"\n\n          # Data joining configuration\n          join:\n            on_columns:\n              - \"sample_id\"\n            how: \"inner\"\n            with_dc:\n              - \"sample_stats\" # Join with statistics\n</code></pre>"},{"location":"usage/projects/guide/#file-discovery-patterns","title":"File Discovery Patterns","text":"<p>Advanced projects use two scanning modes:</p>"},{"location":"usage/projects/guide/#single-file-mode","title":"Single File Mode","text":"<p>Perfect for metadata files or summary statistics generated once per project:</p> <pre><code>scan:\n  mode: \"single\"\n  scan_parameters:\n    filename: \"general_metadata_project_info.csv\"\n</code></pre>"},{"location":"usage/projects/guide/#recursive-mode","title":"Recursive Mode","text":"<p>Uses regex patterns to find files at any directory depth:</p> <pre><code>scan:\n  mode: \"recursive\"\n  scan_parameters:\n    regex_config:\n      pattern: \"star_salmon/.*/quant.sf\"\n</code></pre>"},{"location":"usage/projects/guide/#cli-workflow","title":"CLI Workflow","text":"<p>Process advanced projects using the CLI:</p> <pre><code># Complete workflow execution\ndepictio-cli run --project-config-path ./rnaseq_project.yaml\n</code></pre> <p>The CLI executes this pipeline:</p> <ol> <li>\u2705 Server Check - Verify connection to Depictio backend</li> <li>\u2705 S3 Storage Check - Validate cloud storage configuration</li> <li>\u2705 Config Validation - Ensure YAML structure is correct</li> <li>\u2705 Config Sync - Register project with server</li> <li>\u2705 File Scan - Discover files matching patterns</li> <li>\u2705 Data Process - Convert files to Delta Lake format</li> </ol>"},{"location":"usage/projects/guide/#project-types-comparison","title":"Project Types Comparison","text":"<p>Choose the right project type for your workflow:</p> Feature Basic Projects Advanced Projects Setup Complexity Minimal - Web UI or CLI YAML config + CLI required Data Sources UI File upload or CLI-based processing CLI-based processing File Organization Simple file management Structured directory patterns Multi-sample Support Single datasets Multi samples support Data Processing Direct conversion Aggregation &amp; joining Learning Curve Immediate Moderate (YAML knowledge) Scalability Small-medium datasets Large-scale studies"},{"location":"usage/projects/guide/#how-to-choose-the-right-project-type","title":"How to Choose the Right Project Type","text":"<p>Choose Basic when:</p> <ul> <li>\u2705 You have a limited number of files ready for analysis</li> <li>\u2705 One-time analysis or ad-hoc exploration</li> <li>\u2705 Manual data preparation is acceptable</li> <li>\u2705 Quick insights are the primary goal</li> </ul> <p>Choose Advanced when:</p> <ul> <li>\u2705 Automated pipelines generate your data</li> <li>\u2705 Standardized file organization exists</li> <li>\u2705 You need to aggregate data across samples/runs</li> <li>\u2705 Regular data updates are expected</li> </ul>"},{"location":"usage/projects/guide/#project-permissions","title":"Project Permissions","text":"<p>Depictio implements a comprehensive role-based permission system:</p>"},{"location":"usage/projects/guide/#permission-roles","title":"Permission Roles","text":"Role Capabilities Owner Full control - edit, delete, manage permissions Editor Modify project data, create/edit dashboards Viewer Read-only access to project and dashboards"},{"location":"usage/projects/guide/#public-projects","title":"Public Projects","text":"<p>Projects can be made public by:</p> <ul> <li>Setting <code>is_public: true</code> in configuration</li> <li>Using the web interface toggle</li> </ul> <p>Public projects are:</p> <ul> <li>\u2705 Visible to all users</li> <li>\u2705 Read-only for non-members</li> <li>\u2705 Searchable in project listings</li> <li>\u274c Only editable by owners and editors </li> <li>\u274c Not editable by viewers or anonymous users</li> </ul>"},{"location":"usage/projects/guide/#data-storage-architecture","title":"\ud83d\udcbe Data Storage Architecture","text":""},{"location":"usage/projects/guide/#delta-lake-backend","title":"Delta Lake Backend","text":"<p>All project data is automatically converted to Delta Lake format which provides following benefits:</p> <ul> <li>ACID Transactions - Reliable data consistency</li> <li>Time Travel - Version history and rollback capabilities</li> <li>Schema Evolution - Handle changing data structures</li> <li>Optimized Queries - Fast dashboard performance</li> <li>Compression - Efficient storage utilization</li> </ul> <p>Future Depictio versions will support aforementioned features progressively, enhancing user experience and data management capabilities.</p>"},{"location":"usage/projects/guide/#storage-hierarchy","title":"Storage Hierarchy","text":"<pre><code>Project Storage Structure:\n\u251c\u2500\u2500 metadata/           # Project configuration and metadata\n\u251c\u2500\u2500 data_collections/   # Raw data collections\n\u2502   \u251c\u2500\u2500 collection_1/\n\u2502   \u2502   \u251c\u2500\u2500 delta_table/  # Optimized Delta Lake format\n\u2502   \u2502   \u2514\u2500\u2500 metadata.json # Collection-specific metadata\n\u2502   \u2514\u2500\u2500 collection_2/\n\u251c\u2500\u2500 dashboards/        # Dashboard configurations\n\u2514\u2500\u2500 permissions/       # Access control data\n</code></pre>"},{"location":"usage/projects/guide/#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>Lazy Loading - Load data only when needed</li> <li>Column Pruning - Select only required columns</li> <li>Predicate Pushdown - Filter data at storage level</li> <li>Caching - Cache frequently accessed data</li> <li>Partitioning - Optimize queries by partition keys</li> </ul>"},{"location":"usage/projects/guide/#advanced-configuration-options","title":"\ud83d\udd27 Advanced Configuration Options","text":""},{"location":"usage/projects/guide/#environment-variables","title":"Environment Variables","text":"<p>Use environment variables for flexible deployments:</p> <pre><code># Configuration with environment variables\nparent_runs_location:\n  - \"{DATA_LOCATION}/study1\" # Resolved at runtime\n  - \"{BACKUP_LOCATION}/study1\" # Alternative location\n</code></pre>"},{"location":"usage/projects/guide/#polars-integration","title":"Polars Integration","text":"<p>Advanced data processing with Polars DataFrames:</p> <pre><code>dc_specific_properties:\n  format: \"CSV\"\n  polars_kwargs:\n    separator: \",\"\n    has_header: true\n    skip_rows: 1\n    column_types:\n      sample_id: \"String\"\n      expression: \"Float64\"\n      p_value: \"Float64\"\n    null_values: [\"NA\", \"NULL\", \"\"]\n</code></pre>"},{"location":"usage/projects/guide/#data-joining","title":"Data Joining","text":"<p>Complex data relationships through joins:</p> <pre><code>join:\n  on_columns: [\"sample_id\", \"timepoint\"] # Multi-column joins\n  how: \"inner\" # Join type\n  with_dc: [\"metadata\", \"quality_stats\"] # Target collections\n</code></pre>"},{"location":"usage/projects/guide/#custom-workflows","title":"Custom Workflows","text":"<p>Support for various workflow engines:</p> <pre><code>engine:\n  name: \"nextflow\" # or \"snakemake\", \"python\", \"cwl\", \"galaxy\"\n  version: \"24.10.3\" # Version for reproducibility\n\ncatalog:\n  name: \"nf-core\" # Workflow catalog\n  url: \"https://nf-co.re/rnaseq\"\n</code></pre>"},{"location":"usage/projects/guide/#best-practices","title":"\ud83d\ude80 Best Practices","text":""},{"location":"usage/projects/guide/#project-organization","title":"Project Organization","text":"<ol> <li>Naming Convention - Use descriptive, consistent names</li> <li>Documentation - Include comprehensive descriptions</li> <li>Version Control - Track configuration changes</li> <li>Testing - Validate configurations before deployment</li> </ol>"},{"location":"usage/projects/guide/#data-management","title":"Data Management","text":"<ol> <li>File Organization - Maintain consistent directory structures</li> <li>Metadata - Include comprehensive column descriptions</li> <li>Validation - Use schema validation for data quality</li> <li>Backup - Implement regular backup strategies</li> </ol>"},{"location":"usage/projects/guide/#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Column Selection - Use <code>keep_columns</code> to reduce memory usage</li> <li>File Formats - Prefer Parquet over CSV for large datasets</li> <li>Partitioning - Organize data by frequently queried columns</li> <li>Indexing - Create appropriate indexes for query patterns</li> </ol>"},{"location":"usage/projects/guide/#collaboration","title":"Collaboration","text":"<ol> <li>Permission Management - Set appropriate access levels</li> <li>Documentation - Maintain clear project documentation</li> <li>Communication - Use descriptive commit messages for changes</li> <li>Standardization - Establish team conventions</li> </ol>"},{"location":"usage/projects/guide/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"usage/projects/guide/#common-issues","title":"Common Issues","text":"Configuration Errors <p>Problem: YAML validation fails</p> <p>Solutions: <pre><code># Validate configuration\ndepictio-cli config validate-project-config \\\n  --project-config-path ./config.yaml --verbose\n\n# Check YAML syntax\nyamllint config.yaml\n</code></pre></p> File Discovery Issues <p>Problem: Files not found during scanning</p> <p>Solutions: - Verify file paths and permissions - Test regex patterns with sample files - Check environment variable resolution - Use dry-run mode for testing</p> Permission Problems <p>Problem: Access denied to project resources</p> <p>Solutions: - Verify user roles and permissions - Check project visibility settings - Confirm authentication status - Contact project owners for access</p> Performance Issues <p>Problem: Slow dashboard loading</p> <p>Solutions: - Use column selection to reduce data size - Optimize join operations - Consider data partitioning - Review query patterns</p>"},{"location":"usage/projects/guide/#debugging-commands","title":"Debugging Commands","text":"<pre><code># Verbose execution with detailed logging\ndepictio-cli run --project-config-path ./config.yaml \\\n  --verbose --verbose-level DEBUG\n\n# Dry run to preview operations\ndepictio-cli run --project-config-path ./config.yaml --dry-run\n\n# Step-by-step execution for debugging\ndepictio-cli config check-server-accessibility\ndepictio-cli config validate-project-config --project-config-path ./config.yaml\ndepictio-cli data scan --project-config-path ./config.yaml\n</code></pre>"},{"location":"usage/projects/guide/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>CLI Reference - Complete CLI documentation</li> <li>YAML Examples - Comprehensive configuration examples</li> <li>Configuration Reference - Complete YAML reference</li> <li>Dashboard Creation - Building interactive dashboards</li> <li>API Documentation - Programmatic project management</li> </ul> <p>Projects form the foundation of data organization in Depictio. Choose the right project type for your workflow to unlock the full power of interactive data exploration and collaboration.</p>"},{"location":"usage/projects/reference/","title":"YAML Configuration Reference","text":"<p>Full Configuration Template Warning</p> <p>Do not copy-paste this entire configuration blindly. This reference shows all available options with their defaults and descriptions. Only specify values that differ from defaults or are required for your specific use case.</p> <p>This is a complete reference of all configuration options available in Depictio YAML files. For getting started and examples, see the YAML Examples Guide.</p> <pre><code># =============================================================================\n# DEPICTIO PROJECT CONFIGURATION REFERENCE\n# =============================================================================\n\n# Required: Project identification\nname:\n  \"My Project Name\" # Required: Human-readable project name\n  # Must be non-empty string\n  # Example: \"Multi-omics Cancer Study\"\n\n# Required: Project type determines configuration structure\nproject_type:\n  \"basic\" # Required: Options are \"basic\" or \"advanced\" (default: \"basic\")\n  # basic: Direct file upload/processing\n  # advanced: Workflow-integrated projects\n\n# Optional: Project visibility settings\nis_public:\n  false # Optional: Project visibility (default: false)\n  # true: Visible to all users (read-only)\n  # false: Restricted to project members\n\n# Optional: CLI integration path\nyaml_config_path:\n  null # Optional: Path to this YAML file (default: null)\n  # Auto-populated by CLI, rarely set manually\n\n# Optional: External project management integration\ndata_management_platform_project_url:\n  null # Optional: URL to external project system (default: null)\n  # Must start with http:// or https://\n  # Example: \"https://labid.embl.org/projects/123\"\n\n# =============================================================================\n# WORKFLOWS (Required for Advanced Projects)\n# =============================================================================\n\nworkflows:\n  - # Required: Workflow identification\n    name:\n      \"rnaseq_pipeline\" # Required: Unique workflow identifier\n      # Example: \"rnaseq_pipeline\", \"variant_calling\"\n\n    # Required: Execution engine information\n    engine:\n      name:\n        \"nextflow\" # Required: Engine name\n        # Examples: \"nextflow\", \"snakemake\", \"python\", \"galaxy\", \"cwl\", \"shell\", \"r\"\n      version:\n        \"24.10.3\" # Optional: Engine version for reproducibility\n        # Example: \"24.10.3\", \"7.32.0\"\n\n    # Optional: Workflow metadata\n    version:\n      \"3.18.0\" # Optional: Workflow version\n      # Example: \"1.0.0\", \"v2.3.1\"\n    description: \"nf-core RNA-seq pipeline for expression quantification\" # Optional: Workflow description\n    repository_url:\n      \"https://github.com/nf-core/rnaseq\" # Optional: Source code repository\n      # Example: \"https://github.com/user/workflow\"\n    workflow_tag:\n      \"nextflow/rnaseq_pipeline\" # Optional: Auto-generated workflow identifier\n      # Format: \"engine/name\" or \"catalog/name\"\n\n    # Optional: Workflow registry information\n    catalog:\n      name:\n        \"nf-core\" # Optional: Catalog name\n        # Options: \"nf-core\", \"smk-wf-catalog\", \"workflowhub\"\n      url:\n        \"https://nf-co.re/rnaseq\" # Optional: Catalog URL\n        # Example: \"https://nf-co.re/rnaseq\"\n\n    # Required: Data location configuration\n    data_location:\n      structure:\n        \"sequencing-runs\" # Required: Directory organization pattern\n        # Options:\n        #   \"flat\" - All files in single directory level\n        #   \"sequencing-runs\" - Hierarchical run-based structure\n\n      locations: # Required: Root directories to search\n        - \"{DATA_ROOT}/rnaseq_studies/cohort_2024\" # Supports environment variable expansion: {VAR_NAME}\n        - \"/backup/rnaseq_data\" # Examples: \"/absolute/path/to/data\", \"{DATA_ROOT}/project1\"\n\n      runs_regex:\n        \"batch_[A-C]\" # Required for \"sequencing-runs\" structure\n        # Optional for \"flat\" structure\n        # Regex pattern to identify individual runs\n        # Example: \"run_\\\\d+\", \"sample_.*\", \"batch[A-Z]\"\n\n    # Required: Data collections for this workflow\n    data_collections:\n      - # Required: Unique identifier for this data collection\n        data_collection_tag:\n          \"gene_expression\" # Required: Unique within project\n          # Used for referencing in joins and dashboards\n          # Example: \"gene_counts\", \"quality_metrics\"\n\n        # Optional: Human-readable description\n        description:\n          \"Per-sample gene expression quantification\" # Optional: Description of the data collection\n          # Used in UI tooltips and documentation\n\n        # Required: Data collection configuration\n        config:\n          # Required: Type of data collection\n          type:\n            \"table\" # Required: Data collection type\n            # Options (only table for now):\n            #   \"table\" - Tabular data (CSV, TSV, Excel, Parquet, Feather)\n\n          # Required: Data aggregation strategy\n          metatype:\n            \"aggregate\" # Required: Data collection metatype\n            # Options:\n            #   \"metadata\" - Single annotation/metadata file per project\n            #   \"aggregate\" - Multiple files combined into unified dataset\n\n          # Required: File discovery configuration\n          scan:\n            # Required: File scanning strategy\n            mode:\n              \"recursive\" # Required: Scanning strategy\n              # Options:\n              #   \"single\" - Single file per project/run\n              #   \"recursive\" - Pattern-based file discovery\n\n            # Required: Mode-specific scan parameters\n            scan_parameters:\n              # For mode: \"recursive\" - specify search pattern\n              regex_config: # Required for recursive mode: Pattern matching configuration\n                pattern:\n                  \"salmon/.*/quant.sf\" # Required: Regex pattern for file discovery\n                  # Example: \"stats/.*_stats\\\\.tsv\"\n                wildcards: # Optional: Named capture groups for metadata extraction\n                  - name: \"sample_id\" # Wildcard name for metadata extraction\n                    wildcard_regex: \"salmon/([^/]+)/quant.sf\" # Regex with capture group\n\n              # For mode: \"single\" - specify exact file (alternative to regex_config)\n              # filename: \"metadata/sample_info.csv\"  # Required for single mode: File path\n              # Can be absolute or relative path\n\n          # Required: Type-specific configuration\n          dc_specific_properties:\n            # Required: File format specification\n            format:\n              \"tsv\" # Required: File format\n              # Values: \"csv\", \"tsv\", \"xlsx\", \"xls\", \"parquet\", \"feather\"\n              # Case-insensitive, normalized to lowercase\n\n            # Required: Data reading configuration using Polars\n            polars_kwargs:\n              # Common options\n              separator:\n                \"\\t\" # Required for CSV/TSV: Column separator character\n                # Default: \",\" for CSV, \"\\t\" for TSV\n                # Example: \",\", \"\\t\", \"|\", \";\"\n              has_header:\n                true # Required: First row contains column names\n                # true: First row is headers, false: First row is data\n              skip_rows:\n                0 # Optional: Number of rows to skip at file beginning (default: 0)\n                # Useful for files with metadata headers\n\n              # Advanced options\n              column_types: # Optional: Explicit column type mapping\n                Name: \"String\" # Forces specific data types\n                Length: \"Int64\" # Example types: \"String\", \"Int64\", \"Float64\", \"Boolean\"\n                EffectiveLength: \"Float64\"\n                TPM: \"Float64\"\n                NumReads: \"Float64\"\n              column_names:\n                null # Optional: Override column names when has_header: false\n                # Example: [\"sample\", \"gene\", \"expression\"]\n              null_values:\n                [\"\", \"NULL\", \"null\", \"None\"] # Optional: Values to treat as null/missing\n                # Default: [\"\", \"NULL\", \"null\", \"None\"]\n              n_rows:\n                null # Optional: Limit number of rows to read\n                # Useful for testing configurations\n              encoding:\n                \"utf8\" # Optional: File encoding (default: \"utf8\")\n                # Example: \"utf8\", \"latin1\", \"ascii\"\n\n              # Excel-specific options (for .xlsx, .xls files)\n              sheet_name:\n                null # Optional: Excel sheet name to read\n                # Example: \"Results\", \"Sheet1\"\n              sheet_id:\n                null # Optional: Excel sheet index (0-based)\n                # Example: 0 (first sheet), 1 (second sheet)\n\n            # Optional: Column filtering for performance\n            keep_columns: # Optional: Column filtering\n              - \"Name\" # If specified, only these columns are retained\n              - \"TPM\" # Improves performance for large datasets\n              - \"NumReads\" # Example: [\"sample_id\", \"expression\", \"p_value\"]\n\n            # Optional: Column documentation\n            columns_description: # Optional: Column documentation\n              Name: \"Gene/transcript identifier\" # Human-readable column descriptions\n              TPM: \"Transcripts per million\" # Used in dashboard tooltips and documentation\n              NumReads: \"Estimated read count\" # Example format: column_name: \"Description\"\n\n        # Optional: Data joining configuration\n        join: # Optional: Join this collection with others\n          on_columns:\n            [\"sample_id\"] # Required: Column names for joining\n            # Must exist in both datasets\n            # Example: [\"sample_id\"], [\"sample_id\", \"timepoint\"]\n          how:\n            \"inner\" # Required: Join type\n            # Options: \"inner\", \"outer\", \"left\", \"right\"\n          with_dc:\n            [\"qc_summary\"] # Required: Target data collections to join with\n            # References to other data_collection_tag values\n</code></pre>"},{"location":"usage/projects/reference/#see-also","title":"See Also","text":"<ul> <li>YAML Examples - Complete configuration examples and patterns</li> <li>Project Guide - Comprehensive project management guide</li> <li>CLI Reference - Command-line interface documentation</li> </ul>"},{"location":"usage/projects/yaml-examples/","title":"YAML Project configuration breakdown","text":"<p>Configuration Validation</p> <p>Always validate your YAML configuration before using: <pre><code># Validate configuration syntax and structure\ndepictio-cli config validate-project-config \\\n  --project-config-path ./my_project.yaml --verbose\n</code></pre></p> <p>For YAML syntax highlighting in VS Code: Install the YAML extension and save files with <code>.yaml</code> or <code>.yml</code> extension.</p> <p>Configuration Template Warning</p> <p>Do not copy-paste entire configurations blindly. This reference shows all available options with their defaults and descriptions. Only specify values that differ from defaults or are required for your specific use case.</p> <p>This guide provides comprehensive YAML configuration examples for Depictio projects, from simple setups to complex bioinformatics workflows. For a complete reference of all options, see the Configuration Reference.</p>"},{"location":"usage/projects/yaml-examples/#quick-start-examples","title":"Quick Start Examples","text":"<p>Choose your starting point based on your project complexity:</p> Basic Project (Minimal) <p>Perfect for direct file upload and analysis:</p> <pre><code>name: \"My Analysis Project\"\nproject_type: \"basic\"\n\n# Files will be uploaded through the web interface\n# No additional configuration needed!\n</code></pre> Basic Project (CLI) <p>For CLI-based basic projects with direct files:</p> <pre><code>name: \"CSV Analysis Project\"  \nproject_type: \"basic\"\nis_public: false\n\ndata_collections:\n  - data_collection_tag: \"main_data\"\n    description: \"Primary dataset for analysis\"\n    config:\n      type: \"table\"\n      metatype: \"metadata\"\n      scan:\n        mode: \"single\"\n        scan_parameters:\n          filename: \"/path/to/data.csv\"\n      dc_specific_properties:\n        format: \"csv\"\n        polars_kwargs:\n          separator: \",\"\n          has_header: true\n</code></pre> Advanced Project (Minimal) <p>For workflow-generated data with pattern matching:</p> <pre><code>name: \"RNA-seq Analysis\"\nproject_type: \"advanced\"\n\nworkflows:\n  - name: \"rnaseq_pipeline\"\n    engine:\n      name: \"nextflow\"\n      version: \"24.10.3\"\n    data_location:\n      structure: \"sequencing-runs\"\n      locations:\n        - \"{DATA_LOCATION}/results\"\n      runs_regex: \"run_.*\"\n    data_collections:\n      - data_collection_tag: \"gene_counts\"\n        config:\n          type: \"table\"\n          metatype: \"aggregate\"\n          scan:\n            mode: \"recursive\"\n            scan_parameters:\n              regex_config:\n                pattern: \"counts/.*\\\\.tsv\"\n          dc_specific_properties:\n            format: \"tsv\"\n            polars_kwargs:\n              separator: \"\\t\"\n              has_header: true\n</code></pre>"},{"location":"usage/projects/yaml-examples/#configuration-schema","title":"Configuration Schema","text":""},{"location":"usage/projects/yaml-examples/#project-level-configuration","title":"Project-Level Configuration","text":"<p>All projects share these top-level configuration options:</p> <pre><code># === REQUIRED FIELDS ===\n\n# Project identification\nname: string                              # Required: Human-readable project name\n                                          # Must be non-empty string\n                                          # Example: \"Multi-omics Cancer Study\"\n\n\n# Advanced projects only: Workflow definitions  \nworkflows: [Workflow]                     # Default: [] (empty for basic projects)\n                                          # Array of workflow configurations\n                                          # See \"Workflow Configuration\" section\n\n# === REQUIRED FIELDS WITH DEFAULT VALUES ===\n\n# Project type determines the configuration structure\nproject_type: \"basic\" | \"advanced\"        # Default: \"basic\"\n                                          # Options:\n                                          # - basic: Direct file upload/processing\n                                          # - advanced: Workflow-integrated projects\n\n# Project visibility\nis_public: boolean                        # Default: false\n                                          # true: Visible to all users (read-only)\n                                          # false: Restricted to project members\n\n# CLI integration (typically auto-managed)\nyaml_config_path: string | null          # Default: null\n                                          # Path to this YAML configuration file\n                                          # Auto-populated by CLI, rarely set manually\n\n# === OPTIONAL FIELDS ===\n\n# External project management integration\ndata_management_platform_project_url: string | null    # Default: null\n                                                        # URL to external project system\n                                                        # Must start with http:// or https://\n                                                        # Example: \"https://labid.embl.org/projects/123\"\n</code></pre>"},{"location":"usage/projects/yaml-examples/#project-types-deep-dive","title":"Project Types Deep Dive","text":""},{"location":"usage/projects/yaml-examples/#basic-projects","title":"Basic Projects","text":"<p>Designed to be minimal and easy to set up, WebUI compatible, and suitable for small-scale analyses.</p> <p>Use cases:</p> <ul> <li>Direct CSV/Excel file analysis</li> <li>Ad-hoc data exploration  </li> <li>Small-scale studies (&lt; 100 files)</li> <li>Quick prototyping and visualization</li> </ul> <p>Configuration:</p> <ul> <li>Minimal setup required</li> <li>Data uploaded via web interface or defined in <code>data_collections</code></li> <li>No workflow integration needed (default workflow is created under the hood for system compatibility)</li> </ul>"},{"location":"usage/projects/yaml-examples/#advanced-projects","title":"Advanced Projects","text":"<p>Designed for complex data processing pipelines, automated workflows, and large-scale analyses.</p> <p>Use cases:</p> <ul> <li>Bioinformatics pipeline outputs</li> <li>Multi-sample studies oriented</li> <li>Automated data ingestion and updates</li> <li>Core facility workflows</li> </ul> <p>Configuration:</p> <ul> <li>Requires <code>workflows</code> and <code>data_collections</code> definitions (1 workflow contains &gt;= 1 data collection(s))</li> <li>CLI-driven data processing</li> <li>Regex-based file discovery</li> <li>Multi-run aggregation capabilities</li> </ul>"},{"location":"usage/projects/yaml-examples/#workflow-configuration-advanced","title":"Workflow Configuration (Advanced)","text":"<p>Advanced projects use workflows to describe data organization patterns. Each workflow corresponds to a computational pipeline that generates structured data.</p> <pre><code>workflows:\n  - # === REQUIRED FIELDS ===\n\n    name: string                          # Required: Workflow identifier\n                                          # Must be non-empty\n                                          # Example: \"rnaseq_pipeline\", \"variant_calling\"\n\n    engine:                               # Required: Execution engine information\n      name: string                        # Required: Engine name\n                                          # Examples: \"nextflow\", \"snakemake\", \"python\", \n                                          #          \"galaxy\", \"cwl\", \"shell\", \"r\"\n                                          # Note: currently not validated against a list\n\n      version: string | null              # Optional: Engine version for reproducibility\n                                          # Example: \"24.10.3\", \"7.32.0\"\n                                          # Note: version is currently saved only for the sake of documentation, no functional impact on the system, will be implemented in the future\n\n    data_location:                        # Required: Where to find workflow outputs\n      structure: string                   # Required: Directory organization pattern\n                                          # Options:\n                                          # - \"flat\": All files in single directory level\n                                          # - \"sequencing-runs\": Hierarchical run-based structure\n\n      locations: [string]                 # Required: Root directories to search\n                                          # Supports environment variable expansion: {VAR_NAME}\n                                          # Examples: \n                                          #   - \"/absolute/path/to/data\"\n                                          #   - \"{DATA_ROOT}/project1\"\n                                          #   - \"{HOME}/workflows/results\"\n\n      runs_regex: string | null           # Required if structure=\"sequencing-runs\"\n                                          # Optional if structure=\"flat\" \n                                          # Regex pattern to identify individual runs\n                                          # Example: \"run_\\\\d+\", \"sample_.*\", \"batch[A-Z]\"\n\n    data_collections: [DataCollection]    # Required: Data collection definitions\n                                          # Array of data collections for this workflow\n                                          # See \"Data Collections Configuration\"\n\n    # === OPTIONAL FIELDS ===\n\n    version: string | null                # Optional: Workflow version\n                                          # Example: \"1.0.0\", \"v2.3.1\"\n                                          # Note: version is currently saved only for the sake of documentation, no functional impact on the system, will be implemented in the future\n\n    catalog:                              # Optional: Workflow registry information\n      name: string | null                 # Options: \"nf-core\", \"smk-wf-catalog\", \"workflowhub\"\n      url: string | null                  # Catalog URL\n                                          # Example: \"https://nf-co.re/rnaseq\"\n\n    repository_url: string | null         # Optional: Source code repository\n                                          # Example: \"https://github.com/user/workflow\"\n\n    workflow_tag: string | null           # Optional: Auto-generated workflow identifier\n                                          # Format: \"engine/name\" or \"catalog/name\"\n                                          # Usually auto-populated, rarely set manually\n\n    config:                               # Optional: Workflow-specific configuration\n      version: string | null              # Workflow configuration version\n      workflow_parameters: object | null # Workflow-specific parameters\n</code></pre>"},{"location":"usage/projects/yaml-examples/#workflow-data-location-patterns","title":"Workflow Data Location Patterns","text":""},{"location":"usage/projects/yaml-examples/#flat-structure","title":"Flat Structure","text":"<pre><code>data_location:\n  structure: \"flat\"\n  locations:\n    - \"/data/project1/results\"\n    - \"{BACKUP_LOCATION}/project1\"  # Environment variable expansion\n  # runs_regex not needed for flat structure\n\n# Directory layout:\n# /data/project1/results/\n# \u251c\u2500\u2500 sample1_stats.csv\n# \u251c\u2500\u2500 sample2_stats.csv  \n# \u251c\u2500\u2500 sample1_counts.tsv\n# \u2514\u2500\u2500 sample2_counts.tsv\n</code></pre>"},{"location":"usage/projects/yaml-examples/#sequencing-runs-structure","title":"Sequencing-Runs Structure","text":"<pre><code>data_location:\n  structure: \"sequencing-runs\"  \n  locations:\n    - \"{DATA_ROOT}/rnaseq_study\"\n  runs_regex: \"run_\\\\d+\"  # Required: matches run_001, run_002, etc.\n\n# Directory layout:\n# ${DATA_ROOT}/rnaseq_study/\n# \u251c\u2500\u2500 run_001/\n# \u2502   \u251c\u2500\u2500 sample_A/\n# \u2502   \u2502   \u251c\u2500\u2500 stats.tsv\n# \u2502   \u2502   \u2514\u2500\u2500 counts.tsv\n# \u2502   \u2514\u2500\u2500 sample_B/\n# \u2502       \u251c\u2500\u2500 stats.tsv  \n# \u2502       \u2514\u2500\u2500 counts.tsv\n# \u2514\u2500\u2500 run_002/\n#     \u251c\u2500\u2500 sample_C/\n#     \u2502   \u251c\u2500\u2500 stats.tsv\n#     \u2502   \u2514\u2500\u2500 counts.tsv\n#     \u2514\u2500\u2500 sample_D/\n#         \u251c\u2500\u2500 stats.tsv\n#         \u2514\u2500\u2500 counts.tsv\n</code></pre>"},{"location":"usage/projects/yaml-examples/#environment-variable-expansion","title":"Environment Variable Expansion","text":"<p>Depictio supports environment variable expansion in file paths:</p> <pre><code># Environment setup\n# export DATA_ROOT=\"/mnt/storage/projects\"  \n# export PROJECT_NAME=\"cancer_study\"\n# export BACKUP_LOCATION=\"/backup/data\"\n\ndata_location:\n  locations:\n    - \"{DATA_ROOT}/{PROJECT_NAME}/results\"     # Expands to: /mnt/storage/projects/cancer_study/results\n    - \"{BACKUP_LOCATION}/{PROJECT_NAME}\"       # Expands to: /backup/data/cancer_study\n</code></pre> <p>Common Environment Variables:</p> <ul> <li><code>DATA_ROOT</code>, <code>DATA_LOCATION</code> - Primary data storage</li> <li><code>PROJECT_ROOT</code> - Project base directory  </li> <li><code>HOME</code>, <code>USER</code> - User-specific paths</li> <li><code>SCRATCH_DIR</code>, <code>TEMP_DIR</code> - Temporary storage locations</li> </ul>"},{"location":"usage/projects/yaml-examples/#data-collections-configuration","title":"Data Collections Configuration","text":"<p>Data collections define how to discover, process, and structure your data files. They are the core building blocks that connect file system data to Depictio  dashboards.</p> <pre><code>data_collections:\n  - # === REQUIRED FIELDS ===\n\n    data_collection_tag: string    # Required: Unique identifier within project\n                                  # Must be unique across all data collections\n                                  # Used for referencing in joins and dashboards\n                                  # Example: \"gene_counts\", \"quality_metrics\"\n\n    config:                     # Required: Data collection configuration\n      type: string                # Required: Data collection type\n                                  # Options (only table for now):\n                                  #  - \"table\": Tabular data (CSV, TSV, Excel, Parquet, Feather)\n\n      metatype: string | null    # Required for table type\n                                  # Required: Data collection metatype\n                                  # Options:\n                                  # - \"metadata\": Single annotation/metadata file per project\n                                  # - \"aggregate\": Multiple files combined into unified dataset\n\n      scan:                     # Required: File discovery configuration\n        mode: string              # Required: Scanning strategy\n                                  # Options:\n                                  # - \"single\": Single file per project/run\n                                  # - \"recursive\": Pattern-based file discovery\n\n        scan_parameters:        # Required: Mode-specific parameters\n          # For mode: \"single\"\n          filename: string      # Required: Relative or absolute file path\n                               # Example: \"metadata/sample_info.csv\"\n\n          # For mode: \"recursive\"  \n          regex_config:         # Required: Pattern matching configuration\n            pattern: string    # Required: Regex pattern for file discovery\n                              # Example: \"stats/.*_stats\\\\.tsv\"\n            wildcards: [...]   # Optional: Named capture groups for metadata extraction\n          max_depth: int | null # Optional: Maximum directory depth to search\n          ignore: [string] | null  # Optional: Patterns to exclude from search\n\n      dc_specific_properties:   # Required: Type-specific configuration\n        # See \"Table Configuration\" section for details\n\n    # === OPTIONAL FIELDS ===\n\n    description: string | null  # Optional: Human-readable description\n                               # Example: \"Per-sample quality control metrics\"\n</code></pre>"},{"location":"usage/projects/yaml-examples/#specific-data-collection-types","title":"Specific Data Collection Types","text":"<p>Data Collection Types</p> <p>Data collections can be of different types, each with its own configuration requirements. Currently, only the \"table\" type is supported, which handles structured tabular data. Future versions may introduce additional types for other data formats (e.g., Omics data, Images, GeoJSON).  </p>"},{"location":"usage/projects/yaml-examples/#table-data-collection-configuration","title":"Table Data Collection Configuration","text":"<p>Table data collections handle structured tabular data (CSV, TSV, Excel, Parquet, Feather):</p> <pre><code>dc_specific_properties:\n  # === REQUIRED FIELDS ===\n\n  format: string               # Required: File format\n                              # Values: \"csv\", \"tsv\", \"xlsx\", \"xls\", \"parquet\", \"feather\"\n                              # Case-insensitive, normalized to lowercase\n\n  polars_kwargs: object       # Required: Polars DataFrame configuration\n                             # Polars-specific parameters for data reading\n                             # See \"Polars Configuration\" section\n\n  # === OPTIONAL FIELDS ===\n\n  keep_columns: [string] | null    # Optional: Column filtering\n                                  # If specified, only these columns are retained\n                                  # Improves performance for large datasets\n                                  # Example: [\"sample_id\", \"expression\", \"p_value\"]\n\n  columns_description: {string: string} | null  # Optional: Column documentation\n                                               # Human-readable column descriptions\n                                               # Used in dashboard tooltips and documentation\n                                               # Example: \n                                               #   sample_id: \"Unique sample identifier\"\n                                               #   expression: \"Log2 expression level\"\n</code></pre>"},{"location":"usage/projects/yaml-examples/#polars-configuration-options","title":"Polars Configuration Options","text":"<p>Polars is Depictio's high-performance data processing engine. Configure data reading with these options:</p> <pre><code>polars_kwargs:\n  # === COMMON OPTIONS ===\n\n  # CSV/TSV specific\n  separator: string           # Column separator character\n                             # Default: \",\" for CSV, \"\\t\" for TSV\n                             # Example: \",\", \"\\t\", \"|\", \";\"\n\n  has_header: boolean        # First row contains column names\n                            # Default: true\n                            # Set false if first row is data\n\n  skip_rows: int            # Number of rows to skip at file beginning  \n                           # Default: 0\n                           # Useful for files with metadata headers\n                           # Example: 3 (skip first 3 lines)\n\n  # === ADVANCED OPTIONS ===\n\n  # Data types\n  column_types: object      # Explicit column type mapping\n                           # Forces specific data types\n                           # Example:\n                           #   sample_id: \"String\"\n                           #   count: \"Int64\"  \n                           #   p_value: \"Float64\"\n                           #   significant: \"Boolean\"\n\n  column_names: [string]    # Override column names\n                           # Useful when has_header: false\n                           # Example: [\"sample\", \"gene\", \"expression\"]\n\n  # Missing data handling\n  null_values: [string]     # Values to treat as null/missing\n                           # Default: [\"\", \"NULL\", \"null\", \"None\"]\n                           # Example: [\"NA\", \"N/A\", \"\", \"null\", \"-\"]\n\n  # Performance options\n  n_rows: int               # Limit number of rows to read\n                           # Useful for testing configurations\n                           # Example: 1000 (read only first 1000 rows)\n\n  # Encoding\n  encoding: string          # File encoding  \n                           # Default: \"utf8\"\n                           # Example: \"utf8\", \"latin1\", \"ascii\"\n\n  # Excel specific (for .xlsx, .xls files)\n  sheet_name: string        # Excel sheet name to read\n                           # Default: first sheet\n                           # Example: \"Results\", \"Sheet1\"\n\n  sheet_id: int            # Excel sheet index (0-based)\n                          # Alternative to sheet_name\n                          # Example: 0 (first sheet), 1 (second sheet)\n</code></pre>"},{"location":"usage/projects/yaml-examples/#file-scanning-patterns","title":"File Scanning Patterns","text":""},{"location":"usage/projects/yaml-examples/#single-file-mode","title":"Single File Mode","text":"<p>Best for metadata files or summary statistics generated once per project:</p> <pre><code>scan:\n  mode: \"single\"\n  scan_parameters:\n    filename: \"multiqc_data/multiqc_general_stats.txt\"\n\n# Finds exactly one file:\n# project_root/multiqc_data/multiqc_general_stats.txt\n</code></pre>"},{"location":"usage/projects/yaml-examples/#recursive-mode","title":"Recursive Mode","text":"<p>Uses regex patterns to discover files across directory structures:</p> <pre><code>scan:\n  mode: \"recursive\"\n  scan_parameters:\n    regex_config:\n      pattern: \"star_salmon/.*/quant.sf\"\n      # Wildcards for metadata extraction (optional)\n      wildcards:\n        - name: \"sample_id\"\n          wildcard_regex: \"star_salmon/([^/]+)/quant.sf\"\n    max_depth: 5        # Optional: limit search depth\n\n# Matches files like:\n# run_001/star_salmon/sample_A/quant.sf\n# run_001/star_salmon/sample_B/quant.sf  \n# run_002/star_salmon/sample_C/quant.sf\n</code></pre>"},{"location":"usage/projects/yaml-examples/#data-collection-joins","title":"Data Collection Joins","text":"<p>When you use a production-oriented workflow, it can be tricky to modify workflow structure itself and rely instead of post-processing steps to reformat data into a unified structure. Depictio supports joining multiple data collections to create unified datasets.</p> <p>Note about join configuration</p> <p>A join need to be defined once and does not need to be repeated for each data collection. For instance, if DC1 &amp; DC2 are joined, the join configuration needs to be defined in either DC1 or DC2, not both.</p> <p>This can be achieved by defining join configurations:</p> <pre><code># In one data collection configuration\njoin:\n  on_columns: [string]        # Required: Column names for joining\n                             # Must exist in both datasets\n                             # Example: [\"sample_id\"], [\"sample_id\", \"timepoint\"]\n\n  how: string                # Required: Join type\n                            # \"inner\": Keep only rows with matches in both datasets\n                            # \"outer\": Keep all rows, fill missing with null\n                            # \"left\": Keep all rows from left dataset  \n                            # \"right\": Keep all rows from right dataset\n\n  with_dc: [string]         # Required: Target data collections to join with\n                           # References to other data_collection_tag values\n                           # Example: [\"metadata\", \"quality_stats\"]\n\n# Example: Join expression data with sample metadata\ndata_collections:\n  - data_collection_tag: \"sample_metadata\"\n    # ... metadata configuration ...\n\n  - data_collection_tag: \"gene_expression\"\n    # ... expression configuration ...\n    join:\n      on_columns: [\"sample_id\"]\n      how: \"inner\"  \n      with_dc: [\"sample_metadata\"]\n</code></pre> <p>Join Limitations</p> <p>Joins are currently limited to simple column-based joins. Future versions may support more complex joins and transformations.</p>"},{"location":"usage/projects/yaml-examples/#configuration-patterns-library","title":"Configuration Patterns Library","text":""},{"location":"usage/projects/yaml-examples/#pattern-1-multi-sample-rna-seq-study","title":"Pattern 1: Multi-sample RNA-seq Study","text":"<pre><code>name: \"RNA-seq Expression Analysis\"\nproject_type: \"advanced\"\nis_public: false\n\nworkflows:\n  - name: \"nextflow-custom-rnaseq\"\n    engine:\n      name: \"nextflow\"\n      version: \"24.10.3\"\n    version: \"3.18.0\"\n\n    data_location:\n      structure: \"sequencing-runs\"\n      locations:\n        - \"{DATA_ROOT}/rnaseq_studies/cohort_2024\"\n      runs_regex: \"batch_[A-C]\"\n\n    data_collections:\n      # Quality control metrics\n      - data_collection_tag: \"qc_summary\"\n        description: \"Aggregated quality control summary across samples\"\n        config:\n          type: \"table\"\n          metatype: \"metadata\"\n          scan:\n            mode: \"single\"\n            scan_parameters:\n              filename: \"qc_reports/multiqc_general_stats.txt\"\n          dc_specific_properties:\n            format: \"tsv\"\n            polars_kwargs:\n              separator: \"\\t\"\n              has_header: true\n            keep_columns:\n              - \"Sample\"\n              - \"fastqc-total_sequences\"\n              - \"fastqc-percent_duplicates\"\n              - \"fastqc-percent_gc\"\n              - \"fastqc-avg_sequence_length\"\n              - \"fastqc-percent_fails\"\n            columns_description:\n              \"Sample\": \"Sample identifier\"\n              \"fastqc-total_sequences\": \"Total number of sequences processed by FastQC\"\n              \"fastqc-percent_duplicates\": \"Percentage of duplicate sequences\"\n              \"fastqc-percent_gc\": \"Overall GC content percentage\"\n              \"fastqc-avg_sequence_length\": \"Average read length\"\n              \"fastqc-percent_fails\": \"Percentage of FastQC modules that failed\"\n\n      # Gene expression quantification\n      - data_collection_tag: \"salmon_gene_tpm\"\n        description: \"Salmon merged gene-level TPM expression matrix\"  \n        config:\n          type: \"table\"\n          metatype: \"metadata\"\n          scan:\n            mode: \"single\"\n            scan_parameters:\n              filename: \"salmon/salmon.gene_tpm.melted.tsv\"\n          dc_specific_properties:\n            format: \"tsv\"\n            polars_kwargs:\n              separator: \"\\t\"\n              has_header: true\n            columns_description:\n              sample_id: \"Sample identifier\"\n              gene_id: \"Gene identifier\"  \n              gene_name: \"Gene symbol/name\"\n              condition: \"Experimental condition (e.g., treatment, control)\"\n              replicate: \"Biological replicate identifier\"\n              tpm: \"Transcripts per million (TPM) expression value\"\n        join:\n          on_columns: [\"sample_id\"]\n          how: \"inner\"\n          with_dc: [\"qc_summary\"]\n</code></pre>"},{"location":"usage/projects/yaml-examples/#pattern-2-multi-sample-strand-seq-single-cell-study","title":"Pattern 2: Multi-sample Strand-seq (single-cell) Study","text":"<pre><code>name: \"Strand-Seq data analysis\"\nproject_type: \"advanced\"\ndata_management_platform_project_url: \"https://labid.embl.org/core/projects/default/5baa8f07-bd00-46e7-b3cb-ec79d01f6f3c\"\n\nworkflows:\n  - name: \"mosaicatcher-pipeline\"\n    engine:\n      name: \"snakemake\"\n    version: \"2.3.5\"\n    catalog:\n      name: \"smk-wf-catalog\"\n      url: \"https://snakemake.github.io/snakemake-workflow-catalog/docs/workflows/friendsofstrandseq/mosaicatcher-pipeline.html\"\n    repository_url: \"https://github.com/friendsofstrandseq/mosaicatcher-pipeline\"\n    workflow_tag: \"snakemake/mosaicatcher-pipeline\"\n\n    data_location:\n      structure: \"sequencing-runs\"\n      locations:\n        - \"/Data/mosaicatcher-pipeline-results/\"\n      runs_regex: \".*\"\n\n    data_collections:\n      # MosaiCatcher statistics per cell\n      - data_collection_tag: \"mosaicatcher_stats\"\n        description: \"Statistics file generated by MosaiCatcher\"\n        config:\n          type: \"table\"\n          metatype: \"aggregate\"\n          scan:\n            mode: \"recursive\"\n            scan_parameters:\n              regex_config:\n                pattern: \".*\\\\.info_raw\"\n          dc_specific_properties:\n            format: \"tsv\"\n            polars_kwargs:\n              skip_rows: 13\n              separator: \"\\t\"\n              has_header: true\n            keep_columns:\n              - \"sample\"\n              - \"cell\"\n              - \"mapped\"\n              - \"dupl\"\n              - \"pass1\"\n              - \"good\"\n            columns_description:\n              sample: \"Sample ID\"\n              cell: \"Cell ID\"\n              mapped: \"Total number of reads seen\"\n              dupl: \"Reads filtered out as PCR duplicates\"\n              pass1: \"Coverage compliant cells (binary)\"\n              good: \"Reads used for counting\"\n\n      # Ashleys QC labels  \n      - data_collection_tag: \"ashleys_labels\"\n        description: \"Probabilities generated by ashleys-qc model\"\n        config:\n          type: \"table\"\n          metatype: \"aggregate\"\n          scan:\n            mode: \"recursive\"\n            scan_parameters:\n              regex_config:\n                pattern: \".*cell_selection/labels\\\\.tsv\"\n          dc_specific_properties:\n            format: \"tsv\"\n            polars_kwargs:\n              separator: \"\\t\"\n              has_header: true\n        join:\n          on_columns: [\"sample\", \"cell\"]\n          how: \"inner\"\n          with_dc: [\"mosaicatcher_stats\"]\n\n      # Structural variant calls\n      - data_collection_tag: \"sv_calls\"\n        description: \"SV calls generated by MosaiCatcher (stringent)\"\n        config:\n          type: \"table\"\n          metatype: \"aggregate\"\n          scan:\n            mode: \"recursive\"\n            scan_parameters:\n              regex_config:\n                pattern: \"stringent_filterTRUE\\\\.tsv\"\n          dc_specific_properties:\n            format: \"tsv\"\n            polars_kwargs:\n              separator: \"\\t\"\n              has_header: true\n            columns_description:\n              sample: \"Sample identifier\"\n              cell: \"Single cell identifier\"\n              chrom: \"Chromosome name\"\n              start: \"SV start position\"\n              end: \"SV end position\"\n              sv_call_name: \"Structural variant call identifier\"\n        join:\n          on_columns: [\"sample\", \"cell\"]\n          how: \"inner\"\n          with_dc: [\"ashleys_labels\", \"mosaicatcher_stats\"]\n\n      # Sample metadata\n      - data_collection_tag: \"mosaicatcher_samples_metadata\"\n        description: \"Metadata file for MosaiCatcher samples\"\n        config:\n          type: \"table\"\n          metatype: \"metadata\"\n          scan:\n            mode: \"single\"\n            scan_parameters:\n              filename: \"/Data/mosaicatcher-pipeline-results/metadata/mosaicatcher_samples_metadata_2024.xlsx\"\n          dc_specific_properties:\n            format: \"xlsx\"\n            polars_kwargs:\n              has_header: true\n            columns_description:\n              sample: \"Sample identifier\"\n              patient_id: \"Patient identifier\"\n              tissue_type: \"Type of tissue analyzed\"\n              collection_date: \"Date of sample collection\"\n        join:\n          on_columns: [\"sample\"]\n          how: \"inner\"\n          with_dc: [\"ashleys_labels\", \"mosaicatcher_stats\", \"sv_calls\"]\n</code></pre>"},{"location":"usage/projects/yaml-examples/#validation","title":"\ud83d\udd0d Validation","text":""},{"location":"usage/projects/yaml-examples/#cli-validation-commands","title":"CLI Validation Commands","text":"<pre><code># Validate configuration file syntax and structure\ndepictio-cli config validate-project-config \\\n  --project-config-path ./my_project.yaml \\\n  --verbose\n\n# Check server connectivity and permissions\ndepictio-cli config check-server-accessibility\n\n# Dry-run mode: validate without processing data\ndepictio-cli run --project-config-path ./my_project.yaml \\\n  --dry-run --verbose\n\n# Test file discovery patterns\ndepictio-cli data scan --project-config-path ./my_project.yaml \\\n  --verbose --verbose-level DEBUG\n</code></pre>"},{"location":"usage/projects/yaml-examples/#additional-resources","title":"\ud83d\udcd6 Additional Resources","text":"<ul> <li>Projects Guide - Comprehensive project management guide</li> <li>Configuration Reference - Complete YAML reference documentation</li> <li>CLI Reference - Complete CLI command documentation  </li> <li>Dashboard Creation - Building interactive dashboards</li> <li>API Documentation - Programmatic project management</li> <li>Pydantic Models - Schema definitions and validation</li> </ul> <p>This reference covers all configuration options available in Depictio. Start with the Quick Start examples and gradually add complexity as needed for your specific use case.</p>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/category/tutorials/","title":"Tutorials","text":""},{"location":"blog/category/features/","title":"Features","text":""},{"location":"blog/category/announcements/","title":"Announcements","text":""},{"location":"blog/category/launch/","title":"Launch","text":""},{"location":"blog/category/demo/","title":"Demo","text":""}]}