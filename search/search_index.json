{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Depictio documentation","text":""},{"location":"#project-overview","title":"Project Overview","text":"<p>Depictio is an innovative web-based platform currently under development, aimed at facilitating downstream analysis in bioinformatics. It provides a dynamic and interactive dashboard experience for quality control (QC) metrics monitoring and result exploration in omics. The platform is tailored towards large-scale studies and research facilities, offering support for various data formats and interactive data visualization tools.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Dynamic Dashboards: Real-time data interaction, customizable views, and user-driven exploration features.</li> <li>Diverse Data Format Support: Handles standard formats like CSV, TSV, XLSX, Parquet, and omics files like BED, BigBed, BigWig, BAM/CRAM, VCF.</li> <li>Robust Backend Technologies: Utilizes FastAPI, MongoDB, and Redis cache for high-performance data management and processing.</li> <li>Intuitive Frontend: Built on Plotly Dash, a ReactJS-based framework</li> </ul>"},{"location":"#current-status","title":"Current Status","text":"<p>Depictio is currently in the development phase and is not yet available for general use. The platform is being built with an emphasis on versatility and adaptability to various biological research needs.</p>"},{"location":"api/","title":"API","text":"<p>Depictio API is built on top of FastAPI, a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints. It is designed to be easy to use and understand, with a focus on performance and scalability. </p>"},{"location":"architecture/","title":"Architecture","text":"<p>Depictio architecture is currently composed of two main aspects: a microservices architecture (to be executed into a docker-compose and late on in a kubernetes cluster) and a CLI client to be installed locally on-premise where the data to be scanned is located.  There are currently 6 main microservices running:</p> <ol> <li> <p>FastAPI instance</p> </li> <li> <p>mongoDB database</p> </li> <li> <p>redis cache system</p> </li> <li> <p>JBrowse on-premise genome browser</p> </li> <li> <p>MinIO S3 bucket management instance</p> </li> <li> <p>Plotly Dash server</p> </li> </ol>"},{"location":"architecture/#plotly-dash-server","title":"Plotly Dash server","text":""},{"location":"contributing/","title":"Contributing","text":"<p>While Depictio is not yet operational, we welcome ideas, suggestions, and feedback from the community. If you have insights or want to contribute to the project, please feel free to open an issue or submit a pull request.</p>"},{"location":"get_started/","title":"Get Started","text":""},{"location":"get_started/#current-setup","title":"Current setup","text":"<p>Clone the repo:</p> <pre><code>git clone https://github.com/weber8thomas/depictio.git\n</code></pre> <p>Or if you want to use the jbrowse submodule (which is not mandatory) use the following command to clone the repo with the submodule:</p> <pre><code>git clone --recurse-submodules https://github.com/weber8thomas/depictio.git\n</code></pre> <p>If needed, example data can be downloaded by cloning the following repo:</p> <pre><code>git clone https://github.com/weber8thomas/depictio-data.git\n</code></pre> <p>Create and modify the <code>.env</code> file to update the environment variables. The following variables are mandatory to be set:</p> <pre><code>DEPICTIO_BACKEND_DATA_VOLUME_HOST=/ABSOLUTE/PATH/TO/depictio-data\nMINIO_ROOT_USER=minio\nMINIO_ROOT_PASSWORD=minio123\nMINIO_ACCESS_KEY=minio\nMINIO_SECRET_KEY=minio123\nAUTH_PRIVATE_KEY=&lt;your_public_key&gt;\nAUTH_PUBLIC_KEY=&lt;your_secret_key&gt;\n</code></pre> <p>Create the MongoDB data folder and assign the correct permissions:</p> <pre><code>mkdir -p depictioDB/ &amp;&amp; chmod 777 depictioDB/\n</code></pre> <p>Start the docker-compose services:</p> <pre><code>docker compose -f docker-compose.yml up -d\n</code></pre> <p>The services will be available at the following URLs (with default ports and configurations):</p> <ul> <li>Depictio frontend: http://localhost:5080</li> <li>Depictio backend: http://localhost:8058</li> <li>MinIO: http://localhost:9000</li> <li>MinIO WebUI: http://localhost:9001</li> <li>MongoDB: http://localhost:27018</li> </ul> <p>Create the depictio-cli python venv using the following:</p> <pre><code># Set up a virtual environment\npython -m venv depictio-cli-venv\n\n# Activate the virtual environment\nsource depictio-cli-venv/bin/activate\n\n# Install dependencies from requirements file\npip install -r requirements/depictio-cli-requirements.txt\n\n# Add the depictio package to the PYTHONPATH\nexport PYTHONPATH=$PYTHONPATH:$PWD/depictio\n</code></pre> <p>Then, create a default user (Paul Cezanne) in the mongoDB with the following command:</p> <pre><code>python depictio/api/v1/configs/create_user_mongodb.py\n</code></pre> <p>And create a user token with the following command:</p> <pre><code>python depictio-cli/depictio_cli/depictio_cli.py create-user-and-return-token\n</code></pre> <p>This will create a default user (Paul Cezanne) as well as a configuration in your home folder: <code>~/.depictio-cli/config.yaml</code>. This file contains the user token and the backend URL.</p> <pre><code>DEPICTIO_API: http://localhost:8058\nemail: paul.cezanne@embl.de\ntoken: eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\nuser:\n  email: paul.cezanne@embl.de\n  password: paul\n  username: cezanne\n</code></pre> <p>Update the <code>.env</code> file with the following variables:</p> <pre><code>AUTH_TMP_TOKEN=&lt;token_defined_in_the_config.yaml&gt;\n</code></pre> <p>Restart the docker-compose services with the following command in order to update the environment variables:</p> <pre><code>docker compose -f docker-compose.yml up -d --force-recreate\n</code></pre> <p>You can now register data collections and workflows using the depictio-cli using:</p> <pre><code>python depictio-cli/depictio_cli/depictio_cli.py setup \\\n    --config_path configs/mosaicatcher_pipeline/mosaicatcher_pipeline.yaml \\\n    --scan_files\n</code></pre>"},{"location":"modularity/","title":"Modularity","text":"<p>Depictio code is designed with a modular architecture, allowing for easy integration of new features and functionalities. The frontend and backend components are decoupled, enabling independent development and deployment of each module. The platform is built to be scalable and adaptable to various needs, with a focus on user-friendly interfaces and interactive data visualization tools. </p>"},{"location":"modularity/#general-object-and-database-design","title":"General object and database design","text":"<p>Depictio is designed to manage complex workflows and their associated data collections, files, and configurations. The architecture is built to ensure a clear separation of concerns, with distinct layers for workflows, run configurations, runs, files, and data collections. This modular approach is reflected in both the database schema and the API structure.</p>"},{"location":"modularity/#workflow-object-design","title":"Workflow Object Design","text":"<ul> <li>Workflow: The top-level entity that encapsulates an entire process or pipeline. Each workflow can have multiple configurations and runs associated with it.</li> <li>Run Configurations: These define the parameters and settings for running a workflow. Different configurations can be used to run the same workflow under different conditions.</li> <li>Runs: Instances of a workflow executed using a specific run configuration. Each run generates output files, that are structured the same way across runs. These files can then be associated into data collections.</li> <li>Files: Artifacts produced by each run. These can be intermediate or final results of the workflow.</li> <li>Data Collections: Aggregated data from files following the same structure.</li> </ul> <p>The following diagram illustrates the relationships between different entities in Depictio:</p> <p></p>"},{"location":"modularity/#code-architecture","title":"Code architecture","text":"<p>The code organisation clearly separates each of the frontend components and the API endpoints, making it easy to understand and extend the platform. </p> <p></p>"},{"location":"modularity/#api-structure","title":"API structure","text":"<p>The API is structured to mirror the object design specified above, with each major component of the workflow having its own set of endpoints and models. The organization within <code>depictio/api/v1/endpoints</code> is as follows:</p> <ul> <li>dashboards_endpoints: Manages endpoints related to dashboards, providing models and routes for dashboard data.</li> <li>datacollections_endpoints: Handles endpoints for data collections, mapping closely to the Data Collection objects in the design.</li> <li>deltatables_endpoints: Provides endpoints for delta tables, which are specific types of data collections with versioning.</li> <li>files_endpoints: Manages file-related endpoints, directly corresponding to the File objects.</li> <li>jbrowse_endpoints: Contains endpoints for jbrowse-specific functionalities, likely related to genomic data visualization.</li> <li>user_endpoints: Manages user authentication and authorization, including models and routes for user management.</li> <li>utils_endpoints: Provides utility endpoints, typically for internal or auxiliary operations.</li> <li>workflow_endpoints: Focuses on managing workflows, run configurations, and runs, reflecting the core of the workflow architecture.</li> </ul> <p>Each endpoint is defined in a separate subfolder, where the <code>routes.py</code> file contains the API routes and the <code>models.py</code> file contains the object models associated.</p> <p></p>"},{"location":"modularity/#dashboard-components","title":"Dashboard components","text":"<p>The frontend components in Depictio are organized in the depictio/dash/modules folder, with each component defined in a separate subfolder. This modular design ensures easy integration and maintainability.</p>"},{"location":"modularity/#component-structure","title":"Component Structure","text":"<p>Each component folder typically contains:</p> <ul> <li>frontend.py: Implements Dash callback functions.</li> <li>utils.py: Contains helper functions for rendering and state management.</li> </ul> <p>Each of the frontend components is designed to be modular and can be easily integrated into the dashboard. Each component is defined in a separate folder, containing the component logic and styling. The <code>frontend.py</code> file contains the dash callback functions implementation and the <code>utils.py</code> file contains the helpers functions used by the component, allowing the component to be re-rendered in different scenarios (first design, reload/restore, refresh after data update).</p> <p></p>"},{"location":"modularity/#generic-components-data-collection-table","title":"Generic components (Data collection Table)","text":"<p>There are currently 4 main components supported to build your dashboard:</p> <ul> <li>Figures: Bar, Line, Scatter, Box and Histogram plots.</li> <li>Metrics cards: Cards displaying metrics values.</li> <li>Interactive components: (slider, dropdown, input text, etc.)</li> <li>Tables: Interactive tables with sorting, filtering and searching functionalities.</li> </ul>"},{"location":"modularity/#specific-components","title":"Specific components","text":"<ul> <li>JBrowse: Genome browser to visualize genomic data.</li> <li>Graphs: Network graphs to visualize interactions between entities.</li> <li>Geomap: Geographical map.</li> </ul>"},{"location":"modularity/#web-ui","title":"Web UI","text":"<p>To add a new component to the dashboard, you simply need to click on the \"Add new component\" button of your dashboard. This will open a 3-levels modal where you will be able to select:</p> <ol> <li> <p>The data source: it corresponds to the bioinformatics workflow and the data collection you want to be based on to build your new component.</p> </li> <li> <p>The component type: it corresponds to the type of component (listed below) you want to add to your dashboard.</p> </li> <li> <p>The component configuration: it corresponds to the configuration of the component you want to add to your dashboard.</p> </li> </ol>"},{"location":"installation/cli/","title":"CLI installation","text":"<p>Install the CLI dependencies:</p>"},{"location":"installation/cli/#pip-conda-version","title":"pip / conda version","text":"<pre><code>pip install -r requirements.txt\n</code></pre> <pre><code>conda env create -f \n</code></pre>"},{"location":"installation/cli/#docker-version","title":"Docker version","text":""},{"location":"installation/microservices/docker/","title":"Docker Compose","text":"<p>Clone the repo:</p> <pre><code>git clone https://github.com/weber8thomas/depictio.git\n</code></pre> <p>Or if you want to use the jbrowse submodule:</p> <pre><code>git clone --recurse-submodules https://github.com/weber8thomas/depictio.git\n</code></pre> <p>If needed, example data can be downloaded by cloning the following repo:</p> <pre><code>git clone https://github.com/weber8thomas/depictio-data.git\n</code></pre> <p>Create and modify the <code>.env</code> file to update the environment variables. The following variables are mandatory to be set:</p> <pre><code>DEPICTIO_BACKEND_DATA_VOLUME_HOST=&lt;path_to_your_data_folder&gt;\nMINIO_ROOT_USER=&lt;minio&gt;\nMINIO_ROOT_PASSWORD=&lt;minio123&gt;\nMINIO_ACCESS_KEY=&lt;minio&gt;\nMINIO_SECRET_KEY=&lt;minio123&gt;\n</code></pre> <p>Create the MongoDB data folder and assign the correct permissions:</p> <pre><code>mkdir -p depictioDB/\n</code></pre> <p>Start the docker-compose services:</p> <pre><code>docker compose up -d --build\n</code></pre>"},{"location":"installation/microservices/kubernetes/","title":"Kubernetes","text":"<p>Ongoing</p>"}]}